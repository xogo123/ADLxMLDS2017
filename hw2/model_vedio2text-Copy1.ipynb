{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "def init():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    keras.backend.tensorflow_backend.set_session(session)\n",
    "init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path and parameter\n",
    "path_data = './MLDS_hw2_data/'\n",
    "str_output = 'output_testset.txt'\n",
    "str_output_peer_review = 'output_peer_review.txt'\n",
    "load_model_weight_name = 'lst_layer_weights_10_28_73.pkl'\n",
    "\n",
    "model_name = 's2s'\n",
    "\n",
    "max_seq = 10\n",
    "n_caption = -1\n",
    "only_one_caption = 0\n",
    "\n",
    "loading_model = 1\n",
    "do_training = 0\n",
    "teacherForce = 0\n",
    "attention = 0\n",
    "# after_teacherForce_train = 0\n",
    "after_teacherForce_test = 0\n",
    "\n",
    "save_model = 0\n",
    "train_data_loading = 0\n",
    "test_data_loading = 1\n",
    "peer_review_data_loading = 1\n",
    "\n",
    "special_task = 0\n",
    "\n",
    "# if len(sys.argv) > 1 :\n",
    "#     path_data = sys.argv[1]\n",
    "#     str_output = sys.argv[2]\n",
    "#     str_output_peer_review = sys.argv[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<padding>\": 0, \"<BOS>\": 1, \"<EOS>\" :2}\n",
    "        self.word2count = {\"<padding>\" : 0, \"<BOS>\": 0, \"<EOS>\" : 0}\n",
    "        self.index2word = {0:\"<padding>\", 1: \"<BOS>\", 2: \"<EOS>\"}\n",
    "        self.n_words = 3  # Count padding and BOS and EOS\n",
    "        self.max_len_seq = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        lst_word = sentence.split()\n",
    "        if len(lst_word) > max_seq :\n",
    "            return 0\n",
    "        elif self.max_len_seq < len(lst_word) :\n",
    "            self.max_len_seq = len(lst_word)\n",
    "        for word in lst_word :\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_log_plot(log) :\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    fig = plt.figure(1,figsize=(20,10))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(log['acc'], label='train_acc')\n",
    "    plt.plot(log['val_acc'], label='val_acc')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('acc', fontsize=20, color='black')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(log['loss'], label='train_loss')\n",
    "    plt.plot(log['val_loss'], label='val_loss')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('loss', fontsize=20, color='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_init(lst_dict_label_train) :\n",
    "    lang = Lang()\n",
    "    for dict_label_train in lst_dict_label_train :\n",
    "        for sentence in dict_label_train['caption'] :\n",
    "            sentence = sentence[:-1] + ' <EOS>'\n",
    "            lang.addSentence(sentence) # remove \".\"\n",
    "    print ('lang.n_words : ' + str(lang.n_words))\n",
    "    print ('lang.max_len_seq : ' + str(lang.max_len_seq))\n",
    "    assert lang.max_len_seq == max_seq, 'error here'\n",
    "    return lang\n",
    "# assert lang.word2count['<BOS>'] == lang.word2count['<EOS>'], number of \"<BOS>\" != number of \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index to one-hot\n",
    "def Str2OneHot(sentence, n_class, dict_map, max_len_seq) :\n",
    "    ### sentence to lst_index_sentence\n",
    "    sentence = sentence[:-1] + ' <EOS>'\n",
    "    lst_word = sentence.split()\n",
    "    ary_oneHot = np.zeros((max_len_seq,n_class))\n",
    "    lst_index_word = [dict_map[word] for word in lst_word]\n",
    "    ary_oneHot[range(len(lst_word)),lst_index_word] = 1\n",
    "    ary_oneHot[range(len(lst_word),len(ary_oneHot)),:] = 0.0 # others all set <padding>\n",
    "    ary_oneHot[range(len(lst_word),len(ary_oneHot)),0] = 1.0 # others all set <padding>\n",
    "    return ary_oneHot\n",
    "    \n",
    "### just for test\n",
    "# ary = Str2OneHot('A woman goes under a horse.', lang.n_words, lang.word2index, lang.max_len_seq)\n",
    "# print (ary.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_label.json : \n",
      "caption : \n",
      "['A woman goes under a horse.', 'A woman crawls under a horse and gets a surprise.']\n",
      "id : \n",
      "xBePrplM4OA_6_18.avi\n",
      "lang.n_words : 5149\n",
      "lang.max_len_seq : 10\n",
      "test data is loading...\n",
      "ary_test_EC_input.shape :\n",
      "(100, 80, 4096)\n",
      "ary_test_DC_input.shape :\n",
      "(100, 1, 5149)\n",
      "peer review data is loading...\n",
      "ary_peer_review_EC_input.shape :\n",
      "(5, 80, 4096)\n",
      "ary_peer_review_DC_input.shape :\n",
      "(5, 1, 5149)\n",
      "---data loading finished---\n"
     ]
    }
   ],
   "source": [
    "### preprocessing\n",
    "\n",
    "### for training data\n",
    "### load lst_dict_label_train\n",
    "\n",
    "with open('{}training_label.json'.format(path_data)) as f :\n",
    "    lst_dict_label_train = json.load(f)\n",
    "print ('\\ntraining_label.json : ')\n",
    "print ('caption : \\n' + str(lst_dict_label_train[0]['caption'][:2]))\n",
    "print ('id : \\n' + str(lst_dict_label_train[0]['id']))\n",
    "\n",
    "lang = lang_init(lst_dict_label_train)\n",
    "\n",
    "if train_data_loading :\n",
    "    print ('train data is loading...')\n",
    "    ### pair caption and vedio feature\n",
    "    ### output : ary_train_EC_input\n",
    "    ###          ary_train_DC_output\n",
    "    ###          ary_train_DC_input\n",
    "    lst_id_train = [dict_label_train['id'] for dict_label_train in lst_dict_label_train]\n",
    "    lst_train_EC_input = []\n",
    "    lst_train_DC_output = []\n",
    "    for i, id in enumerate(lst_id_train) :\n",
    "        lst_npy = np.load('{}training_data/feat/{}.npy'.format(path_data, id)).tolist()\n",
    "        for caption in lst_dict_label_train[i]['caption'][:n_caption] :\n",
    "            if len(caption.split()) >= max_seq : # note >=\n",
    "                continue\n",
    "            lst_train_EC_input += [lst_npy]\n",
    "            lst_ary_OneHot = Str2OneHot(caption, lang.n_words, lang.word2index, lang.max_len_seq).tolist()\n",
    "            lst_train_DC_output += [lst_ary_OneHot]\n",
    "            if only_one_caption :\n",
    "                break\n",
    "    assert len(lst_train_EC_input) == len(lst_train_DC_output), \"??\"\n",
    "    ary_train_EC_input = np.asarray(lst_train_EC_input).reshape(-1,80,4096)\n",
    "    del lst_train_EC_input\n",
    "    ary_train_DC_output = np.asarray(lst_train_DC_output).reshape(-1,lang.max_len_seq,lang.n_words)\n",
    "    del lst_train_DC_output\n",
    "\n",
    "    ### add \"<BOS>\" to ary_train_DC_input\n",
    "    ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    if teacherForce :\n",
    "        ary_train_DC_input = np.concatenate([ary_temp,ary_train_DC_output[:,:-1]],axis=1)\n",
    "    else :\n",
    "        ary_train_DC_input = ary_temp\n",
    "\n",
    "    print ('ary_train_EC_input.shape :')\n",
    "    print (ary_train_EC_input.shape)\n",
    "    print ('ary_train_DC_output.shape :')\n",
    "    print (ary_train_DC_output.shape)\n",
    "    print ('ary_train_DC_input.shape :')\n",
    "    print (ary_train_DC_input.shape)\n",
    "\n",
    "### for testing data\n",
    "if test_data_loading :\n",
    "    print ('test data is loading...')\n",
    "    with open('{}testing_label.json'.format(path_data)) as f :\n",
    "        lst_dict_label_test = json.load(f)\n",
    "    ### pair caption and vedio feature\n",
    "    ### output : ary_test_EC_input\n",
    "    lst_id_test = [dict_label_test['id'] for dict_label_test in lst_dict_label_test]\n",
    "\n",
    "    ### just check\n",
    "    lst_id_test_2 = []\n",
    "    with open('{}{}.txt'.format(path_data, 'testing_id')) as f :\n",
    "        for line in f.readlines() :\n",
    "            lst_id_test_2 += [line.rstrip('\\n')]\n",
    "    for i in range(len(lst_id_test)) :\n",
    "        assert str(lst_id_test[i]) == str(lst_id_test_2[i]), 'error here'\n",
    "\n",
    "    lst_test_EC_input = []\n",
    "    for i, id in enumerate(lst_id_test) :\n",
    "        npy = np.load('{}testing_data/feat/{}.npy'.format(path_data, id))\n",
    "        lst_test_EC_input += [npy]\n",
    "    ary_test_EC_input = np.concatenate(lst_test_EC_input,axis=0).reshape(-1,80,4096)\n",
    "\n",
    "    ary_temp = np.zeros((len(ary_test_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    ary_test_DC_input = ary_temp\n",
    "    \n",
    "    print ('ary_test_EC_input.shape :')\n",
    "    print (ary_test_EC_input.shape)\n",
    "    print ('ary_test_DC_input.shape :')\n",
    "    print (ary_test_DC_input.shape)\n",
    "    \n",
    "### for peer review\n",
    "if peer_review_data_loading :\n",
    "    print ('peer review data is loading...')\n",
    "    with open('{}peer_review_id.txt'.format(path_data),'r') as f :\n",
    "        lst_id_peer_review = f.readlines()\n",
    "        for i,id in enumerate(lst_id_peer_review) :\n",
    "            lst_id_peer_review[i] = id.rstrip('\\n')\n",
    "    \n",
    "    lst_peer_review_EC_input = []\n",
    "    for i, id in enumerate(lst_id_peer_review) :\n",
    "        npy = np.load('{}peer_review/feat/{}.npy'.format(path_data, id))\n",
    "        lst_peer_review_EC_input += [npy]\n",
    "    ary_peer_review_EC_input = np.concatenate(lst_peer_review_EC_input,axis=0).reshape(-1,80,4096)\n",
    "\n",
    "    ary_temp = np.zeros((len(ary_peer_review_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    ary_peer_review_DC_input = ary_temp\n",
    "\n",
    "    print ('ary_peer_review_EC_input.shape :')\n",
    "    print (ary_peer_review_EC_input.shape)\n",
    "    print ('ary_peer_review_DC_input.shape :')\n",
    "    print (ary_peer_review_DC_input.shape)\n",
    "    \n",
    "print ('---data loading finished---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_pretrain(lang=lang) :\n",
    "\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = GRU(32,return_state=False, return_sequences=True, activation='selu')(EC_input)\n",
    "#     EC_output, EC_output_state = GRU(32,return_state=True, activation='selu')(EC_output)\n",
    "#     DC_input = Input(shape=(None,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_gru1 = GRU(32, return_sequences=True, activation='selu')\n",
    "#     DC_time_dense = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "\n",
    "#     DC_output = DC_gru1(DC_input_M, initial_state=EC_output_state)\n",
    "#     DC_output = DC_time_dense(DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_DC_only1(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = GRU(32,return_state=False, return_sequences=True, activation='selu')(EC_input)\n",
    "#     EC_output, EC_output_state = GRU(32,return_state=True, activation='selu')(EC_output)\n",
    "#     DC_input = Input(shape=(1,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_gru1 = GRU(32, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_time_dense = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "\n",
    "#     DC_output_state = EC_output_state\n",
    "#     DC_output = DC_input_M\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "#         DC_output, DC_output_state = DC_gru1(DC_output, initial_state=DC_output_state)\n",
    "#         DC_output = DC_time_dense(DC_output)\n",
    "#         lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pretrain(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_state=True, activation='selu')(EC_output)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(None,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = TimeDistributed(Dense(32))\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "    Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "    DC_output_state2 = EC_output_state\n",
    "#     DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "    DC_output = DC_dense_1(DC_output)\n",
    "    DC_output = Ba_output_1(DC_output)\n",
    "    DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "\n",
    "#     DC_output = Ba_output_2(DC_output)\n",
    "\n",
    "    DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "#         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "#         DC_output = Ba_output_3(DC_output)\n",
    "    DC_output = DC_dense_2(DC_output)\n",
    "#     lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### not work\n",
    "# def model_pretrain(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "# #     EC_output = BatchNormalization()(EC_input)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu', kernel_initializer='lecun_normal'), merge_mode='concat')(EC_input)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output, EC_output_state = GRU(64,return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "#     EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "#     DC_input = Input(shape=(None,lang.n_words))\n",
    "# #     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_dense_1 = TimeDistributed(Dense(64, activation='selu', kernel_initializer='lecun_normal'))\n",
    "#     DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "# #     Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "#     DC_output_state1 = EC_output_state\n",
    "# #     DC_output_state2 = EC_output_state\n",
    "# #     DC_output_state3 = EC_output_state\n",
    "#     DC_output = DC_input\n",
    "# #     lst_DC_output = []\n",
    "# #     for _ in range(lang.max_len_seq) :\n",
    "#     DC_output = DC_dense_1(DC_output)\n",
    "# #     DC_output = Ba_output_1(DC_output)\n",
    "#     DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "# #     DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "# #         DC_output = Ba_output_2(DC_output)\n",
    "# #         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "# #         DC_output = Ba_output_3(DC_output)\n",
    "#     DC_output = DC_dense_2(DC_output)\n",
    "# #     lst_DC_output += [DC_output]\n",
    "\n",
    "# #     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_DC_only1(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_state=True, activation='selu')(EC_output)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(1,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = TimeDistributed(Dense(32))\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "    Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "    DC_output_state2 = EC_output_state\n",
    "    DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input\n",
    "    lst_DC_output = []\n",
    "    for _ in range(lang.max_len_seq) :\n",
    "        DC_output = DC_dense_1(DC_output)\n",
    "        DC_output = Ba_output_1(DC_output)\n",
    "        DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "        DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "#         DC_output = Ba_output_2(DC_output)\n",
    "#         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "#         DC_output = Ba_output_3(DC_output)\n",
    "        DC_output = DC_dense_2(DC_output)\n",
    "        lst_DC_output += [DC_output]\n",
    "\n",
    "    DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_DC_only1(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "# #     EC_output = BatchNormalization()(EC_input)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output, EC_output_state = GRU(64,return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "#     EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "#     DC_input = Input(shape=(1,lang.n_words))\n",
    "# #     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_dense_1 = TimeDistributed(Dense(64, activation='selu', kernel_initializer='lecun_normal'))\n",
    "#     DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu', kernel_initializer='lecun_normal')\n",
    "# #     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "# #     Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "\n",
    "#     DC_output_state1 = EC_output_state\n",
    "# #     DC_output_state2 = EC_output_state\n",
    "# #     DC_output_state3 = EC_output_state\n",
    "#     DC_output = DC_input\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "#         DC_output = DC_dense_1(DC_output)\n",
    "# #         DC_output = Ba_output_1(DC_output)\n",
    "#         DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "# #         DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "# #         DC_output = Ba_output_2(DC_output)\n",
    "# #         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "# #         DC_output = Ba_output_3(DC_output)\n",
    "#         DC_output = DC_dense_2(DC_output)\n",
    "#         lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = BatchNormalization()(EC_input)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_sequences=True, return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(1,lang.n_words,))\n",
    "    DC_input_R = Reshape((lang.n_words,))(DC_input)\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = Dense(64, activation='selu', kernel_initializer='lecun_normal')\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = Dense(lang.n_words, activation='softmax')\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "#     DC_output_state2 = EC_output_state\n",
    "#     DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input_R\n",
    "#     print (DC_output)\n",
    "    lst_DC_output = []\n",
    "#     print (len(EC_output.shape))\n",
    "    for _ in range(lang.max_len_seq) :\n",
    "        DC_output = Reshape((lang.n_words,))(DC_output)\n",
    "        DC_output = DC_dense_1(DC_output)\n",
    "        DC_output_RV = RepeatVector(80)(DC_output)\n",
    "        EC_output = Multiply()([DC_output_RV,EC_output])\n",
    "        DC_output = Lambda(lambda x: K.mean(x,axis=1))(EC_output)\n",
    "        DC_output = Reshape((1,64))(DC_output)\n",
    "\n",
    "        DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "\n",
    "        DC_output = DC_dense_2(DC_output)\n",
    "        lst_DC_output += [DC_output]\n",
    "\n",
    "    DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ary_pred_to_df_ans(ary_pred, lst_id_test) :\n",
    "    ary_pred_argmax = np.argmax(ary_pred,axis=2)\n",
    "    lst_ans_numbers = ary_pred_argmax.tolist()\n",
    "    lst_ans_string = []\n",
    "    for ans_numbers in lst_ans_numbers :\n",
    "        lst_ans_string += [' '.join([lang.index2word[ans] for ans in ans_numbers]).split(' <EOS>')[0]]\n",
    "    df_ans = pd.DataFrame([lst_id_test,lst_ans_string]).T\n",
    "    return df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 80, 64)        792768      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 80, 64)        256         bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1, 5149)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 80, 64)        18624       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 1, 32)         164800      input_2[0][0]                    \n",
      "                                                                   time_distributed_2[0][0]         \n",
      "                                                                   time_distributed_2[1][0]         \n",
      "                                                                   time_distributed_2[2][0]         \n",
      "                                                                   time_distributed_2[3][0]         \n",
      "                                                                   time_distributed_2[4][0]         \n",
      "                                                                   time_distributed_2[5][0]         \n",
      "                                                                   time_distributed_2[6][0]         \n",
      "                                                                   time_distributed_2[7][0]         \n",
      "                                                                   time_distributed_2[8][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 80, 64)        256         bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 1, 32)         128         time_distributed_1[0][0]         \n",
      "                                                                   time_distributed_1[1][0]         \n",
      "                                                                   time_distributed_1[2][0]         \n",
      "                                                                   time_distributed_1[3][0]         \n",
      "                                                                   time_distributed_1[4][0]         \n",
      "                                                                   time_distributed_1[5][0]         \n",
      "                                                                   time_distributed_1[6][0]         \n",
      "                                                                   time_distributed_1[7][0]         \n",
      "                                                                   time_distributed_1[8][0]         \n",
      "                                                                   time_distributed_1[9][0]         \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      [(None, 64), (None, 6 24768       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      [(None, 1, 64), (None 18624       time_distributed_3[0][0]         \n",
      "                                                                   gru_3[0][1]                      \n",
      "                                                                   time_distributed_3[1][0]         \n",
      "                                                                   gru_4[0][1]                      \n",
      "                                                                   time_distributed_3[2][0]         \n",
      "                                                                   gru_4[1][1]                      \n",
      "                                                                   time_distributed_3[3][0]         \n",
      "                                                                   gru_4[2][1]                      \n",
      "                                                                   time_distributed_3[4][0]         \n",
      "                                                                   gru_4[3][1]                      \n",
      "                                                                   time_distributed_3[5][0]         \n",
      "                                                                   gru_4[4][1]                      \n",
      "                                                                   time_distributed_3[6][0]         \n",
      "                                                                   gru_4[5][1]                      \n",
      "                                                                   time_distributed_3[7][0]         \n",
      "                                                                   gru_4[6][1]                      \n",
      "                                                                   time_distributed_3[8][0]         \n",
      "                                                                   gru_4[7][1]                      \n",
      "                                                                   time_distributed_3[9][0]         \n",
      "                                                                   gru_4[8][1]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      [(None, 1, 64), (None 24768       gru_4[0][0]                      \n",
      "                                                                   gru_3[0][1]                      \n",
      "                                                                   gru_4[1][0]                      \n",
      "                                                                   gru_5[0][1]                      \n",
      "                                                                   gru_4[2][0]                      \n",
      "                                                                   gru_5[1][1]                      \n",
      "                                                                   gru_4[3][0]                      \n",
      "                                                                   gru_5[2][1]                      \n",
      "                                                                   gru_4[4][0]                      \n",
      "                                                                   gru_5[3][1]                      \n",
      "                                                                   gru_4[5][0]                      \n",
      "                                                                   gru_5[4][1]                      \n",
      "                                                                   gru_4[6][0]                      \n",
      "                                                                   gru_5[5][1]                      \n",
      "                                                                   gru_4[7][0]                      \n",
      "                                                                   gru_5[6][1]                      \n",
      "                                                                   gru_4[8][0]                      \n",
      "                                                                   gru_5[7][1]                      \n",
      "                                                                   gru_4[9][0]                      \n",
      "                                                                   gru_5[8][1]                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 1, 5149)       334685      gru_5[0][0]                      \n",
      "                                                                   gru_5[1][0]                      \n",
      "                                                                   gru_5[2][0]                      \n",
      "                                                                   gru_5[3][0]                      \n",
      "                                                                   gru_5[4][0]                      \n",
      "                                                                   gru_5[5][0]                      \n",
      "                                                                   gru_5[6][0]                      \n",
      "                                                                   gru_5[7][0]                      \n",
      "                                                                   gru_5[8][0]                      \n",
      "                                                                   gru_5[9][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 10, 5149)      0           time_distributed_2[0][0]         \n",
      "                                                                   time_distributed_2[1][0]         \n",
      "                                                                   time_distributed_2[2][0]         \n",
      "                                                                   time_distributed_2[3][0]         \n",
      "                                                                   time_distributed_2[4][0]         \n",
      "                                                                   time_distributed_2[5][0]         \n",
      "                                                                   time_distributed_2[6][0]         \n",
      "                                                                   time_distributed_2[7][0]         \n",
      "                                                                   time_distributed_2[8][0]         \n",
      "                                                                   time_distributed_2[9][0]         \n",
      "====================================================================================================\n",
      "Total params: 1,379,677\n",
      "Trainable params: 1,379,357\n",
      "Non-trainable params: 320\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "loading and seting weight...\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "loading model_weight finished...\n"
     ]
    }
   ],
   "source": [
    "### main\n",
    "# MCP = keras.callbacks.ModelCheckpoint('./model/{}_{}.h5'.format(model_name,k), monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "ES = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "if teacherForce :\n",
    "    model = model_pretrain(lang)\n",
    "else :\n",
    "    if attention :\n",
    "        model = model_attention(lang)\n",
    "    else :\n",
    "        model = model_DC_only1(lang)\n",
    "        if do_training :\n",
    "            ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "            ary_temp[:,0,0] = 1\n",
    "            ary_train_DC_input_2 = ary_temp\n",
    "\n",
    "    \n",
    "if loading_model :\n",
    "    print ('loading and seting weight...')\n",
    "    if special_task :\n",
    "        with open('./model_weight/lst_layer_weights_special.pkl'.format(i), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    elif teacherForce :\n",
    "        with open('./model_weight/lst_layer_weights_0.pkl'.format(i), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    else :\n",
    "#         with open('./weights/lst_layer_weights_noTeacher_special.pkl'.format(i), \"rb\") as f:\n",
    "        with open('./model_weight/{}'.format(load_model_weight_name), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    len_model_layer = len(model.layers)\n",
    "    for i, layer in enumerate(model.layers) :\n",
    "        if i > 11 :\n",
    "            break\n",
    "        elif i < 7 :\n",
    "            layer.trainable = False\n",
    "        print (i)\n",
    "        layer.set_weights(lst_layer_weights[i])\n",
    "    print ('loading model_weight finished...')\n",
    "\n",
    "if do_training :\n",
    "    if teacherForce :\n",
    "        log = model.fit([ary_train_EC_input, ary_train_DC_input],ary_train_DC_output, epochs=500, batch_size=256, validation_split=0., callbacks=[]) \n",
    "    else :\n",
    "        log = model.fit([ary_train_EC_input, ary_train_DC_input_2],ary_train_DC_output, epochs=500, batch_size=256, validation_split=0., callbacks=[]) \n",
    "    df_log = log.history\n",
    "    #fig = keras_log_plot(df_log)\n",
    "    \n",
    "if save_model :\n",
    "    print ('saving model...')\n",
    "    if not os.path.isdir('./model_weight') :\n",
    "        os.mkdir('./model_weight')\n",
    "    k = 0\n",
    "    while 1 :\n",
    "        if os.path.isfile('./model_weight/lst_layer_weights_{}.pkl'.format(k)) :\n",
    "            k += 1\n",
    "        else :\n",
    "            break\n",
    "    lst_weights = []\n",
    "    for i, layer in enumerate(model.layers) :\n",
    "        lst_weights += [layer.get_weights()] # list of numpy arrays\n",
    "        #np.save(ary_weights,'./weight/layer{}'.format(i))\n",
    "    with open('./model_weight/lst_layer_weights_{}.pkl'.format(k), \"wb\") as f:\n",
    "        pickle.dump(lst_weights,f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : \n",
      "                          0                              1\n",
      "0     ScdUht-pM6s_53_63.avi            A woman is a into a\n",
      "1     wkgGxsuNVSg_34_41.avi               A man is a a the\n",
      "2     BtQtRGI0F2Q_15_20.avi               A man is a a the\n",
      "3      k06Ge9ANKM8_5_16.avi         A cat is playing a the\n",
      "4   sZf3VDsdDPM_107_114.avi                  A girl is a a\n",
      "5      shPymuahrsc_5_12.avi        A panda is playing in a\n",
      "6      XOAgUVVwKEA_8_20.avi         A baby is her her from\n",
      "7       ufFT2BWh3BQ_0_8.avi                A panda is is a\n",
      "8     5YJaS2Eswg0_22_26.avi                 A man is a a a\n",
      "9     lw7pTwpx0K0_38_48.avi          A man is a into of of\n",
      "10  UbmZAe5u5FI_132_141.avi  A woman is shrimp shrimp into\n",
      "11      xCFCXzDUGjY_5_9.avi                   A man is a a\n",
      "12    He7Ge7Sogrk_47_70.avi                 A man is a a a\n",
      "13  tJHUH9tpqPg_113_118.avi                A woman is a in\n",
      "14     n016q1w8Q30_2_11.avi          A person is slicing a\n",
      "15     RjpbFlOHFps_8_25.avi                   A man is a a\n",
      "16     6JnGBs88sL0_4_10.avi                 A woman is a a\n",
      "17  EpMuCrbxE8A_107_115.avi      A man is playing a guitar\n",
      "18    HAjwXjwN9-A_16_24.avi             A man is a the the\n",
      "19    4xVGpDmA4lE_23_33.avi                 A man is a a a\n",
      "20    k5OKBX2e7xA_19_32.avi                 A man is a the\n",
      "21    Jag7oTemldY_12_25.avi               A man is a a the\n",
      "22  8MVo7fje_oE_125_130.avi              A man is a in the\n",
      "23     bqMmyY1ImkI_0_14.avi              A woman is a in a\n",
      "24    jTnrm338_KY_34_42.avi              A woman is a in a\n",
      "25    UdcObAQ5OOM_15_30.avi                 A man is a a a\n",
      "26    4PcL6-mjRNk_11_18.avi                 A man is a a a\n",
      "27     3qqEKTPxLNs_1_15.avi                  A baby is a a\n",
      "28  glrijRGnmc0_211_215.avi                 A man is a a a\n",
      "29  q7pOFn8s4zc_263_273.avi             A man is a the the\n",
      "..                      ...                            ...\n",
      "70     qvg9eM4Hmzk_4_10.avi                 A man is a a a\n",
      "71     5HAf_INrFy0_3_25.avi                   A man is a a\n",
      "72  YmXCfQm0_CA_277_284.avi                   A man is a a\n",
      "73    88DOMJ11q2M_84_87.avi           A man is the the the\n",
      "74     NUYu9c9XsgY_7_21.avi       A man is a into into the\n",
      "75    N3A7944_UJw_63_70.avi                   A man is a a\n",
      "76     uJPupV4oLZ0_4_12.avi                 A baby is a in\n",
      "77     cnsjm3fNEec_4_10.avi                   A man is a a\n",
      "78  J_evFB7RIKA_104_120.avi           A woman is slicing a\n",
      "79     g1Gldu1KS44_8_14.avi                  A dog is a in\n",
      "80    s1ZABV7AQdA_38_48.avi              A man are a a the\n",
      "81    tcxhOGyrCtI_15_21.avi        A cat is playing in the\n",
      "82     inzk2fTUe1w_1_15.avi                 A man is a a a\n",
      "83    j2Dhf-xFUxU_13_20.avi              A woman is a into\n",
      "84     MTjrZthHwJQ_2_11.avi              A dog is a in the\n",
      "85      J---aiyznGQ_0_6.avi                   A man is a a\n",
      "86  ZbtpcGi2DWY_161_170.avi           A person is a in the\n",
      "87    RSx5G0_xH48_12_17.avi         A cat is playing a the\n",
      "88     ecm9gf2Pgkc_1_24.avi                   A man is a a\n",
      "89    pW9DFPqoIsI_26_50.avi            A woman is a a into\n",
      "90    N2Cm0SLr0ZE_18_29.avi                   A boy is a a\n",
      "91      sJSmRik2c-c_1_7.avi                   A man is a a\n",
      "92  zv2RIbUsnSw_335_341.avi               A man is a a the\n",
      "93    aM-RcQj0a7I_37_55.avi         A man is a in the meat\n",
      "94    TZ860P4iTaM_15_28.avi        A cat is playing in the\n",
      "95     lo4KcsBN--A_0_10.avi               A man is a a the\n",
      "96     u4T76jsPin0_0_11.avi                A men are a the\n",
      "97    7HcYJKMxpcg_20_28.avi                 A man is a a a\n",
      "98     CGllPWAwmUo_1_15.avi                 A man is a a a\n",
      "99  WTf5EgVY5uU_124_128.avi       A woman is eggs into the\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "test : \n",
      "       0                 1\n",
      "0  1.avi  A man is a a the\n",
      "1  2.avi      A man is a a\n",
      "2  3.avi    A man is a a a\n",
      "3  4.avi      A man is a a\n",
      "4  5.avi  A man is a a the\n"
     ]
    }
   ],
   "source": [
    "### prediction\n",
    "\n",
    "### train data prediction\n",
    "if after_teacherForce_test :\n",
    "    ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,0] = 1\n",
    "    ary_train_DC_input = ary_temp\n",
    "\n",
    "    if train_data_loading :\n",
    "        if teacherForce :\n",
    "            ary_pred_train = model.predict([ary_train_EC_input, ary_train_DC_input])\n",
    "        else :\n",
    "            ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "            ary_temp[:,0,0] = 1\n",
    "            ary_pred_train = model.predict([ary_train_EC_input, ary_temp])\n",
    "\n",
    "        df_ans_train = ary_pred_to_df_ans(ary_pred_train, lst_id_train)\n",
    "        print ('train : ')\n",
    "        print (df_ans_train.iloc[:5])\n",
    "\n",
    "### testing data prediction\n",
    "# model_test = model_DC_only1(lang)\n",
    "# ary_pred_test = model_test.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "ary_pred_test = model.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "\n",
    "df_ans = ary_pred_to_df_ans(ary_pred_test, lst_id_test)\n",
    "df_ans.to_csv(\"./{}\".format(str_output), index=False, header=False)\n",
    "print ('test : ')\n",
    "print (df_ans)\n",
    "\n",
    "### testing data prediction\n",
    "# model_test = model_DC_only1(lang)\n",
    "# ary_pred_test = model_test.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "ary_pred_test = model.predict([ary_peer_review_EC_input, ary_peer_review_DC_input])\n",
    "\n",
    "df_ans = ary_pred_to_df_ans(ary_pred_test, lst_id_peer_review)\n",
    "df_ans.to_csv(\"./{}\".format(str_output_peer_review), index=False, header=False)\n",
    "print ('test : ')\n",
    "print (df_ans)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ary_sample_output_testset = np.loadtxt(open(path_data + \"sample_output_testset.txt\", \"rb\"), delimiter=\",\")\n",
    "# for i, name in enumerate(ary_sample_output_testset[:][0]) :\n",
    "#     print (name)\n",
    "\n",
    "### for special task\n",
    "if special_task :\n",
    "    lst_id_special = ['klteYv1Uv9A_27_33.avi','5YJaS2Eswg0_22_26.avi','UbmZAe5u5FI_132_141.avi','JntMAcTlOF0_50_70.avi','tJHUH9tpqPg_113_118.avi']\n",
    "    lst_ans_pair = []\n",
    "    for i,id in enumerate(lst_id_test) :\n",
    "        if id in lst_id_special :\n",
    "            ans = lst_ans_string_test[i].split(' <EOS>')[0]\n",
    "            lst_ans_pair += [[id,ans]]\n",
    "    \n",
    "    lst_ans_pair_sort = []\n",
    "\n",
    "    for id in lst_id_special :\n",
    "        for ans_pair in lst_ans_pair :\n",
    "            if id == ans_pair[0] :\n",
    "                lst_ans_pair_sort += [ans_pair]\n",
    "    df_ans = pd.DataFrame(lst_ans_pair_sort)\n",
    "    print (df_ans)\n",
    "    df_ans.to_csv(\"./{}\".format(str_output), index=False, header=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
