{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "# def init():\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     session = tf.Session(config=config)\n",
    "#     keras.backend.tensorflow_backend.set_session(session)\n",
    "# init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path and parameter\n",
    "path_data = './MLDS_hw2_data/'\n",
    "str_output = 'output_testset.txt'\n",
    "str_output_peer_review = 'output_peer_review.txt'\n",
    "\n",
    "### highest BLEU score model\n",
    "# load_model_weight_name = 'lst_layer_weights_10_28_73.pkl'\n",
    "### better output model\n",
    "load_model_weight_name = 'lst_layer_weights_8_279_603_15epo.pkl'\n",
    "# load_model_weight_name = 'lst_layer_weights_18.pkl'\n",
    "\n",
    "model_name = 's2s'\n",
    "\n",
    "max_seq = 8\n",
    "n_caption = -1\n",
    "only_one_caption = 1\n",
    "\n",
    "loading_model = 1\n",
    "do_training = 0\n",
    "teacherForce = 0\n",
    "attention = 0\n",
    "no_attention = 0\n",
    "# after_teacherForce_train = 0\n",
    "after_teacherForce_test = 0\n",
    "\n",
    "save_model = 0\n",
    "train_data_loading = 0\n",
    "test_data_loading = 1\n",
    "peer_review_data_loading = 1\n",
    "\n",
    "special_task = 0\n",
    "\n",
    "if len(sys.argv) > 1 :\n",
    "    path_data = sys.argv[1]\n",
    "    str_output = sys.argv[2]\n",
    "    str_output_peer_review = sys.argv[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<padding>\": 0, \"<BOS>\": 1, \"<EOS>\" :2}\n",
    "        self.word2count = {\"<padding>\" : 0, \"<BOS>\": 0, \"<EOS>\" : 0}\n",
    "        self.index2word = {0:\"<padding>\", 1: \"<BOS>\", 2: \"<EOS>\"}\n",
    "        self.n_words = 3  # Count padding and BOS and EOS\n",
    "        self.max_len_seq = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        lst_word = sentence.split()\n",
    "        if len(lst_word) > max_seq :\n",
    "            return 0\n",
    "        elif self.max_len_seq < len(lst_word) :\n",
    "            self.max_len_seq = len(lst_word)\n",
    "        for word in lst_word :\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_log_plot(log) :\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    fig = plt.figure(1,figsize=(20,10))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(log['acc'], label='train_acc')\n",
    "    plt.plot(log['val_acc'], label='val_acc')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('acc', fontsize=20, color='black')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(log['loss'], label='train_loss')\n",
    "    plt.plot(log['val_loss'], label='val_loss')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('loss', fontsize=20, color='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_init(lst_dict_label_train) :\n",
    "    lang = Lang()\n",
    "    for dict_label_train in lst_dict_label_train :\n",
    "        for sentence in dict_label_train['caption'] :\n",
    "            sentence = sentence[:-1] + ' <EOS>'\n",
    "            lang.addSentence(sentence) # remove \".\"\n",
    "    print ('lang.n_words : ' + str(lang.n_words))\n",
    "    print ('lang.max_len_seq : ' + str(lang.max_len_seq))\n",
    "    assert lang.max_len_seq == max_seq, 'error here'\n",
    "    return lang\n",
    "# assert lang.word2count['<BOS>'] == lang.word2count['<EOS>'], number of \"<BOS>\" != number of \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index to one-hot\n",
    "def Str2OneHot(sentence, n_class, dict_map, max_len_seq) :\n",
    "    ### sentence to lst_index_sentence\n",
    "    sentence = sentence[:-1] + ' <EOS>'\n",
    "    lst_word = sentence.split()\n",
    "    ary_oneHot = np.zeros((max_len_seq,n_class))\n",
    "    lst_index_word = [dict_map[word] for word in lst_word]\n",
    "    ary_oneHot[range(len(lst_word)),lst_index_word] = 1\n",
    "    ary_oneHot[range(len(lst_word),len(ary_oneHot)),:] = 0.0 # others all set <padding>\n",
    "    ary_oneHot[range(len(lst_word),len(ary_oneHot)),0] = 1.0 # others all set <padding>\n",
    "    return ary_oneHot\n",
    "    \n",
    "### just for test\n",
    "# ary = Str2OneHot('A woman goes under a horse.', lang.n_words, lang.word2index, lang.max_len_seq)\n",
    "# print (ary.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_label.json : \n",
      "caption : \n",
      "['A woman goes under a horse.', 'A woman crawls under a horse and gets a surprise.']\n",
      "id : \n",
      "xBePrplM4OA_6_18.avi\n",
      "lang.n_words : 4012\n",
      "lang.max_len_seq : 8\n",
      "train data is loading...\n",
      "ary_train_EC_input.shape :\n",
      "(1443, 80, 4096)\n",
      "ary_train_DC_output.shape :\n",
      "(1443, 8, 4012)\n",
      "ary_train_DC_input.shape :\n",
      "(1443, 1, 4012)\n",
      "test data is loading...\n",
      "ary_test_EC_input.shape :\n",
      "(100, 80, 4096)\n",
      "ary_test_DC_input.shape :\n",
      "(100, 1, 4012)\n",
      "peer review data is loading...\n",
      "ary_peer_review_EC_input.shape :\n",
      "(5, 80, 4096)\n",
      "ary_peer_review_DC_input.shape :\n",
      "(5, 1, 4012)\n",
      "---data loading finished---\n"
     ]
    }
   ],
   "source": [
    "### preprocessing\n",
    "\n",
    "### for training data\n",
    "### load lst_dict_label_train\n",
    "\n",
    "with open('{}training_label.json'.format(path_data)) as f :\n",
    "    lst_dict_label_train = json.load(f)\n",
    "print ('\\ntraining_label.json : ')\n",
    "print ('caption : \\n' + str(lst_dict_label_train[0]['caption'][:2]))\n",
    "print ('id : \\n' + str(lst_dict_label_train[0]['id']))\n",
    "\n",
    "lang = lang_init(lst_dict_label_train)\n",
    "\n",
    "if train_data_loading :\n",
    "    print ('train data is loading...')\n",
    "    ### pair caption and vedio feature\n",
    "    ### output : ary_train_EC_input\n",
    "    ###          ary_train_DC_output\n",
    "    ###          ary_train_DC_input\n",
    "    lst_id_train = [dict_label_train['id'] for dict_label_train in lst_dict_label_train]\n",
    "    lst_train_EC_input = []\n",
    "    lst_train_DC_output = []\n",
    "    for i, id in enumerate(lst_id_train) :\n",
    "        lst_npy = np.load('{}training_data/feat/{}.npy'.format(path_data, id)).tolist()\n",
    "        for caption in lst_dict_label_train[i]['caption'][:n_caption] :\n",
    "            if len(caption.split()) >= max_seq : # note >=\n",
    "                continue\n",
    "            lst_train_EC_input += [lst_npy]\n",
    "            lst_ary_OneHot = Str2OneHot(caption, lang.n_words, lang.word2index, lang.max_len_seq).tolist()\n",
    "            lst_train_DC_output += [lst_ary_OneHot]\n",
    "            if only_one_caption :\n",
    "                break\n",
    "    assert len(lst_train_EC_input) == len(lst_train_DC_output), \"??\"\n",
    "    ary_train_EC_input = np.asarray(lst_train_EC_input).reshape(-1,80,4096)\n",
    "    del lst_train_EC_input\n",
    "    ary_train_DC_output = np.asarray(lst_train_DC_output).reshape(-1,lang.max_len_seq,lang.n_words)\n",
    "    del lst_train_DC_output\n",
    "\n",
    "    ### add \"<BOS>\" to ary_train_DC_input\n",
    "    ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    if teacherForce :\n",
    "        ary_train_DC_input = np.concatenate([ary_temp,ary_train_DC_output[:,:-1]],axis=1)\n",
    "    else :\n",
    "        ary_train_DC_input = ary_temp\n",
    "\n",
    "    print ('ary_train_EC_input.shape :')\n",
    "    print (ary_train_EC_input.shape)\n",
    "    print ('ary_train_DC_output.shape :')\n",
    "    print (ary_train_DC_output.shape)\n",
    "    print ('ary_train_DC_input.shape :')\n",
    "    print (ary_train_DC_input.shape)\n",
    "\n",
    "### for testing data\n",
    "if test_data_loading :\n",
    "    print ('test data is loading...')\n",
    "    with open('{}testing_label.json'.format(path_data)) as f :\n",
    "        lst_dict_label_test = json.load(f)\n",
    "    ### pair caption and vedio feature\n",
    "    ### output : ary_test_EC_input\n",
    "    lst_id_test = [dict_label_test['id'] for dict_label_test in lst_dict_label_test]\n",
    "\n",
    "    ### just check\n",
    "    lst_id_test_2 = []\n",
    "    with open('{}{}.txt'.format(path_data, 'testing_id')) as f :\n",
    "        for line in f.readlines() :\n",
    "            lst_id_test_2 += [line.rstrip('\\n')]\n",
    "    for i in range(len(lst_id_test)) :\n",
    "        assert str(lst_id_test[i]) == str(lst_id_test_2[i]), 'error here'\n",
    "\n",
    "    lst_test_EC_input = []\n",
    "    for i, id in enumerate(lst_id_test) :\n",
    "        npy = np.load('{}testing_data/feat/{}.npy'.format(path_data, id))\n",
    "        lst_test_EC_input += [npy]\n",
    "    ary_test_EC_input = np.concatenate(lst_test_EC_input,axis=0).reshape(-1,80,4096)\n",
    "\n",
    "    ary_temp = np.zeros((len(ary_test_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    ary_test_DC_input = ary_temp\n",
    "    \n",
    "    print ('ary_test_EC_input.shape :')\n",
    "    print (ary_test_EC_input.shape)\n",
    "    print ('ary_test_DC_input.shape :')\n",
    "    print (ary_test_DC_input.shape)\n",
    "    \n",
    "### for peer review\n",
    "if peer_review_data_loading :\n",
    "    print ('peer review data is loading...')\n",
    "    with open('{}peer_review_id.txt'.format(path_data),'r') as f :\n",
    "        lst_id_peer_review = f.readlines()\n",
    "        for i,id in enumerate(lst_id_peer_review) :\n",
    "            lst_id_peer_review[i] = id.rstrip('\\n')\n",
    "    \n",
    "    lst_peer_review_EC_input = []\n",
    "    for i, id in enumerate(lst_id_peer_review) :\n",
    "        npy = np.load('{}peer_review/feat/{}.npy'.format(path_data, id))\n",
    "        lst_peer_review_EC_input += [npy]\n",
    "    ary_peer_review_EC_input = np.concatenate(lst_peer_review_EC_input,axis=0).reshape(-1,80,4096)\n",
    "\n",
    "    ary_temp = np.zeros((len(ary_peer_review_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,lang.word2index['<BOS>']] = 1\n",
    "    ary_peer_review_DC_input = ary_temp\n",
    "\n",
    "    print ('ary_peer_review_EC_input.shape :')\n",
    "    print (ary_peer_review_EC_input.shape)\n",
    "    print ('ary_peer_review_DC_input.shape :')\n",
    "    print (ary_peer_review_DC_input.shape)\n",
    "    \n",
    "print ('---data loading finished---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_pretrain(lang=lang) :\n",
    "\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = GRU(32,return_state=False, return_sequences=True, activation='selu')(EC_input)\n",
    "#     EC_output, EC_output_state = GRU(32,return_state=True, activation='selu')(EC_output)\n",
    "#     DC_input = Input(shape=(None,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_gru1 = GRU(32, return_sequences=True, activation='selu')\n",
    "#     DC_time_dense = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "\n",
    "#     DC_output = DC_gru1(DC_input_M, initial_state=EC_output_state)\n",
    "#     DC_output = DC_time_dense(DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_DC_only1(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = GRU(32,return_state=False, return_sequences=True, activation='selu')(EC_input)\n",
    "#     EC_output, EC_output_state = GRU(32,return_state=True, activation='selu')(EC_output)\n",
    "#     DC_input = Input(shape=(1,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_gru1 = GRU(32, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_time_dense = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "\n",
    "#     DC_output_state = EC_output_state\n",
    "#     DC_output = DC_input_M\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "#         DC_output, DC_output_state = DC_gru1(DC_output, initial_state=DC_output_state)\n",
    "#         DC_output = DC_time_dense(DC_output)\n",
    "#         lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pretrain(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_state=True, activation='selu')(EC_output)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(None,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = TimeDistributed(Dense(32))\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "    Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "    DC_output_state2 = EC_output_state\n",
    "#     DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "    DC_output = DC_dense_1(DC_output)\n",
    "    DC_output = Ba_output_1(DC_output)\n",
    "    DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "\n",
    "#     DC_output = Ba_output_2(DC_output)\n",
    "\n",
    "    DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "#         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "#         DC_output = Ba_output_3(DC_output)\n",
    "    DC_output = DC_dense_2(DC_output)\n",
    "#     lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### not work\n",
    "# def model_pretrain(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "# #     EC_output = BatchNormalization()(EC_input)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu', kernel_initializer='lecun_normal'), merge_mode='concat')(EC_input)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output, EC_output_state = GRU(64,return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "#     EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "#     DC_input = Input(shape=(None,lang.n_words))\n",
    "# #     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_dense_1 = TimeDistributed(Dense(64, activation='selu', kernel_initializer='lecun_normal'))\n",
    "#     DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "# #     Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "#     DC_output_state1 = EC_output_state\n",
    "# #     DC_output_state2 = EC_output_state\n",
    "# #     DC_output_state3 = EC_output_state\n",
    "#     DC_output = DC_input\n",
    "# #     lst_DC_output = []\n",
    "# #     for _ in range(lang.max_len_seq) :\n",
    "#     DC_output = DC_dense_1(DC_output)\n",
    "# #     DC_output = Ba_output_1(DC_output)\n",
    "#     DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "# #     DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "# #         DC_output = Ba_output_2(DC_output)\n",
    "# #         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "# #         DC_output = Ba_output_3(DC_output)\n",
    "#     DC_output = DC_dense_2(DC_output)\n",
    "# #     lst_DC_output += [DC_output]\n",
    "\n",
    "# #     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_DC_only1(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "    EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_state=True, activation='selu')(EC_output)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(1,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = TimeDistributed(Dense(32))\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "    Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "#     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "    DC_output_state2 = EC_output_state\n",
    "    DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input\n",
    "    lst_DC_output = []\n",
    "    for _ in range(lang.max_len_seq) :\n",
    "        DC_output = DC_dense_1(DC_output)\n",
    "        DC_output = Ba_output_1(DC_output)\n",
    "        DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "        DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "#         DC_output = Ba_output_2(DC_output)\n",
    "#         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "#         DC_output = Ba_output_3(DC_output)\n",
    "        DC_output = DC_dense_2(DC_output)\n",
    "        lst_DC_output += [DC_output]\n",
    "\n",
    "    DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_DC_only1(lang=lang) :\n",
    "#     EC_input = Input(shape=(80,4096))\n",
    "# #     EC_output = BatchNormalization()(EC_input)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "# #     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "# #     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output, EC_output_state = GRU(64,return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "#     EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "#     DC_input = Input(shape=(1,lang.n_words))\n",
    "# #     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "#     DC_dense_1 = TimeDistributed(Dense(64, activation='selu', kernel_initializer='lecun_normal'))\n",
    "#     DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "# #     DC_gru2 = GRU(64, return_sequences=True, return_state=True, activation='selu', kernel_initializer='lecun_normal')\n",
    "# #     DC_gru3 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "#     DC_dense_2 = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "# #     Ba_output_1 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_2 = TimeDistributed(BatchNormalization())\n",
    "# #     Ba_output_3 = TimeDistributed(BatchNormalization())\n",
    "\n",
    "\n",
    "#     DC_output_state1 = EC_output_state\n",
    "# #     DC_output_state2 = EC_output_state\n",
    "# #     DC_output_state3 = EC_output_state\n",
    "#     DC_output = DC_input\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "#         DC_output = DC_dense_1(DC_output)\n",
    "# #         DC_output = Ba_output_1(DC_output)\n",
    "#         DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "# #         DC_output, DC_output_state2 = DC_gru2(DC_output, initial_state=DC_output_state2)\n",
    "# #         DC_output = Ba_output_2(DC_output)\n",
    "# #         DC_output, DC_output_state3 = DC_gru3(DC_output, initial_state=DC_output_state3)\n",
    "# #         DC_output = Ba_output_3(DC_output)\n",
    "#         DC_output = DC_dense_2(DC_output)\n",
    "#         lst_DC_output += [DC_output]\n",
    "\n",
    "#     DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "#     model = Model([EC_input,DC_input],DC_output)\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = BatchNormalization()(EC_input)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_sequences=True, return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(1,lang.n_words,))\n",
    "    DC_input_R = Reshape((lang.n_words,))(DC_input)\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = Dense(64, activation='selu', kernel_initializer='lecun_normal')\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = Dense(lang.n_words, activation='softmax')\n",
    "\n",
    "    DC_output_state1 = EC_output_state\n",
    "#     DC_output_state2 = EC_output_state\n",
    "#     DC_output_state3 = EC_output_state\n",
    "    DC_output = DC_input_R\n",
    "#     print (DC_output)\n",
    "    lst_DC_output = []\n",
    "#     print (len(EC_output.shape))\n",
    "    for _ in range(lang.max_len_seq) :\n",
    "        DC_output = Reshape((lang.n_words,))(DC_output)\n",
    "        DC_output = DC_dense_1(DC_output)\n",
    "        DC_output_RV = RepeatVector(80)(DC_output)\n",
    "        EC_output = Multiply()([DC_output_RV,EC_output])\n",
    "        DC_output = Lambda(lambda x: K.mean(x,axis=1))(EC_output)\n",
    "        DC_output = Reshape((1,64))(DC_output)\n",
    "\n",
    "        DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "\n",
    "        DC_output = DC_dense_2(DC_output)\n",
    "        lst_DC_output += [DC_output]\n",
    "\n",
    "    DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_no_attention(lang=lang) :\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "#     EC_output = BatchNormalization()(EC_input)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_input)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "#     EC_output = Bidirectional(GRU(32,return_state=False, return_sequences=True, activation='selu'), merge_mode='concat')(EC_output)\n",
    "#     EC_output = BatchNormalization()(EC_output)\n",
    "    EC_output, EC_output_state = GRU(64,return_sequences=True, return_state=True, activation='selu', kernel_initializer='lecun_normal')(EC_input)\n",
    "    EC_output_stage = BatchNormalization()(EC_output_state)\n",
    "    DC_input = Input(shape=(1,lang.n_words))\n",
    "#     DC_input_M = Masking(mask_value=0.0)(DC_input)\n",
    "\n",
    "    DC_dense_1 = TimeDistributed(Dense(64, activation='selu', kernel_initializer='lecun_normal'))\n",
    "    DC_gru1 = GRU(64, return_sequences=True, return_state=True, activation='selu')\n",
    "    DC_dense_2 = Dense(lang.n_words, activation='softmax')\n",
    "    \n",
    "    DC_output_state1 = EC_output_state\n",
    "    DC_output = DC_input\n",
    "    lst_DC_output = []\n",
    "    for _ in range(lang.max_len_seq) :\n",
    "        DC_output = DC_dense_1(DC_output)\n",
    "        DC_output, DC_output_state1 = DC_gru1(DC_output, initial_state=DC_output_state1)\n",
    "        DC_output = DC_dense_2(DC_output)\n",
    "        lst_DC_output += [DC_output]\n",
    "\n",
    "    DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ary_pred_to_df_ans(ary_pred, lst_id_test) :\n",
    "    ary_pred_argmax = np.argmax(ary_pred,axis=2)\n",
    "    lst_ans_numbers = ary_pred_argmax.tolist()\n",
    "    lst_ans_string = []\n",
    "    for ans_numbers in lst_ans_numbers :\n",
    "        lst_ans_string += [' '.join([lang.index2word[ans] for ans in ans_numbers]).split(' <EOS>')[0]]\n",
    "    df_ans = pd.DataFrame([lst_id_test,lst_ans_string]).T\n",
    "    return df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_35 (InputLayer)            (None, 1, 4012)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)             (None, 4012)          0           input_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)             (None, 4012)          0           reshape_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 64)            256832      reshape_19[0][0]                 \n",
      "                                                                   reshape_21[0][0]                 \n",
      "                                                                   reshape_23[0][0]                 \n",
      "                                                                   reshape_25[0][0]                 \n",
      "                                                                   reshape_27[0][0]                 \n",
      "                                                                   reshape_29[0][0]                 \n",
      "                                                                   reshape_31[0][0]                 \n",
      "                                                                   reshape_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_9 (RepeatVector)   (None, 80, 64)        0           dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "gru_34 (GRU)                     [(None, 80, 64), (Non 798912      input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)            (None, 80, 64)        0           repeat_vector_9[0][0]            \n",
      "                                                                   gru_34[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 64)            0           multiply_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)             (None, 1, 64)         0           lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "gru_35 (GRU)                     [(None, 1, 64), (None 24768       reshape_20[0][0]                 \n",
      "                                                                   gru_34[0][1]                     \n",
      "                                                                   reshape_22[0][0]                 \n",
      "                                                                   gru_35[0][1]                     \n",
      "                                                                   reshape_24[0][0]                 \n",
      "                                                                   gru_35[1][1]                     \n",
      "                                                                   reshape_26[0][0]                 \n",
      "                                                                   gru_35[2][1]                     \n",
      "                                                                   reshape_28[0][0]                 \n",
      "                                                                   gru_35[3][1]                     \n",
      "                                                                   reshape_30[0][0]                 \n",
      "                                                                   gru_35[4][1]                     \n",
      "                                                                   reshape_32[0][0]                 \n",
      "                                                                   gru_35[5][1]                     \n",
      "                                                                   reshape_34[0][0]                 \n",
      "                                                                   gru_35[6][1]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 1, 4012)       260780      gru_35[0][0]                     \n",
      "                                                                   gru_35[1][0]                     \n",
      "                                                                   gru_35[2][0]                     \n",
      "                                                                   gru_35[3][0]                     \n",
      "                                                                   gru_35[4][0]                     \n",
      "                                                                   gru_35[5][0]                     \n",
      "                                                                   gru_35[6][0]                     \n",
      "                                                                   gru_35[7][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)             (None, 4012)          0           dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_10 (RepeatVector)  (None, 80, 64)        0           dense_33[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)           (None, 80, 64)        0           repeat_vector_10[0][0]           \n",
      "                                                                   multiply_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 64)            0           multiply_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)             (None, 1, 64)         0           lambda_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)             (None, 4012)          0           dense_34[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_11 (RepeatVector)  (None, 80, 64)        0           dense_33[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)           (None, 80, 64)        0           repeat_vector_11[0][0]           \n",
      "                                                                   multiply_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 64)            0           multiply_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)             (None, 1, 64)         0           lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)             (None, 4012)          0           dense_34[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_12 (RepeatVector)  (None, 80, 64)        0           dense_33[3][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)           (None, 80, 64)        0           repeat_vector_12[0][0]           \n",
      "                                                                   multiply_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (None, 64)            0           multiply_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)             (None, 1, 64)         0           lambda_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)             (None, 4012)          0           dense_34[3][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_13 (RepeatVector)  (None, 80, 64)        0           dense_33[4][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)           (None, 80, 64)        0           repeat_vector_13[0][0]           \n",
      "                                                                   multiply_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (None, 64)            0           multiply_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)             (None, 1, 64)         0           lambda_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)             (None, 4012)          0           dense_34[4][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_14 (RepeatVector)  (None, 80, 64)        0           dense_33[5][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)           (None, 80, 64)        0           repeat_vector_14[0][0]           \n",
      "                                                                   multiply_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (None, 64)            0           multiply_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)             (None, 1, 64)         0           lambda_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)             (None, 4012)          0           dense_34[5][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_15 (RepeatVector)  (None, 80, 64)        0           dense_33[6][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)           (None, 80, 64)        0           repeat_vector_15[0][0]           \n",
      "                                                                   multiply_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (None, 64)            0           multiply_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)             (None, 1, 64)         0           lambda_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)             (None, 4012)          0           dense_34[6][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_16 (RepeatVector)  (None, 80, 64)        0           dense_33[7][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)           (None, 80, 64)        0           repeat_vector_16[0][0]           \n",
      "                                                                   multiply_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (None, 64)            0           multiply_16[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)             (None, 1, 64)         0           lambda_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (None, 8, 4012)       0           dense_34[0][0]                   \n",
      "                                                                   dense_34[1][0]                   \n",
      "                                                                   dense_34[2][0]                   \n",
      "                                                                   dense_34[3][0]                   \n",
      "                                                                   dense_34[4][0]                   \n",
      "                                                                   dense_34[5][0]                   \n",
      "                                                                   dense_34[6][0]                   \n",
      "                                                                   dense_34[7][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1,341,292\n",
      "Trainable params: 1,341,292\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1443/1443 [==============================] - 4s - loss: 7.8807 - acc: 0.0843      \n",
      "Epoch 2/50\n",
      "1443/1443 [==============================] - 1s - loss: 6.0304 - acc: 0.1219     \n",
      "Epoch 3/50\n",
      "1443/1443 [==============================] - 1s - loss: 4.6065 - acc: 0.3066     \n",
      "Epoch 4/50\n",
      "1443/1443 [==============================] - 1s - loss: 4.0555 - acc: 0.3121     \n",
      "Epoch 5/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.8404 - acc: 0.3514     \n",
      "Epoch 6/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.6214 - acc: 0.3601     \n",
      "Epoch 7/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.4718 - acc: 0.3822     \n",
      "Epoch 8/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.3626 - acc: 0.3896     \n",
      "Epoch 9/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.2698 - acc: 0.3999     \n",
      "Epoch 10/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.1864 - acc: 0.4116     \n",
      "Epoch 11/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.1233 - acc: 0.4173     \n",
      "Epoch 12/50\n",
      "1443/1443 [==============================] - 1s - loss: 3.0455 - acc: 0.4208     \n",
      "Epoch 13/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.9822 - acc: 0.4275     \n",
      "Epoch 14/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.9528 - acc: 0.4258     \n",
      "Epoch 15/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.9241 - acc: 0.4265     \n",
      "Epoch 16/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.8426 - acc: 0.4362     \n",
      "Epoch 17/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.7738 - acc: 0.4447     \n",
      "Epoch 18/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.7337 - acc: 0.4513     \n",
      "Epoch 19/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.6532 - acc: 0.4640     \n",
      "Epoch 20/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.6528 - acc: 0.4537     \n",
      "Epoch 21/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.5704 - acc: 0.4741     \n",
      "Epoch 22/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.4923 - acc: 0.4844     \n",
      "Epoch 23/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.6142 - acc: 0.4436     \n",
      "Epoch 24/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.5123 - acc: 0.4634     \n",
      "Epoch 25/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.4323 - acc: 0.4782     \n",
      "Epoch 26/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.3900 - acc: 0.4835     \n",
      "Epoch 27/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.3236 - acc: 0.4932     \n",
      "Epoch 28/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.2425 - acc: 0.5060     \n",
      "Epoch 29/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.1870 - acc: 0.5115     \n",
      "Epoch 30/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.1406 - acc: 0.5161     \n",
      "Epoch 31/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.1800 - acc: 0.5031     \n",
      "Epoch 32/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.1965 - acc: 0.4989     \n",
      "Epoch 33/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.1270 - acc: 0.5077     \n",
      "Epoch 34/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.0527 - acc: 0.5217     \n",
      "Epoch 35/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.9826 - acc: 0.5348     \n",
      "Epoch 36/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.9303 - acc: 0.5428     \n",
      "Epoch 37/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.8894 - acc: 0.5469     \n",
      "Epoch 38/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.8422 - acc: 0.5567     \n",
      "Epoch 39/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.8106 - acc: 0.5586     \n",
      "Epoch 40/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.0197 - acc: 0.5222     \n",
      "Epoch 41/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.2014 - acc: 0.4850     \n",
      "Epoch 42/50\n",
      "1443/1443 [==============================] - 1s - loss: 2.0004 - acc: 0.5126     \n",
      "Epoch 43/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.8840 - acc: 0.5374     \n",
      "Epoch 44/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.7868 - acc: 0.5606     \n",
      "Epoch 45/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.7057 - acc: 0.5773     \n",
      "Epoch 46/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.6484 - acc: 0.5899     \n",
      "Epoch 47/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.6007 - acc: 0.6008     \n",
      "Epoch 48/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.5528 - acc: 0.6085     \n",
      "Epoch 49/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.5555 - acc: 0.6011     \n",
      "Epoch 50/50\n",
      "1443/1443 [==============================] - 1s - loss: 1.5922 - acc: 0.5905     \n",
      "saving model...\n"
     ]
    }
   ],
   "source": [
    "### main\n",
    "# MCP = keras.callbacks.ModelCheckpoint('./model/{}_{}.h5'.format(model_name,k), monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# ES = keras.callbacks.EarlyStopping(monitor='acc', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "if teacherForce :\n",
    "    model = model_pretrain(lang)\n",
    "else :\n",
    "    if attention :\n",
    "        if no_attention :\n",
    "            model = model_no_attention(lang)\n",
    "        else :\n",
    "            model = model_attention(lang)\n",
    "    else :\n",
    "        model = model_DC_only1(lang)\n",
    "    if do_training :\n",
    "        ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "        ary_temp[:,0,0] = 1\n",
    "        ary_train_DC_input_2 = ary_temp\n",
    "\n",
    "    \n",
    "if loading_model :\n",
    "    print ('loading and seting weight...')\n",
    "    if special_task :\n",
    "        with open('./model_weight/lst_layer_weights_special.pkl'.format(i), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    elif teacherForce :\n",
    "        with open('./model_weight/lst_layer_weights_0.pkl'.format(i), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    else :\n",
    "#         with open('./weights/lst_layer_weights_noTeacher_special.pkl'.format(i), \"rb\") as f:\n",
    "        with open('./model_weight/{}'.format(load_model_weight_name), \"rb\") as f:\n",
    "            lst_layer_weights = pickle.load(f)\n",
    "    len_model_layer = len(model.layers)\n",
    "    for i, layer in enumerate(model.layers) :\n",
    "        if i > 11 :\n",
    "            break\n",
    "        elif i < 7 :\n",
    "            layer.trainable = False\n",
    "        print (i)\n",
    "        layer.set_weights(lst_layer_weights[i])\n",
    "    print ('loading model_weight finished...')\n",
    "\n",
    "if do_training :\n",
    "    if teacherForce :\n",
    "        log = model.fit([ary_train_EC_input, ary_train_DC_input],ary_train_DC_output, epochs=50, batch_size=256, validation_split=0., callbacks=[]) \n",
    "    else :\n",
    "        log = model.fit([ary_train_EC_input, ary_train_DC_input_2],ary_train_DC_output, epochs=50, batch_size=256, validation_split=0., callbacks=[]) \n",
    "    df_log = log.history\n",
    "    #fig = keras_log_plot(df_log)\n",
    "    \n",
    "if save_model :\n",
    "    print ('saving model...')\n",
    "    if not os.path.isdir('./model_weight') :\n",
    "        os.mkdir('./model_weight')\n",
    "    k = 0\n",
    "    while 1 :\n",
    "        if os.path.isfile('./model_weight/lst_layer_weights_{}.pkl'.format(k)) :\n",
    "            k += 1\n",
    "        else :\n",
    "            break\n",
    "    lst_weights = []\n",
    "    for i, layer in enumerate(model.layers) :\n",
    "        lst_weights += [layer.get_weights()] # list of numpy arrays\n",
    "        #np.save(ary_weights,'./weight/layer{}'.format(i))\n",
    "    with open('./model_weight/lst_layer_weights_{}.pkl'.format(k), \"wb\") as f:\n",
    "        pickle.dump(lst_weights,f)\n",
    "        \n",
    "    plot_model(model, to_file='./model_weight/model_{}.png'.format(k))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : \n",
      "                          0                                                 1\n",
      "0     ScdUht-pM6s_53_63.avi                                      A woman is a\n",
      "1     wkgGxsuNVSg_34_41.avi                            A woman is playing the\n",
      "2     BtQtRGI0F2Q_15_20.avi                     A girl is riding a skateboard\n",
      "3      k06Ge9ANKM8_5_16.avi                            A person is up a onion\n",
      "4   sZf3VDsdDPM_107_114.avi                          A man is drinking a hair\n",
      "5      shPymuahrsc_5_12.avi                                   A cat is a in a\n",
      "6      XOAgUVVwKEA_8_20.avi                           A baby is laughing face\n",
      "7       ufFT2BWh3BQ_0_8.avi                                        A panda is\n",
      "8     5YJaS2Eswg0_22_26.avi                              A man is a on soccer\n",
      "9     lw7pTwpx0K0_38_48.avi                              A man is food a bowl\n",
      "10  UbmZAe5u5FI_132_141.avi                         A woman is slicing shrimp\n",
      "11      xCFCXzDUGjY_5_9.avi                                      A woman is a\n",
      "12    He7Ge7Sogrk_47_70.avi                                        A man is a\n",
      "13  tJHUH9tpqPg_113_118.avi                                      A man is a a\n",
      "14     n016q1w8Q30_2_11.avi                        A person is slicing cloves\n",
      "15     RjpbFlOHFps_8_25.avi                                          A are is\n",
      "16     6JnGBs88sL0_4_10.avi                               A man is buying a a\n",
      "17  EpMuCrbxE8A_107_115.avi  A man is playing a <padding> <padding> <padding>\n",
      "18    HAjwXjwN9-A_16_24.avi                                      A man is a a\n",
      "19    4xVGpDmA4lE_23_33.avi                                      A dog is a a\n",
      "20    k5OKBX2e7xA_19_32.avi                              A woman is on a ball\n",
      "21    Jag7oTemldY_12_25.avi                    A man walks skateboarding pots\n",
      "22  8MVo7fje_oE_125_130.avi                                 A man eats a food\n",
      "23     bqMmyY1ImkI_0_14.avi                                 A woman is eating\n",
      "24    jTnrm338_KY_34_42.avi                            A woman is eating face\n",
      "25    UdcObAQ5OOM_15_30.avi                                      A dog is a a\n",
      "26    4PcL6-mjRNk_11_18.avi                          A man is on a motorcycle\n",
      "27     3qqEKTPxLNs_1_15.avi                                    A baby is up a\n",
      "28  glrijRGnmc0_211_215.avi                                      A man is a a\n",
      "29  q7pOFn8s4zc_263_273.avi                           A man is playing a ball\n",
      "..                      ...                                               ...\n",
      "70     qvg9eM4Hmzk_4_10.avi                                    A man is a car\n",
      "71     5HAf_INrFy0_3_25.avi                                      A woman is a\n",
      "72  YmXCfQm0_CA_277_284.avi                              A man is a huge wood\n",
      "73    88DOMJ11q2M_84_87.avi                  A woman is out getting of stairs\n",
      "74     NUYu9c9XsgY_7_21.avi                                      A man is a a\n",
      "75    N3A7944_UJw_63_70.avi                          A man is playing a flute\n",
      "76     uJPupV4oLZ0_4_12.avi                                A woman is a onion\n",
      "77     cnsjm3fNEec_4_10.avi                                      A man is a a\n",
      "78  J_evFB7RIKA_104_120.avi                               A person is a onion\n",
      "79     g1Gldu1KS44_8_14.avi                              A man is mowing away\n",
      "80    s1ZABV7AQdA_38_48.avi                                 A man is riding a\n",
      "81    tcxhOGyrCtI_15_21.avi                            A cat is playing a dog\n",
      "82     inzk2fTUe1w_1_15.avi                                     A person is a\n",
      "83    j2Dhf-xFUxU_13_20.avi                             A woman is slicing an\n",
      "84     MTjrZthHwJQ_2_11.avi                                       A girl is a\n",
      "85      J---aiyznGQ_0_6.avi                                   A cat is eating\n",
      "86  ZbtpcGi2DWY_161_170.avi                                        A cat is a\n",
      "87    RSx5G0_xH48_12_17.avi                          A woman is playing a dog\n",
      "88     ecm9gf2Pgkc_1_24.avi                                      A man is a a\n",
      "89    pW9DFPqoIsI_26_50.avi                            A woman is cutting a a\n",
      "90    N2Cm0SLr0ZE_18_29.avi                                       A baby is a\n",
      "91      sJSmRik2c-c_1_7.avi                        A man is riding a the path\n",
      "92  zv2RIbUsnSw_335_341.avi                                      A man is a a\n",
      "93    aM-RcQj0a7I_37_55.avi                                  A person boils a\n",
      "94    TZ860P4iTaM_15_28.avi                           A cat playing playing a\n",
      "95     lo4KcsBN--A_0_10.avi                         A Creed holds a explosion\n",
      "96     u4T76jsPin0_0_11.avi                            A are are a a building\n",
      "97    7HcYJKMxpcg_20_28.avi                                A man is running a\n",
      "98     CGllPWAwmUo_1_15.avi                                        A man is a\n",
      "99  WTf5EgVY5uU_124_128.avi                               A person is cooking\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "test : \n",
      "       0                       1\n",
      "0  1.avi            A man is a a\n",
      "1  2.avi                A man is\n",
      "2  3.avi      A man is on a ball\n",
      "3  4.avi            A woman is a\n",
      "4  5.avi  A woman is playing the\n"
     ]
    }
   ],
   "source": [
    "### prediction\n",
    "\n",
    "### train data prediction\n",
    "if after_teacherForce_test :\n",
    "    ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "    ary_temp[:,0,0] = 1\n",
    "    ary_train_DC_input = ary_temp\n",
    "\n",
    "    if train_data_loading :\n",
    "        if teacherForce :\n",
    "            ary_pred_train = model.predict([ary_train_EC_input, ary_train_DC_input])\n",
    "        else :\n",
    "            ary_temp = np.zeros((len(ary_train_EC_input),1,lang.n_words))\n",
    "            ary_temp[:,0,0] = 1\n",
    "            ary_pred_train = model.predict([ary_train_EC_input, ary_temp])\n",
    "\n",
    "        df_ans_train = ary_pred_to_df_ans(ary_pred_train, lst_id_train)\n",
    "        print ('train : ')\n",
    "        print (df_ans_train.iloc[:5])\n",
    "\n",
    "### testing data prediction\n",
    "# model_test = model_DC_only1(lang)\n",
    "# ary_pred_test = model_test.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "ary_pred_test = model.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "\n",
    "df_ans = ary_pred_to_df_ans(ary_pred_test, lst_id_test)\n",
    "df_ans.to_csv(\"./{}\".format(str_output), index=False, header=False)\n",
    "print ('test : ')\n",
    "print (df_ans)\n",
    "\n",
    "### testing data prediction\n",
    "# model_test = model_DC_only1(lang)\n",
    "# ary_pred_test = model_test.predict([ary_test_EC_input, ary_test_DC_input])\n",
    "ary_pred_test = model.predict([ary_peer_review_EC_input, ary_peer_review_DC_input])\n",
    "\n",
    "df_ans = ary_pred_to_df_ans(ary_pred_test, lst_id_peer_review)\n",
    "df_ans.to_csv(\"./{}\".format(str_output_peer_review), index=False, header=False)\n",
    "print ('test : ')\n",
    "print (df_ans)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ary_sample_output_testset = np.loadtxt(open(path_data + \"sample_output_testset.txt\", \"rb\"), delimiter=\",\")\n",
    "# for i, name in enumerate(ary_sample_output_testset[:][0]) :\n",
    "#     print (name)\n",
    "\n",
    "### for special task\n",
    "if special_task :\n",
    "    lst_id_special = ['klteYv1Uv9A_27_33.avi','5YJaS2Eswg0_22_26.avi','UbmZAe5u5FI_132_141.avi','JntMAcTlOF0_50_70.avi','tJHUH9tpqPg_113_118.avi']\n",
    "    lst_ans_pair = []\n",
    "    for i,id in enumerate(lst_id_test) :\n",
    "        if id in lst_id_special :\n",
    "            ans = lst_ans_string_test[i].split(' <EOS>')[0]\n",
    "            lst_ans_pair += [[id,ans]]\n",
    "    \n",
    "    lst_ans_pair_sort = []\n",
    "\n",
    "    for id in lst_id_special :\n",
    "        for ans_pair in lst_ans_pair :\n",
    "            if id == ans_pair[0] :\n",
    "                lst_ans_pair_sort += [ans_pair]\n",
    "    df_ans = pd.DataFrame(lst_ans_pair_sort)\n",
    "    print (df_ans)\n",
    "    df_ans.to_csv(\"./{}\".format(str_output), index=False, header=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
