{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-1dbd265e03c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path and parameter\n",
    "path_data = './MLDS_hw2_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of lst_train_npy : 1450\n",
      "shape of train npy : (80, 4096)\n",
      "len of lst_test_npy : 100\n",
      "shape of test npy : (80, 4096)\n",
      "\n",
      "training_label.json : \n",
      "caption : \n",
      "['A woman goes under a horse.', 'A woman crawls under a horse and gets a surprise.', 'A girl is jutting out her head from between the back legs of a horse who shits on her head.', \"A horse defecated on a woman's head.\", 'A horse excretes on the head of a woman as she gets in between the fore anf hind legs and sticks her head out.', \"A horse is defecating on a woman's head.\", 'A horse poops on a woman.', 'A horse poops on a woman.', \"A lady was pooped on because she was under a horse's tail end.\", 'A woman crawls under a horse and when she sticks her head between the horses rear legs the horse defecates on her head.', \"A woman goes under a horse's behind and gets pooped on.\", 'A woman goes underneath a horse.', 'A woman is crawling under a horse.', 'A woman is getting pooped on by a horse.', 'A woman is walking between horse legs.', 'A woman is walking under horse and it poops on her head.', 'As the woman went underneath the horse, the horse pooped on her head.', 'The horse pooped on the lady who was underneath him.']\n",
      "id : \n",
      "xBePrplM4OA_6_18.avi\n"
     ]
    }
   ],
   "source": [
    "### load data\n",
    "\n",
    "### load *.npy\n",
    "lst_name_train_npy = os.listdir('{}training_data/feat'.format(path_data))\n",
    "lst_name_test_npy = os.listdir('{}testing_data/feat'.format(path_data))\n",
    "\n",
    "lst_train_npy = []\n",
    "for npy in lst_name_train_npy :\n",
    "    lst_train_npy += [np.load('{}training_data/feat/{}'.format(path_data, npy))]\n",
    "lst_test_npy = []\n",
    "for npy in lst_name_test_npy :\n",
    "    lst_test_npy += [np.load('{}testing_data/feat/{}'.format(path_data, npy))]\n",
    "\n",
    "print ('len of lst_train_npy : '+str(len(lst_train_npy))+'\\nshape of train npy : '+str(lst_train_npy[0].shape))\n",
    "print ('len of lst_test_npy : '+str(len(lst_test_npy))+'\\nshape of test npy : '+str(lst_test_npy[0].shape))\n",
    "\n",
    "### load training_label.json testing_label.json\n",
    "with open('{}training_label.json'.format(path_data)) as f :\n",
    "    lst_dict_label_train = json.load(f)\n",
    "print ('\\ntraining_label.json : ')\n",
    "print ('caption : \\n' + str(lst_dict_label_train[0]['caption']))\n",
    "print ('id : \\n' + str(lst_dict_label_train[0]['id']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lst_word) : 6871\n",
      "<<-- dict_map_W2I and dict_I2W are built completely -->>\n"
     ]
    }
   ],
   "source": [
    "### build dict_map_W2I and dict_map_I2W to mapping from word to index\n",
    "\n",
    "### count unique words\n",
    "lst_word = list(set([word for dict_label_train in lst_dict_label_train for str_label in dict_label_train['caption'] for word in str_label[:-1].split()]))\n",
    "lst_word += ['<BOS>']\n",
    "lst_word += ['<EOS>']\n",
    "n_class = len(lst_word)\n",
    "print ('len(lst_word) : {}'.format(n_class))\n",
    "\n",
    "### map from word to index\n",
    "dict_map_W2I = dict()\n",
    "index = 0\n",
    "for word in lst_word :\n",
    "    if word not in dict_map_W2I :\n",
    "        dict_map_W2I[word] = index\n",
    "        index += 1\n",
    "        \n",
    "### map from index to word\n",
    "dict_map_I2W = {v:k for k,v in dict_map_W2I.items()}\n",
    "\n",
    "print ('<<-- dict_map_W2I and dict_I2W are built completely -->>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### index to one-hot\n",
    "def Str2OneHot(sentence, n_class) :\n",
    "    ### sentence to lst_index_sentence\n",
    "    sentence = '<BOS> ' + sentence[:-1] + ' <EOS>'\n",
    "    lst_word = sentence.split()\n",
    "    ary_oneHot = np.zeros((len(lst_word),n_class))\n",
    "    lst_index_word = [dict_map[word] for word in lst_word]\n",
    "    ary_oneHot[range(len(lst_word)),lst_index_word] = 1\n",
    "    return ary_oneHot\n",
    "    \n",
    "### just for test\n",
    "Str2OneHot('A woman goes under a horse.', n_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### note\n",
    "# remember to add <BOS> and <EOS>\n",
    "# Tom's should split as \"TOM\" and \"s\"\n",
    "# notice [:-1] to delete \".\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
