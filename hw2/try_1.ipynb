{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "def init():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    keras.backend.tensorflow_backend.set_session(session)\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path and parameter\n",
    "path_data = './MLDS_hw2_data/'\n",
    "model_name = 's2s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<BOS>\": 0, \"<EOS>\" :1}\n",
    "        self.word2count = {\"<BOS>\": 0, \"<EOS>\" : 0}\n",
    "        self.index2word = {0: \"<BOS>\", 1: \"<EOS>\"}\n",
    "        self.n_words = 2  # Count BOS and EOS\n",
    "        self.max_len_seq = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        lst_word = sentence.split()\n",
    "        if self.max_len_seq < len(lst_word) :\n",
    "            self.max_len_seq = len(lst_word)\n",
    "        for word in lst_word :\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_log_plot(log) :\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    fig = plt.figure(1,figsize=(20,10))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(log['acc'], label='train_acc')\n",
    "    plt.plot(log['val_acc'], label='val_acc')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('acc', fontsize=20, color='black')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(log['loss'], label='train_loss')\n",
    "    plt.plot(log['val_loss'], label='val_loss')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('loss', fontsize=20, color='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_label.json : \n",
      "caption : \n",
      "['A woman goes under a horse.', 'A woman crawls under a horse and gets a surprise.', 'A girl is jutting out her head from between the back legs of a horse who shits on her head.', \"A horse defecated on a woman's head.\", 'A horse excretes on the head of a woman as she gets in between the fore anf hind legs and sticks her head out.', \"A horse is defecating on a woman's head.\", 'A horse poops on a woman.', 'A horse poops on a woman.', \"A lady was pooped on because she was under a horse's tail end.\", 'A woman crawls under a horse and when she sticks her head between the horses rear legs the horse defecates on her head.', \"A woman goes under a horse's behind and gets pooped on.\", 'A woman goes underneath a horse.', 'A woman is crawling under a horse.', 'A woman is getting pooped on by a horse.', 'A woman is walking between horse legs.', 'A woman is walking under horse and it poops on her head.', 'As the woman went underneath the horse, the horse pooped on her head.', 'The horse pooped on the lady who was underneath him.']\n",
      "id : \n",
      "xBePrplM4OA_6_18.avi\n"
     ]
    }
   ],
   "source": [
    "### load data\n",
    "\n",
    "### load *.npy\n",
    "# lst_name_train_npy = os.listdir('{}training_data/feat'.format(path_data))\n",
    "# lst_name_test_npy = os.listdir('{}testing_data/feat'.format(path_data))\n",
    "\n",
    "# lst_train_npy = []\n",
    "# for npy in lst_name_train_npy :\n",
    "#     lst_train_npy += [np.load('{}training_data/feat/{}'.format(path_data, npy))]\n",
    "# lst_test_npy = []\n",
    "# for npy in lst_name_test_npy :\n",
    "#     lst_test_npy += [np.load('{}testing_data/feat/{}'.format(path_data, npy))]\n",
    "\n",
    "# print ('len of lst_train_npy : '+str(len(lst_train_npy))+'\\nshape of train npy : '+str(lst_train_npy[0].shape))\n",
    "# print ('len of lst_test_npy : '+str(len(lst_test_npy))+'\\nshape of test npy : '+str(lst_test_npy[0].shape))\n",
    "\n",
    "### load training_label.json testing_label.json\n",
    "with open('{}training_label.json'.format(path_data)) as f :\n",
    "    lst_dict_label_train = json.load(f)\n",
    "print ('\\ntraining_label.json : ')\n",
    "print ('caption : \\n' + str(lst_dict_label_train[0]['caption']))\n",
    "print ('id : \\n' + str(lst_dict_label_train[0]['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<BOS>\": 0, \"<EOS>\" :1}\n",
    "        self.word2count = {\"<BOS>\": 0, \"<EOS>\" : 0}\n",
    "        self.index2word = {0: \"<BOS>\", 1: \"<EOS>\"}\n",
    "        self.n_words = 2  # Count BOS and EOS\n",
    "        self.max_len_seq = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        lst_word = sentence.split()\n",
    "        if self.max_len_seq < len(lst_word) :\n",
    "            self.max_len_seq = len(lst_word)\n",
    "        for word in lst_word :\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6871\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "lang = Lang()\n",
    "for dict_label_train in lst_dict_label_train :\n",
    "    for sentence in dict_label_train['caption'] :\n",
    "        sentence = sentence[:-1] + ' <EOS>'\n",
    "        lang.addSentence(sentence) # remove \".\"\n",
    "print (lang.n_words)\n",
    "print (lang.max_len_seq)\n",
    "# assert lang.word2count['<BOS>'] == lang.word2count['<EOS>'], number of \"<BOS>\" != number of \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 6871)\n"
     ]
    }
   ],
   "source": [
    "### index to one-hot\n",
    "def Str2OneHot(sentence, n_class, dict_map, max_len_seq) :\n",
    "    ### sentence to lst_index_sentence\n",
    "    sentence = sentence[:-1] + ' <EOS>'\n",
    "    lst_word = sentence.split()\n",
    "    ary_oneHot = np.zeros((max_len_seq,n_class))\n",
    "    lst_index_word = [dict_map[word] for word in lst_word]\n",
    "    ary_oneHot[range(len(lst_word)),lst_index_word] = 1\n",
    "    ary_oneHot[range(len(lst_word),len(ary_oneHot)),:] = 0.01 # others all set <EOS>\n",
    "    return ary_oneHot\n",
    "    \n",
    "### just for test\n",
    "ary = Str2OneHot('A woman goes under a horse.', lang.n_words, lang.word2index, lang.max_len_seq)\n",
    "print (ary.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,5) :\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4350, 80, 4096)\n"
     ]
    }
   ],
   "source": [
    "lst_id = [dict_label_train['id'] for dict_label_train in lst_dict_label_train]\n",
    "lst_train_EC_input = []\n",
    "lst_train_DC_output = []\n",
    "for i, id in enumerate(lst_id) :\n",
    "    npy = np.load('{}training_data/feat/{}.npy'.format(path_data, id))\n",
    "    for caption in lst_dict_label_train[i]['caption'][:3] :\n",
    "        lst_train_EC_input += [npy]\n",
    "        ary_OneHot = Str2OneHot(caption, lang.n_words, lang.word2index, lang.max_len_seq)\n",
    "        lst_train_DC_output += [ary_OneHot]\n",
    "assert len(lst_train_EC_input) == len(lst_train_DC_output), \"??\"\n",
    "ary_train_EC_input = np.concatenate(lst_train_EC_input,axis=0).reshape(-1,80,4096)\n",
    "ary_train_DC_output = np.concatenate(lst_train_DC_output,axis=0).reshape(-1,lang.max_len_seq,lang.n_words)\n",
    "# ary_train_EC_input = np.vstack(tuple(lst_train_EC_input)).reshape(-1,80,4096)\n",
    "print (ary_train_EC_input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pretrain(lang=lang) :\n",
    "\n",
    "    EC_input = Input(shape=(80,4096))\n",
    "    EC_output, EC_output_state = GRU(32,return_state=True)(EC_input)\n",
    "    print (EC_output_state)\n",
    "    DC_input = Input(shape=(None,lang.n_words))\n",
    "    DC_input_M = Masking(mask_value=0.01)(DC_input)\n",
    "    print (DC_input)\n",
    "\n",
    "    DC_gru = GRU(32, return_sequences=True)\n",
    "    DC_time_dense = TimeDistributed(Dense(lang.n_words, activation='softmax'))\n",
    "\n",
    "#     DC_output_state = EC_output_state\n",
    "#     DC_output = DC_input\n",
    "#     lst_DC_output = []\n",
    "#     for _ in range(lang.max_len_seq) :\n",
    "    DC_output = DC_gru(DC_input_M, initial_state=EC_output_state)\n",
    "    DC_output = DC_time_dense(DC_output)\n",
    "\n",
    "    model = Model([EC_input,DC_input],DC_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# EC_input = Input(shape=(80,4096))\n",
    "# EC_output, EC_output_state = GRU(32,return_state=True)(EC_input)\n",
    "# print (EC_output_state)\n",
    "# DC_input = Input(shape=(1,lang.n_words))\n",
    "# print (DC_input)\n",
    "\n",
    "# DC_gru = GRU(32, return_sequences=True, return_state=True)\n",
    "# DC_dense = Dense(lang.n_words, activation='softmax')\n",
    "\n",
    "# DC_output_state = EC_output_state\n",
    "# DC_output = DC_input\n",
    "# lst_DC_output = []\n",
    "# for _ in range(lang.max_len_seq) :\n",
    "#     DC_output, DC_output_state = DC_gru(DC_output, initial_state=DC_output_state)\n",
    "#     DC_output = DC_dense(DC_output)\n",
    "#     lst_DC_output += [DC_output]\n",
    "\n",
    "# DC_output = Lambda(lambda x: K.concatenate(x, axis=1))(lst_DC_output)\n",
    "\n",
    "    \n",
    "# model = Model([EC_input,DC_input],DC_output)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4350, 1, 6871)\n",
      "(4350, 40, 6871)\n",
      "[[[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]\n",
      "\n",
      " [[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]\n",
      "\n",
      " [[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]\n",
      "\n",
      " ..., \n",
      " [[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]\n",
      "\n",
      " [[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]\n",
      "\n",
      " [[ 1.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      "  ..., \n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "  [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]]]\n",
      "Tensor(\"gru_3/while/Exit_2:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"input_4:0\", shape=(?, ?, 6871), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, None, 6871)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "masking_2 (Masking)              (None, None, 6871)    0           input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      [(None, 32), (None, 3 396384      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, None, 32)      662784      masking_2[0][0]                  \n",
      "                                                                   gru_3[0][1]                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, None, 6871)    226743      gru_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 1,285,911\n",
      "Trainable params: 1,285,911\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3915 samples, validate on 435 samples\n",
      "Epoch 1/500\n",
      "3915/3915 [==============================] - 31s - loss: 66.2182 - acc: 0.1659 - val_loss: 65.5288 - val_acc: 0.2597\n",
      "Epoch 2/500\n",
      "3915/3915 [==============================] - 31s - loss: 64.7074 - acc: 0.2081 - val_loss: 64.7267 - val_acc: 0.1869\n",
      "Epoch 3/500\n",
      "3915/3915 [==============================] - 31s - loss: 64.0681 - acc: 0.1945 - val_loss: 64.4478 - val_acc: 0.2431\n",
      "Epoch 4/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.9186 - acc: 0.2370 - val_loss: 64.3218 - val_acc: 0.2407\n",
      "Epoch 5/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.7958 - acc: 0.2425 - val_loss: 64.1979 - val_acc: 0.2516\n",
      "Epoch 6/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.6640 - acc: 0.2558 - val_loss: 64.0796 - val_acc: 0.2842\n",
      "Epoch 7/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.5084 - acc: 0.2831 - val_loss: 63.9689 - val_acc: 0.3004\n",
      "Epoch 8/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.3618 - acc: 0.3126 - val_loss: 63.8658 - val_acc: 0.3257\n",
      "Epoch 9/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.2809 - acc: 0.3223 - val_loss: 63.7884 - val_acc: 0.3324\n",
      "Epoch 10/500\n",
      "3915/3915 [==============================] - 31s - loss: 63.1077 - acc: 0.3263 - val_loss: 63.7252 - val_acc: 0.3341\n",
      "Epoch 11/500\n",
      "3915/3915 [==============================] - 32s - loss: 63.1195 - acc: 0.3290 - val_loss: 63.6782 - val_acc: 0.3354\n",
      "Epoch 12/500\n",
      "3915/3915 [==============================] - 32s - loss: 63.0227 - acc: 0.3315 - val_loss: 63.6339 - val_acc: 0.3382\n",
      "Epoch 13/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.9817 - acc: 0.3359 - val_loss: 63.5995 - val_acc: 0.3419\n",
      "Epoch 14/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.9457 - acc: 0.3386 - val_loss: 63.5646 - val_acc: 0.3452\n",
      "Epoch 15/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.8552 - acc: 0.3433 - val_loss: 63.5387 - val_acc: 0.3494\n",
      "Epoch 16/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.8514 - acc: 0.3463 - val_loss: 63.5092 - val_acc: 0.3529\n",
      "Epoch 17/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.7896 - acc: 0.3501 - val_loss: 63.4877 - val_acc: 0.3544\n",
      "Epoch 18/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.7673 - acc: 0.3531 - val_loss: 63.4691 - val_acc: 0.3570\n",
      "Epoch 19/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.7125 - acc: 0.3571 - val_loss: 63.4547 - val_acc: 0.3565\n",
      "Epoch 20/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.7128 - acc: 0.3614 - val_loss: 63.4386 - val_acc: 0.3588\n",
      "Epoch 21/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.6174 - acc: 0.3647 - val_loss: 63.4217 - val_acc: 0.3602\n",
      "Epoch 22/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.5685 - acc: 0.3674 - val_loss: 63.4112 - val_acc: 0.3626\n",
      "Epoch 23/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.6107 - acc: 0.3697 - val_loss: 63.4007 - val_acc: 0.3606\n",
      "Epoch 24/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.5546 - acc: 0.3724 - val_loss: 63.3931 - val_acc: 0.3631\n",
      "Epoch 25/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.4836 - acc: 0.3742 - val_loss: 63.3834 - val_acc: 0.3642\n",
      "Epoch 26/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.4648 - acc: 0.3767 - val_loss: 63.3773 - val_acc: 0.3653\n",
      "Epoch 27/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.4487 - acc: 0.3791 - val_loss: 63.3709 - val_acc: 0.3640\n",
      "Epoch 28/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.3873 - acc: 0.3820 - val_loss: 63.3684 - val_acc: 0.3655\n",
      "Epoch 29/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.3671 - acc: 0.3865 - val_loss: 63.3646 - val_acc: 0.3703\n",
      "Epoch 30/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.3309 - acc: 0.3890 - val_loss: 63.3580 - val_acc: 0.3669\n",
      "Epoch 31/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.3426 - acc: 0.3914 - val_loss: 63.3496 - val_acc: 0.3687\n",
      "Epoch 32/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.3083 - acc: 0.3932 - val_loss: 63.3539 - val_acc: 0.3693\n",
      "Epoch 33/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.2352 - acc: 0.3964 - val_loss: 63.3527 - val_acc: 0.3671\n",
      "Epoch 34/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.2629 - acc: 0.3990 - val_loss: 63.3514 - val_acc: 0.3675\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3915/3915 [==============================] - 32s - loss: 62.2106 - acc: 0.4011 - val_loss: 63.3523 - val_acc: 0.3677\n",
      "Epoch 36/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.2145 - acc: 0.4042 - val_loss: 63.3517 - val_acc: 0.3666\n",
      "Epoch 37/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.2234 - acc: 0.4061 - val_loss: 63.3482 - val_acc: 0.3679\n",
      "Epoch 38/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.2129 - acc: 0.4081 - val_loss: 63.3502 - val_acc: 0.3671\n",
      "Epoch 39/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.1652 - acc: 0.4105 - val_loss: 63.3538 - val_acc: 0.3688\n",
      "Epoch 40/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.0898 - acc: 0.4122 - val_loss: 63.3555 - val_acc: 0.3676\n",
      "Epoch 41/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.1335 - acc: 0.4166 - val_loss: 63.3544 - val_acc: 0.3682\n",
      "Epoch 42/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.0854 - acc: 0.4184 - val_loss: 63.3618 - val_acc: 0.3692\n",
      "Epoch 43/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.0694 - acc: 0.4210 - val_loss: 63.3654 - val_acc: 0.3720\n",
      "Epoch 44/500\n",
      "3915/3915 [==============================] - 32s - loss: 62.0381 - acc: 0.4227 - val_loss: 63.3766 - val_acc: 0.3685\n",
      "Epoch 45/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9765 - acc: 0.4259 - val_loss: 63.3769 - val_acc: 0.3720\n",
      "Epoch 46/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9759 - acc: 0.4281 - val_loss: 63.3752 - val_acc: 0.3695\n",
      "Epoch 47/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9639 - acc: 0.4302 - val_loss: 63.3689 - val_acc: 0.3728\n",
      "Epoch 48/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9519 - acc: 0.4331 - val_loss: 63.3932 - val_acc: 0.3693\n",
      "Epoch 49/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9070 - acc: 0.4355 - val_loss: 63.3804 - val_acc: 0.3707\n",
      "Epoch 50/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9409 - acc: 0.4368 - val_loss: 63.3971 - val_acc: 0.3672\n",
      "Epoch 51/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.8871 - acc: 0.4388 - val_loss: 63.3881 - val_acc: 0.3687\n",
      "Epoch 52/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9008 - acc: 0.4413 - val_loss: 63.4235 - val_acc: 0.3631\n",
      "Epoch 53/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.9008 - acc: 0.4434 - val_loss: 63.4178 - val_acc: 0.3671\n",
      "Epoch 54/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.8636 - acc: 0.4462 - val_loss: 63.4168 - val_acc: 0.3666\n",
      "Epoch 55/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7726 - acc: 0.4477 - val_loss: 63.4116 - val_acc: 0.3693\n",
      "Epoch 56/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7935 - acc: 0.4493 - val_loss: 63.4338 - val_acc: 0.3652\n",
      "Epoch 57/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7692 - acc: 0.4522 - val_loss: 63.4473 - val_acc: 0.3634\n",
      "Epoch 58/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.8083 - acc: 0.4543 - val_loss: 63.4369 - val_acc: 0.3671\n",
      "Epoch 59/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7727 - acc: 0.4557 - val_loss: 63.4581 - val_acc: 0.3634\n",
      "Epoch 60/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.6952 - acc: 0.4581 - val_loss: 63.4436 - val_acc: 0.3637\n",
      "Epoch 61/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7371 - acc: 0.4596 - val_loss: 63.4594 - val_acc: 0.3643\n",
      "Epoch 62/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7270 - acc: 0.4610 - val_loss: 63.4809 - val_acc: 0.3632\n",
      "Epoch 63/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.6675 - acc: 0.4639 - val_loss: 63.4676 - val_acc: 0.3658\n",
      "Epoch 64/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.6741 - acc: 0.4677 - val_loss: 63.4815 - val_acc: 0.3633\n",
      "Epoch 65/500\n",
      "3915/3915 [==============================] - 32s - loss: 61.7005 - acc: 0.4679 - val_loss: 63.4875 - val_acc: 0.3634\n",
      "Epoch 66/500\n",
      "2112/3915 [===============>..............] - ETA: 13s - loss: 61.5454 - acc: 0.4701"
     ]
    }
   ],
   "source": [
    "ary_temp = np.zeros((len(ary_train_DC_output),1,lang.n_words))\n",
    "ary_temp[:,0,0] = 1\n",
    "print (ary_temp.shape)\n",
    "print (ary_train_DC_output[:,:-1].shape)\n",
    "\n",
    "ary_train_DC_input = np.concatenate([ary_temp,ary_train_DC_output[:,:-1]],axis=1)\n",
    "# for i in range(len(ary_train_DC_output)) :\n",
    "#     print (i)\n",
    "#     if i == 0 :\n",
    "#         lst_train_DC_input = [np.concatenate([ary_temp,ary_train_DC_output[i,:-1]],axis=1).tolist()]\n",
    "#     else :\n",
    "#         lst_train_DC_input += [np.concatenate([ary_temp,ary_train_DC_output[i,:-1]],axis=1).tolist()]\n",
    "# ary_train_DC_output = np.asarray(lst_train_DC_input)\n",
    "print (ary_train_DC_input[:7])\n",
    "\n",
    "if not os.path.isdir('./model') :\n",
    "    os.mkdir('./model')\n",
    "k = 0\n",
    "while 1 :\n",
    "    if os.path.isfile('./model/{}_{}.h5'.format(model_name,k)) :\n",
    "        k += 1\n",
    "    else :\n",
    "        break\n",
    "MCP = keras.callbacks.ModelCheckpoint('./model/{}_{}.h5'.format(model_name,k), monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=50, verbose=0, mode='auto')\n",
    "\n",
    "model = model_pretrain(lang)\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "loading_model = 0\n",
    "\n",
    "if loading_model :\n",
    "    model = load_model('./model/s2s_0.h5')\n",
    "log = model.fit([ary_train_EC_input, ary_train_DC_input],ary_train_DC_output, epochs=500, batch_size=32, validation_split=0.1, callbacks=[ES]) \n",
    "df_log = log.history\n",
    "fig = keras_log_plot(df_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ary_pred_to_sentence(ary_pred) :\n",
    "    ary_pred_argmax = np.argmax(ary_pred,axis=2)\n",
    "    lst_ans_numbers = ary_pred_argmax.tolist()\n",
    "#     print (lst_ans_numbers[:3])\n",
    "    lst_ans_string = []\n",
    "    for ans_numbers in lst_ans_numbers :\n",
    "        lst_ans_string += [' '.join([lang.index2word[ans] for ans in ans_numbers])]\n",
    "    return lst_ans_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary_pred = model.predict([ary_train_EC_input, ary_train_DC_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (ary_train_EC_input[:3])\n",
    "# print (ary_train_DC_input[1]\n",
    "print (ary_train_DC_input.shape)\n",
    "print (np.argmax(ary_train_DC_input[1],axis=1))\n",
    "print (np.argmax(ary_train_DC_input[1],axis=1).shape)\n",
    "print (ary_pred.shape)\n",
    "ary_pred_argmax = np.argmax(ary_pred,axis=2)\n",
    "print (ary_pred_argmax.shape)\n",
    "# print (ary_pred_argmax[:5])\n",
    "\n",
    "lst_ans_string = ary_pred_to_sentence(ary_pred)\n",
    "print (lst_ans_string[:5])\n",
    "# print (len(lst_ans_string[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "s+=[['aa']]\n",
    "s+=['bb']\n",
    "print (s)\n",
    "print (len(lst_ans_string[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('./model') :\n",
    "#     os.mkdir('./model')\n",
    "# model.save('./model/s2s_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_seq = 30\n",
    "\n",
    "ary_train_EC_input = np.concatenate(lst_train_npy,axis=0)\n",
    "ary_train_EC_input = ary_train.reshape(-1,80,4096)\n",
    "print (ary_train_EC_input.shape)\n",
    "\n",
    "ary_train_DC_output = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda :\n",
    "    print ('using cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size=4096, hidden_size=32, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=self.n_layers, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1,self.n_layers, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module) :\n",
    "    def __init__(self, hidden_size=32, input_size=6871, n_layers=1) :\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=self.n_layers, batch_first=True, bidirectional=False)\n",
    "        self.out = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, input, hidden) :\n",
    "        output = input\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        output = self.out(output.float())\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = nn.GRU(10, 20, 2)\n",
    "# rnn = rnn.cuda()\n",
    "# input = Variable(torch.randn(5, 3, 10)).cuda()\n",
    "# h0 = Variable(torch.randn(2, 3, 20)).cuda()\n",
    "# output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_net = EncoderRNN(4096,64,1).cuda()\n",
    "D_net = DecoderRNN(64,6871,1).cuda()\n",
    "v_input = Variable(torch.from_numpy(lst_train_npy[0].reshape((1,80,4096))))\n",
    "v_input = v_input.cuda()\n",
    "h_0 = E_net.initHidden()\n",
    "output_encoder, hidden = E_net(v_input, h_0)\n",
    "\n",
    "lst_output = []\n",
    "print (lst_dict_label_train[0]['caption'])\n",
    "for caption in lst_dict_label_train[0]['caption'] :\n",
    "    ary_label_OneHot = Str2OneHot(caption, lang.n_words, lang.word2index)\n",
    "    print (ary_label_OneHot.shape)\n",
    "    i = 0\n",
    "    for i in range(len(ary_label_OneHot)) : # check not <EOS>\n",
    "        print (i)\n",
    "        output = Variable(torch.from_numpy(ary_label_OneHot[i].reshape(1,1,-1))).cuda()\n",
    "        output, hidden = D_net.forward(output, hidden)\n",
    "        lst_output += [output]\n",
    "        i += 1\n",
    "                \n",
    "\n",
    "target = Variable(torch.from_numpy(ary_label_OneHot[1:])).cuda()  # a dummy target, for example\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "print (lst_output[0])\n",
    "# print (target[0])\n",
    "# print (lst_output[0].data.shape)\n",
    "# a = Variable(torch.zeros())\n",
    "print (target[0].data.shape)\n",
    "\n",
    "# loss = criterion()\n",
    "loss = criterion(lst_output[0].view(1,6871), target[0])\n",
    "print (loss)\n",
    "for i in range(len(label_OneHot)) :\n",
    "    loss.add\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print ('epoch : {}'.format(epoch) + '\\t loss : ' + str(loss.data[0]))\n",
    "# print ('epoch : {}'.format(epoch) + '\\t loss : ' + str(loss.data[0]))\n",
    "\n",
    "\n",
    "\n",
    "# for epoch in range(10) :\n",
    "#     running_loss = 0.0\n",
    "#     loss = criterion(lst_output[0], target[i]) for i in range(len(label_OneHot)))\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print ('epoch : {}'.format(epoch) + '\\t loss : ' + str(loss.data[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### note\n",
    "# remember to add <BOS> and <EOS>\n",
    "# Tom's should split as \"TOM\" and \"s\"\n",
    "# notice [:-1] to delete \".\"\n",
    "# A and a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### build dict_map_W2I and dict_map_I2W to mapping from word to index\n",
    "\n",
    "# ### count unique words\n",
    "# lst_word = list(set([word for dict_label_train in lst_dict_label_train for str_label in dict_label_train['caption'] for word in str_label[:-1].split()]))\n",
    "# lst_word += ['<BOS>']\n",
    "# lst_word += ['<EOS>']\n",
    "# n_class = len(lst_word)\n",
    "# print ('len(lst_word) : {}'.format(n_class))\n",
    "\n",
    "# ### map from word to index\n",
    "# dict_map_W2I = dict()\n",
    "# index = 0\n",
    "# for word in lst_word :\n",
    "#     if word not in dict_map_W2I :\n",
    "#         dict_map_W2I[word] = index\n",
    "#         index += 1\n",
    "        \n",
    "# ### map from index to word\n",
    "# dict_map_I2W = {v:k for k,v in dict_map_W2I.items()}\n",
    "\n",
    "# print ('<<-- dict_map_W2I and dict_I2W are built completely -->>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15).reshape((3,5))\n",
    "max_size=5\n",
    "for i in range(max_size-len(a)) :\n",
    "    print (i)\n",
    "    a = np.append(a,[[0,0,0,0,0]],axis=0)\n",
    "# a = np.pad(a,(0,10-len(a)),'constant')\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum(i for i in range(5))\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
