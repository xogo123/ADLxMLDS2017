{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# require :\n",
    "# data/data_pp/lab_train_num.csv because it needs to run 1 hr\n",
    "\n",
    "# time(sec) :\n",
    "# conv_48_to_char_or_num : 2500\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "start_time_prep = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_user_train = 462\n",
    "n_user_test = 74\n",
    "n_sen_train = 1716\n",
    "n_sen_test = 342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__' :\n",
    "    path_data = 'data/'\n",
    "    model_name = 'CNN'\n",
    "    mfcc_or_fbank = 'mfcc'\n",
    "    n_seq = 13\n",
    "    n_CNN_window = 3\n",
    "\n",
    "    if_making_beginEnd = 0\n",
    "\n",
    "    # RNN seting\n",
    "    # if_making_RNN_data = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# map 48 to char or num\n",
    "#\n",
    "def conv_48_to_char_or_num(df_lab_train,path_data,char_or_num='num') :\n",
    "    if not os.path.isdir('./data_pp') :\n",
    "        os.mkdir('./data_pp')\n",
    "    \n",
    "    map_48_39 = pd.read_csv('./data/phones/48_39.map', header=None, delimiter='\\t')\n",
    "#     print (map_48_39.head(5))\n",
    "    map_48phone_char = pd.read_csv('./data/48phone_char.map', header=None, delimiter='\\t')\n",
    "#     print (map_48phone_char.head(5))\n",
    "#     lab_train = pd.read_csv('{}label/train.lab'.format(path_data), index_col=0, header=None)\n",
    "#     print (lab_train.head(5))\n",
    "\n",
    "    dict_map_39char = dict()\n",
    "    dict_map_39num = dict()\n",
    "    for name in map_48phone_char.iterrows() :\n",
    "        #dict_map_39char[name[1][0]] = name[1][2]\n",
    "        dict_map_39num[name[1][0]] = name[1][1]\n",
    "\n",
    "    dict_map_48char = dict()\n",
    "    dict_map_48num = dict()\n",
    "    for name in map_48_39.iterrows() :\n",
    "        #dict_map_48char[name[1][0]] = dict_map_39char[name[1][1]]\n",
    "        dict_map_48num[name[1][0]] = dict_map_39num[name[1][1]]\n",
    "\n",
    "\n",
    "    print (dict_map_48num)    \n",
    "    len_lab_train = df_lab_train.shape[0]\n",
    "    for i,lab in enumerate(df_lab_train[1]) :\n",
    "        sys.stdout.write('\\r{}/{} \\t'.format(i,len_lab_train))\n",
    "        sys.stdout.flush()\n",
    "        df_lab_train[1][i] = dict_map_48num[lab]\n",
    "        \n",
    "    df_lab_train.to_csv('./data_pp/lab_train_num.csv')\n",
    "    print (\"conv_48_to_char_or_num took\", str(time.time() - start_time_prep), \"to run\")\n",
    "\n",
    "    #return df_lab_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making beginEnd_train and beginEnd_test\n",
    "#\n",
    "def making_beginEnd(path_data,mfcc_or_fbank) :\n",
    "    df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "\n",
    "    df_id_train = df_train_ark[0]\n",
    "    df_id_test = df_test_ark[0]\n",
    "\n",
    "    for df_id in [df_id_train, df_id_test] :\n",
    "        lst_beginEnd = []\n",
    "        for i,id in enumerate(df_id) :\n",
    "            lst_id = id.split('_')\n",
    "            if i == 0:\n",
    "                index_begin = i\n",
    "                speakerId = lst_id[0]\n",
    "                sentenceId = lst_id[1]\n",
    "            else : \n",
    "                frameId = lst_id[2]\n",
    "                if frameId == '1' :\n",
    "                    index_end = i - 1\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "                    index_begin = i\n",
    "                    speakerId = lst_id[0]\n",
    "                    sentenceId = lst_id[1]\n",
    "                elif i == len(df_id) - 1 :\n",
    "                    index_end = i\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "        if df_id is df_id_train :\n",
    "            print ('saving beginEnd_train')\n",
    "            df_beginEnd_train = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "            print (df_beginEnd_train.head(5))\n",
    "            print (df_beginEnd_train.tail(5))\n",
    "            df_beginEnd_train.to_csv('./data_pp/beginEnd_train.csv', index=None)\n",
    "\n",
    "        elif df_id is df_id_test :\n",
    "            print ('saving beginEnd_test')\n",
    "            df_beginEnd_test = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "            print (df_beginEnd_test.head(5))\n",
    "            print (df_beginEnd_test.tail(5))\n",
    "            if not os.path.isdir('./data_pp') :\n",
    "                os.mkdir('./data_pp')\n",
    "            df_beginEnd_test.to_csv('./data_pp/beginEnd_test.csv', index=None)\n",
    "            \n",
    "# if if_making_beginEnd :\n",
    "#     making_beginEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making RNN data \n",
    "#\n",
    "# need : beginEnd_train.csv, beginEnd_test.csv\n",
    "\n",
    "def making_RNN_data(path_data,model_name,mfcc_or_fbank,n_seq) :\n",
    "    df_y_train = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "    df_y_train_noId = df_y_train.drop('0', axis=1)\n",
    "#     print (df_y_train_noId[:3])\n",
    "    \n",
    "    df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_train_ark_noId = df_train_ark.drop(0, axis=1)\n",
    "    df_test_ark_noId = df_test_ark.drop(0, axis=1)\n",
    "#     print (df_train_ark_noId.iloc[:3])\n",
    "    \n",
    "    \n",
    "    df_beginEnd_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "    df_beginEnd_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "#     print (df_beginEnd_train.head(5))\n",
    "#     print (df_beginEnd_train.tail(5))\n",
    "#     print (df_beginEnd_test.head(5))\n",
    "#     print (df_beginEnd_test.tail(5))    \n",
    "    for df_BE in [df_beginEnd_train,df_beginEnd_test] :\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            print ('RNN_train is building...')\n",
    "            df_ark = df_train_ark_noId\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            print ('RNN_test is building...')\n",
    "            df_ark = df_test_ark_noId\n",
    "            \n",
    "        lst_X_data = []\n",
    "        lst_y_data = []\n",
    "        \n",
    "        for BE in df_BE.iterrows() :\n",
    "            index_begin = BE[1]['index_begin']\n",
    "            index_end = BE[1]['index_end']\n",
    "            length_BE = BE[1]['length']\n",
    "            n_data = length_BE - n_seq + 1\n",
    "            assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "            \n",
    "            for i in range(n_data) :\n",
    "                lst_X_data += [df_ark.iloc[index_begin+i:index_begin+i+n_seq].values.tolist()]\n",
    "                if df_BE is df_beginEnd_train :\n",
    "                    lst_y_data += [df_y_train_noId.iloc[index_begin+i:index_begin+i+n_seq].values.tolist()]\n",
    "\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "            ary_y_data = np.array(lst_y_data)\n",
    "            np.save('./data_pp/y_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_y_data)\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "    print ('finished making RNN data')\n",
    "# if if_making_RNN_data :\n",
    "#     making_RNN_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making CNN data \n",
    "#\n",
    "# need : beginEnd_train.csv, beginEnd_test.csv\n",
    "\n",
    "def making_CNN_data(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window) :\n",
    "    df_y_train = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "    df_y_train_noId = df_y_train.drop('0', axis=1)\n",
    "#     print (df_y_train_noId[:3])\n",
    "    \n",
    "    df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_train_ark_noId = df_train_ark.drop(0, axis=1)\n",
    "    df_test_ark_noId = df_test_ark.drop(0, axis=1)\n",
    "#     print (df_train_ark_noId.iloc[:3])\n",
    "    \n",
    "    \n",
    "    df_beginEnd_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "    df_beginEnd_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "#     print (df_beginEnd_train.head(5))\n",
    "#     print (df_beginEnd_train.tail(5))\n",
    "#     print (df_beginEnd_test.head(5))\n",
    "#     print (df_beginEnd_test.tail(5))    \n",
    "    for df_BE in [df_beginEnd_train,df_beginEnd_test] :\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            print ('train data is building...')\n",
    "            df_ark = df_train_ark_noId\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            print ('test data is building...')\n",
    "            df_ark = df_test_ark_noId\n",
    "            \n",
    "        lst_X_data = []\n",
    "        lst_y_data = []\n",
    "        \n",
    "        for BE in df_BE.iterrows() :\n",
    "            index_begin = BE[1]['index_begin']\n",
    "            index_end = BE[1]['index_end']\n",
    "            length_BE = BE[1]['length']\n",
    "            n_data = length_BE - n_seq + 1 - n_CNN_window + 1\n",
    "            assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "            \n",
    "            for i in range(n_data) :\n",
    "                lst_lst_X_data = []\n",
    "                lst_lst_y_data = []\n",
    "                for i2 in range(n_seq) :\n",
    "                    lst_lst_X_data += [df_ark.iloc[index_begin+i+i2:index_begin+i+i2+n_CNN_window].values.tolist()]\n",
    "#                     if df_BE is df_beginEnd_train :\n",
    "#                         lst_lst_y_data += [df_y_train_noId.iloc[index_begin+i+i2:index_begin+i+i2+n_CNN_window].values.tolist()]\n",
    "\n",
    "                lst_X_data += [lst_lst_X_data]\n",
    "                \n",
    "                #\n",
    "                # notice !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #\n",
    "                \n",
    "                if df_BE is df_beginEnd_train :\n",
    "                    lst_y_data += [df_y_train_noId.iloc[index_begin+i+int((n_CNN_window-1)/2):index_begin+i+n_seq+int((n_CNN_window-1)/2)].values.tolist()]\n",
    "\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "            ary_y_data = np.array(lst_y_data)\n",
    "            np.save('./data_pp/y_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_y_data)\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "    print ('finished making CNN data')\n",
    "# if if_making_RNN_data :\n",
    "# making_CNN_data(path_data,model_name,mfcc_or_fbank,n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess finished...\n",
      "show the data below : \n",
      "label_train_num.csv : \n",
      "                0   1\n",
      "0  maeb0_si1411_1  37\n",
      "1  maeb0_si1411_2  37\n",
      "2  maeb0_si1411_3  37\n",
      "lab_train_num_reindex_axis.csv : \n",
      "                0   1\n",
      "0  faem0_si1392_1  37\n",
      "1  faem0_si1392_2  37\n",
      "2  faem0_si1392_3  37\n",
      "3  faem0_si1392_4  37\n",
      "4  faem0_si1392_5  37\n",
      "beginEnd_train.csv : \n",
      "     speakerId sentenceId  index_begin  index_end  length\n",
      "3693     mzmb0      sx356      1124009    1124327     319\n",
      "3694     mzmb0      sx446      1124328    1124600     273\n",
      "3695     mzmb0       sx86      1124601    1124822     222\n",
      "beginEnd_test.csv : \n",
      "    speakerId sentenceId  index_begin  index_end  length\n",
      "589     mwew0      sx191       179535     179785     251\n",
      "590     mwew0      sx281       179786     180117     332\n",
      "591     mwew0      sx371       180118     180405     288\n",
      "X_test.shape :\n",
      "(179222, 3, 39)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# main (preprocessing)\n",
    "#\n",
    "def preprocessing(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window) :\n",
    "    # just for use. note just use mfcc is enough\n",
    "    train_ark_no_index_col = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    \n",
    "    \n",
    "\n",
    "    if not os.path.isfile('./data_pp/lab_train_num.csv') :\n",
    "        print ('creating lab_train_num.csv')\n",
    "        df_lab_train = pd.read_csv('{}label/train.lab'.format(path_data), index_col=0, header=None)\n",
    "        conv_48_to_char_or_num(df_lab_train,path_data,char_or_num='num')\n",
    "\n",
    "    if not os.path.isfile('./data_pp/lab_train_num_reindex_axis.csv') :\n",
    "        print ('creating lab_train_num_reindex_axis.csv')\n",
    "        lab_train_num = pd.read_csv('./data_pp/lab_train_num.csv', index_col=0)\n",
    "        lab_train_num_reindex_axis = lab_train_num.reindex_axis(train_ark_no_index_col[0], axis=0)\n",
    "        lab_train_num_reindex_axis.to_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "\n",
    "    if not os.path.isfile('./data_pp/beginEnd_train.csv') :\n",
    "        print ('creating BE')\n",
    "        making_beginEnd(path_data,mfcc_or_fbank)\n",
    "\n",
    "    if not os.path.isfile('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq)) :\n",
    "        print ('creating {}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "        if model_name == 'RNN' :\n",
    "            making_RNN_data(path_data,model_name,mfcc_or_fbank,n_seq)\n",
    "        elif model_name == 'CNN' :\n",
    "            making_CNN_data(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window)\n",
    "\n",
    "\n",
    "    print ('preprocess finished...')\n",
    "#     print ('show the data below : ')\n",
    "\n",
    "#     lab_train_num = pd.read_csv('./data_pp/lab_train_num.csv')\n",
    "#     print ('label_train_num.csv : ')\n",
    "#     print (lab_train_num.head(3))\n",
    "\n",
    "#     lab_train_num_reindex_axis = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "#     print ('lab_train_num_reindex_axis.csv : ')\n",
    "#     print (lab_train_num_reindex_axis.head(5))\n",
    "\n",
    "#     BE_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "#     BE_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "#     print ('beginEnd_train.csv : ')\n",
    "#     print (BE_train.tail(3))\n",
    "#     print ('beginEnd_test.csv : ')\n",
    "#     print (BE_test.tail(3))\n",
    "\n",
    "#     X_test = np.load('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "#     print ('X_test.shape :')\n",
    "#     print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面是test_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making beginEnd_train and beginEnd_test\n",
    "#\n",
    "def making_beginEnd_test_only(path_data,mfcc_or_fbank) :\n",
    "    start_time_tmp = time.time()\n",
    "#     df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "\n",
    "#     df_id_train = df_train_ark[0]\n",
    "    df_id_test = df_test_ark[0]\n",
    "\n",
    "    for df_id in [df_id_test] :\n",
    "        lst_beginEnd = []\n",
    "        for i,id in enumerate(df_id) :\n",
    "            lst_id = id.split('_')\n",
    "            if i == 0:\n",
    "                index_begin = i\n",
    "                speakerId = lst_id[0]\n",
    "                sentenceId = lst_id[1]\n",
    "            else : \n",
    "                frameId = lst_id[2]\n",
    "                if frameId == '1' :\n",
    "                    index_end = i - 1\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "                    index_begin = i\n",
    "                    speakerId = lst_id[0]\n",
    "                    sentenceId = lst_id[1]\n",
    "                elif i == len(df_id) - 1 :\n",
    "                    index_end = i\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "#         if df_id is df_id_train :\n",
    "#             print ('saving beginEnd_train')\n",
    "#             df_beginEnd_train = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "#             print (df_beginEnd_train.head(5))\n",
    "#             print (df_beginEnd_train.tail(5))\n",
    "#             df_beginEnd_train.to_csv('./data_pp/beginEnd_train.csv', index=None)\n",
    "\n",
    "#         elif df_id is df_id_test :\n",
    "        print ('saving beginEnd_test')\n",
    "        df_beginEnd_test = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "        print (df_beginEnd_test.head(5))\n",
    "        print (df_beginEnd_test.tail(5))\n",
    "        if not os.path.isdir('./data_pp') :\n",
    "            os.mkdir('./data_pp')\n",
    "        df_beginEnd_test.to_csv('./data_pp/beginEnd_test.csv', index=None)\n",
    "    print (\"making_beginEnd_test_only took\", str(time.time() - start_time_tmp), \"to run\")\n",
    "\n",
    "# if if_making_beginEnd :\n",
    "#     making_beginEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making RNN data \n",
    "#\n",
    "# need : beginEnd_train.csv, beginEnd_test.csv\n",
    "\n",
    "def making_RNN_data_test_only(path_data,model_name,mfcc_or_fbank,n_seq) :\n",
    "    start_time_tmp = time.time()\n",
    "#     df_y_train = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "#     df_y_train_noId = df_y_train.drop('0', axis=1)\n",
    "#     print (df_y_train_noId[:3])\n",
    "    \n",
    "#     df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "#     df_train_ark_noId = df_train_ark.drop(0, axis=1)\n",
    "    df_test_ark_noId = df_test_ark.drop(0, axis=1)\n",
    "#     print (df_train_ark_noId.iloc[:3])\n",
    "    \n",
    "    \n",
    "#     df_beginEnd_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "    df_beginEnd_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "#     print (df_beginEnd_train.head(5))\n",
    "#     print (df_beginEnd_train.tail(5))\n",
    "#     print (df_beginEnd_test.head(5))\n",
    "#     print (df_beginEnd_test.tail(5))    \n",
    "    for df_BE in [df_beginEnd_test] :\n",
    "        if df_BE is df_beginEnd_test :\n",
    "            print ('RNN_test is building...')\n",
    "            df_ark = df_test_ark_noId\n",
    "            \n",
    "        lst_X_data = []\n",
    "        lst_y_data = []\n",
    "        \n",
    "        for BE in df_BE.iterrows() :\n",
    "            index_begin = BE[1]['index_begin']\n",
    "            index_end = BE[1]['index_end']\n",
    "            length_BE = BE[1]['length']\n",
    "            n_data = length_BE - n_seq + 1\n",
    "            assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "            \n",
    "            for i in range(n_data) :\n",
    "                lst_X_data += [df_ark.iloc[index_begin+i:index_begin+i+n_seq].values.tolist()]\n",
    "#         if df_BE is df_beginEnd_train :\n",
    "#             ary_X_data = np.array(lst_X_data)\n",
    "#             np.save('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "#             ary_y_data = np.array(lst_y_data)\n",
    "#             np.save('./data_pp/y_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_y_data)\n",
    "#         elif df_BE is df_beginEnd_test :\n",
    "        ary_X_data = np.array(lst_X_data)\n",
    "        np.save('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "    print ('finished making RNN data')\n",
    "    print (\"making_RNN_data_test_only took\", str(time.time() - start_time_tmp), \"to run\")\n",
    "    return ary_X_data\n",
    "# if if_making_RNN_data :\n",
    "#     making_RNN_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making CNN data \n",
    "#\n",
    "# need : beginEnd_train.csv, beginEnd_test.csv\n",
    "\n",
    "def making_CNN_data_test_only(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window) :\n",
    "    start_time_tmp = time.time()\n",
    "#     df_y_train = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "#     df_y_train_noId = df_y_train.drop('0', axis=1)\n",
    "#     print (df_y_train_noId[:3])\n",
    "    \n",
    "#     df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "#     df_train_ark_noId = df_train_ark.drop(0, axis=1)\n",
    "    df_test_ark_noId = df_test_ark.drop(0, axis=1)\n",
    "#     print (df_train_ark_noId.iloc[:3])\n",
    "    \n",
    "    \n",
    "#     df_beginEnd_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "    df_beginEnd_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "    \n",
    "    for df_BE in [df_beginEnd_test] :\n",
    "        print ('test data is building...')\n",
    "        df_ark = df_test_ark_noId\n",
    "            \n",
    "        lst_X_data = []\n",
    "        lst_y_data = []\n",
    "        \n",
    "        for BE in df_BE.iterrows() :\n",
    "            index_begin = BE[1]['index_begin']\n",
    "            index_end = BE[1]['index_end']\n",
    "            length_BE = BE[1]['length']\n",
    "            n_data = length_BE - n_seq + 1 - n_CNN_window + 1\n",
    "            assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "            \n",
    "            for i in range(n_data) :\n",
    "                lst_lst_X_data = []\n",
    "                lst_lst_y_data = []\n",
    "                for i2 in range(n_seq) :\n",
    "                    lst_lst_X_data += [df_ark.iloc[index_begin+i+i2:index_begin+i+i2+n_CNN_window].values.tolist()]\n",
    "#                     if df_BE is df_beginEnd_train :\n",
    "#                         lst_lst_y_data += [df_y_train_noId.iloc[index_begin+i+i2:index_begin+i+i2+n_CNN_window].values.tolist()]\n",
    "\n",
    "                lst_X_data += [lst_lst_X_data]\n",
    "                \n",
    "                #\n",
    "                # notice !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #\n",
    "                \n",
    "#                 if df_BE is df_beginEnd_train :\n",
    "#                     lst_y_data += [df_y_train_noId.iloc[index_begin+i+int((n_CNN_window-1)/2):index_begin+i+n_seq+int((n_CNN_window-1)/2)].values.tolist()]\n",
    "\n",
    "#         if df_BE is df_beginEnd_train :\n",
    "#             ary_X_data = np.array(lst_X_data)\n",
    "#             np.save('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "#             ary_y_data = np.array(lst_y_data)\n",
    "#             np.save('./data_pp/y_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_y_data)\n",
    "#         elif df_BE is df_beginEnd_test :\n",
    "        ary_X_data = np.array(lst_X_data)\n",
    "        print (str(time.time() - start_time_tmp))\n",
    "        np.save('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "        print (str(time.time() - start_time_tmp))\n",
    "    print ('finished making CNN data')\n",
    "    print (\"making_CNN_data_test_only took\", str(time.time() - start_time_tmp), \"to run\")\n",
    "    return ary_X_data\n",
    "# if if_making_RNN_data :\n",
    "# making_CNN_data(path_data,model_name,mfcc_or_fbank,n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# main (preprocessing)\n",
    "#\n",
    "def preprocessing_test_only(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window) :\n",
    "#     # just for use. note just use mfcc is enough\n",
    "#     train_ark_no_index_col = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    \n",
    "    \n",
    "\n",
    "#     if not os.path.isfile('./data_pp/lab_train_num.csv') :\n",
    "#         print ('creating lab_train_num.csv')\n",
    "#         df_lab_train = pd.read_csv('{}label/train.lab'.format(path_data), index_col=0, header=None)\n",
    "#         conv_48_to_char_or_num(df_lab_train,path_data,char_or_num='num')\n",
    "\n",
    "#     if not os.path.isfile('./data_pp/lab_train_num_reindex_axis.csv') :\n",
    "#         print ('creating lab_train_num_reindex_axis.csv')\n",
    "#         lab_train_num = pd.read_csv('./data_pp/lab_train_num.csv', index_col=0)\n",
    "#         lab_train_num_reindex_axis = lab_train_num.reindex_axis(train_ark_no_index_col[0], axis=0)\n",
    "#         lab_train_num_reindex_axis.to_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "\n",
    "    if not os.path.isfile('./data_pp/beginEnd_test.csv'.format(path_data)) :\n",
    "        print ('creating BE')\n",
    "        making_beginEnd_test_only(path_data,mfcc_or_fbank)\n",
    "\n",
    "    if not os.path.isfile('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq)) :\n",
    "        print ('creating {}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "        if model_name == 'RNN' :\n",
    "            ary_X_data = making_RNN_data_test_only(path_data,model_name,mfcc_or_fbank,n_seq)\n",
    "        elif model_name == 'CNN' :\n",
    "            ary_X_data = making_CNN_data_test_only(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window)\n",
    "\n",
    "\n",
    "    print ('preprocess finished...')\n",
    "    return ary_X_data\n",
    "#     print ('show the data below : ')\n",
    "\n",
    "#     lab_train_num = pd.read_csv('./data_pp/lab_train_num.csv')\n",
    "#     print ('label_train_num.csv : ')\n",
    "#     print (lab_train_num.head(3))\n",
    "\n",
    "#     lab_train_num_reindex_axis = pd.read_csv('./data_pp/lab_train_num_reindex_axis.csv')\n",
    "#     print ('lab_train_num_reindex_axis.csv : ')\n",
    "#     print (lab_train_num_reindex_axis.head(5))\n",
    "\n",
    "#     BE_train = pd.read_csv('./data_pp/beginEnd_train.csv')\n",
    "#     BE_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "#     print ('beginEnd_train.csv : ')\n",
    "#     print (BE_train.tail(3))\n",
    "#     print ('beginEnd_test.csv : ')\n",
    "#     print (BE_test.tail(3))\n",
    "\n",
    "#     X_test = np.load('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "#     print ('X_test.shape :')\n",
    "#     print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
