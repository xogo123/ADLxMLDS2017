{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# require :\n",
    "# data/data_pp/lab_train_num.csv because it needs to run 1 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_user_train = 462\n",
    "n_user_test = 74\n",
    "n_sen_train = 1716\n",
    "n_sen_test = 342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'data/'\n",
    "model_name = 'RNN'\n",
    "mfcc_or_fbank = 'mfcc'\n",
    "n_seq = 5\n",
    "\n",
    "if_making_beginEnd = 0\n",
    "\n",
    "# RNN seting\n",
    "# if_making_RNN_data = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# map 48 to char or num\n",
    "#\n",
    "def conv_48_to_char_or_num(df_lab_train,char_or_num='num') :\n",
    "    path_save = '{}data_pp/'.format(path_data)\n",
    "    \n",
    "    map_48_39 = pd.read_csv('{}phones/48_39.map'.format(path_data), header=None, delimiter='\\t')\n",
    "#     print (map_48_39.head(5))\n",
    "    map_48phone_char = pd.read_csv('{}48phone_char.map'.format(path_data), header=None, delimiter='\\t')\n",
    "#     print (map_48phone_char.head(5))\n",
    "#     lab_train = pd.read_csv('{}label/train.lab'.format(path_data), index_col=0, header=None)\n",
    "#     print (lab_train.head(5))\n",
    "\n",
    "    dict_map_39char = dict()\n",
    "    dict_map_39num = dict()\n",
    "    for name in map_48phone_char.iterrows() :\n",
    "        #dict_map_39char[name[1][0]] = name[1][2]\n",
    "        dict_map_39num[name[1][0]] = name[1][1]\n",
    "\n",
    "    dict_map_48char = dict()\n",
    "    dict_map_48num = dict()\n",
    "    for name in map_48_39.iterrows() :\n",
    "        #dict_map_48char[name[1][0]] = dict_map_39char[name[1][1]]\n",
    "        dict_map_48num[name[1][0]] = dict_map_39num[name[1][1]]\n",
    "\n",
    "\n",
    "    print (dict_map_48num)    \n",
    "    len_lab_train = df_lab_train.shape[0]\n",
    "    for i,lab in enumerate(df_lab_train[1]) :\n",
    "        sys.stdout.write('\\r{}/{} \\t'.format(i,len_lab_train))\n",
    "        sys.stdout.flush()\n",
    "        df_lab_train[1][i] = dict_map_48num[lab]\n",
    "        \n",
    "    df_lab_train.to_csv('{}lab_train_num.csv'.format(path_save))\n",
    "\n",
    "    #return df_lab_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making beginEnd_train and beginEnd_test\n",
    "#\n",
    "def making_beginEnd() :\n",
    "    df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "\n",
    "    df_id_train = df_train_ark[0]\n",
    "    df_id_test = df_test_ark[0]\n",
    "\n",
    "    for df_id in [df_id_train, df_id_test] :\n",
    "        lst_beginEnd = []\n",
    "        for i,id in enumerate(df_id) :\n",
    "            lst_id = id.split('_')\n",
    "            if i == 0:\n",
    "                index_begin = i\n",
    "                speakerId = lst_id[0]\n",
    "                sentenceId = lst_id[1]\n",
    "            else : \n",
    "                frameId = lst_id[2]\n",
    "                if frameId == '1' :\n",
    "                    index_end = i - 1\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "                    index_begin = i\n",
    "                    speakerId = lst_id[0]\n",
    "                    sentenceId = lst_id[1]\n",
    "                elif i == len(df_id) - 1 :\n",
    "                    index_end = i\n",
    "                    length = index_end - index_begin + 1\n",
    "                    lst_beginEnd += [[speakerId,sentenceId,index_begin,index_end,length]]\n",
    "        if df_id is df_id_train :\n",
    "            print ('saving beginEnd_train')\n",
    "            df_beginEnd_train = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "            print (df_beginEnd_train.head(5))\n",
    "            print (df_beginEnd_train.tail(5))\n",
    "            df_beginEnd_train.to_csv('{}data_pp/beginEnd_train.csv'.format(path_data), index=None)\n",
    "\n",
    "        elif df_id is df_id_test :\n",
    "            print ('saving beginEnd_test')\n",
    "            df_beginEnd_test = pd.DataFrame(np.array(lst_beginEnd), columns=['speakerId','sentenceId','index_begin','index_end','length'])\n",
    "            print (df_beginEnd_test.head(5))\n",
    "            print (df_beginEnd_test.tail(5))\n",
    "            df_beginEnd_test.to_csv('{}data_pp/beginEnd_test.csv'.format(path_data), index=None)\n",
    "            \n",
    "# if if_making_beginEnd :\n",
    "#     making_beginEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# making RNN data \n",
    "#\n",
    "# need : beginEnd_train.csv, beginEnd_test.csv\n",
    "\n",
    "def making_RNN_data() :\n",
    "    df_y_train = pd.read_csv('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data))\n",
    "    df_y_train_noId = df_y_train.drop('0', axis=1)\n",
    "#     print (df_y_train_noId[:3])\n",
    "    \n",
    "    df_train_ark = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_test_ark = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "    df_train_ark_noId = df_train_ark.drop(0, axis=1)\n",
    "    df_test_ark_noId = df_test_ark.drop(0, axis=1)\n",
    "#     print (df_train_ark_noId.iloc[:3])\n",
    "    \n",
    "    \n",
    "    df_beginEnd_train = pd.read_csv('{}data_pp/beginEnd_train.csv'.format(path_data))\n",
    "    df_beginEnd_test = pd.read_csv('{}data_pp/beginEnd_test.csv'.format(path_data))\n",
    "#     print (df_beginEnd_train.head(5))\n",
    "#     print (df_beginEnd_train.tail(5))\n",
    "#     print (df_beginEnd_test.head(5))\n",
    "#     print (df_beginEnd_test.tail(5))    \n",
    "    for df_BE in [df_beginEnd_train,df_beginEnd_test] :\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            print ('RNN_train is building...')\n",
    "            df_ark = df_train_ark_noId\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            print ('RNN_test is building...')\n",
    "            df_ark = df_test_ark_noId\n",
    "            \n",
    "        lst_X_data = []\n",
    "        lst_y_data = []\n",
    "        \n",
    "        for BE in df_BE.iterrows() :\n",
    "            index_begin = BE[1]['index_begin']\n",
    "            index_end = BE[1]['index_end']\n",
    "            length_BE = BE[1]['length']\n",
    "            n_data = length_BE - n_seq + 1\n",
    "            assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "            \n",
    "            for i in range(n_data) :\n",
    "                lst_X_data += [df_ark.iloc[index_begin+i:index_begin+i+n_seq].values.tolist()]\n",
    "                if df_BE is df_beginEnd_train :\n",
    "                    lst_y_data += [df_y_train_noId.iloc[index_begin+i:index_begin+i+n_seq].values.tolist()]\n",
    "\n",
    "        if df_BE is df_beginEnd_train :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('{}data_pp/X_train_{}_{}_{}.npy'.format(path_data, model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "            ary_y_data = np.array(lst_y_data)\n",
    "            np.save('{}data_pp/y_train_{}_{}_{}.npy'.format(path_data,model_name, mfcc_or_fbank, n_seq), ary_y_data)\n",
    "        elif df_BE is df_beginEnd_test :\n",
    "            ary_X_data = np.array(lst_X_data)\n",
    "            np.save('{}data_pp/X_test_{}_{}_{}.npy'.format(path_data,model_name, mfcc_or_fbank, n_seq), ary_X_data)\n",
    "    print ('finished making RNN data')\n",
    "# if if_making_RNN_data :\n",
    "#     making_RNN_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess finished...\n",
      "show the data below : \n",
      "label_train_num.csv : \n",
      "                0   1\n",
      "0  maeb0_si1411_1  37\n",
      "1  maeb0_si1411_2  37\n",
      "2  maeb0_si1411_3  37\n",
      "lab_train_num_reindex_axis.csv : \n",
      "                0   1\n",
      "0  faem0_si1392_1  37\n",
      "1  faem0_si1392_2  37\n",
      "2  faem0_si1392_3  37\n",
      "3  faem0_si1392_4  37\n",
      "4  faem0_si1392_5  37\n",
      "beginEnd_train.csv : \n",
      "     speakerId sentenceId  index_begin  index_end  length\n",
      "3693     mzmb0      sx356      1124009    1124327     319\n",
      "3694     mzmb0      sx446      1124328    1124600     273\n",
      "3695     mzmb0       sx86      1124601    1124822     222\n",
      "beginEnd_test.csv : \n",
      "    speakerId sentenceId  index_begin  index_end  length\n",
      "589     mwew0      sx191       179535     179785     251\n",
      "590     mwew0      sx281       179786     180117     332\n",
      "591     mwew0      sx371       180118     180405     288\n",
      "X_test.shape :\n",
      "(179222, 3, 39)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# main (preprocessing)\n",
    "#\n",
    "\n",
    "# just for use\n",
    "train_ark_no_index_col = pd.read_csv('{}mfcc/train.ark'.format(path_data), header=None, delimiter=' ')\n",
    "\n",
    "if not os.path.isfile('{}data_pp/lab_train_num.csv'.format(path_data)) :\n",
    "    print ('creating lab_train_num.csv')\n",
    "    conv_48_to_char_or_num(lab_train,char_or_num='num')\n",
    "\n",
    "if not os.path.isfile('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data)) :\n",
    "    print ('creating lab_train_num_reindex_axis.csv')\n",
    "    lab_train_num = pd.read_csv('{}data_pp/lab_train_num.csv'.format(path_data), index_col=0)\n",
    "    lab_train_num_reindex_axis = lab_train_num.reindex_axis(train_ark_no_index_col[0], axis=0)\n",
    "    lab_train_num_reindex_axis.to_csv('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data))\n",
    "    \n",
    "if not os.path.isfile('{}data_pp/beginEnd_test.csv'.format(path_data)) :\n",
    "    print ('creating BE')\n",
    "    making_beginEnd()\n",
    "    \n",
    "if not os.path.isfile('{}data_pp/X_test_{}_{}_{}.npy'.format(path_data,model_name, mfcc_or_fbank, n_seq)) :\n",
    "    print ('creating {}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "    making_RNN_data()\n",
    "\n",
    "\n",
    "print ('preprocess finished...')\n",
    "print ('show the data below : ')\n",
    "\n",
    "lab_train_num = pd.read_csv('{}data_pp/lab_train_num.csv'.format(path_data))\n",
    "print ('label_train_num.csv : ')\n",
    "print (lab_train_num.head(3))\n",
    "\n",
    "lab_train_num_reindex_axis = pd.read_csv('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data))\n",
    "print ('lab_train_num_reindex_axis.csv : ')\n",
    "print (lab_train_num_reindex_axis.head(5))\n",
    "\n",
    "BE_train = pd.read_csv('{}data_pp/beginEnd_train.csv'.format(path_data))\n",
    "BE_test = pd.read_csv('{}data_pp/beginEnd_test.csv'.format(path_data))\n",
    "print ('beginEnd_train.csv : ')\n",
    "print (BE_train.tail(3))\n",
    "print ('beginEnd_test.csv : ')\n",
    "print (BE_test.tail(3))\n",
    "\n",
    "X_test = np.load('{}data_pp/X_test_{}_{}_{}.npy'.format(path_data,model_name, mfcc_or_fbank, n_seq))\n",
    "print ('X_test.shape :')\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('{}data_pp/X_train_{}{}.pkl'.format(path_data,mfcc_or_fbank,n_seq), 'rb') as f:\n",
    "#     lst_X_train = pickle.load(f)\n",
    "# with open('{}data_pp/y_train_{}{}.pkl'.format(path_data,mfcc_or_fbank,n_seq), 'rb') as f:\n",
    "#     lst_y_train = pickle.load(f)\n",
    "# with open('{}data_pp/X_test_{}{}.pkl'.format(path_data,mfcc_or_fbank,n_seq), 'rb') as f:\n",
    "#     lst_X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面先不要看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train = pd.read_csv('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data))\n",
    "# y_train.drop('0',axis=1, inplace=True)\n",
    "# y_train.to_csv('{}data_pp/y_train.csv'.format(path_data), index=False)\n",
    "# y_train = pd.read_csv('{}data_pp/y_train.csv'.format(path_data))\n",
    "# print (y_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('{}{}/train.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "# X_train.drop(0,axis=1, inplace=True)\n",
    "# X_train.to_csv('{}data_pp/X_train_{}.csv'.format(path_data,mfcc_or_fbank), index=False)\n",
    "# X_train = pd.read_csv('{}data_pp/X_train_{}.csv'.format(path_data,mfcc_or_fbank))\n",
    "# print (X_train.head(5))\n",
    "\n",
    "# y_train = pd.read_csv('{}data_pp/lab_train_num_reindex_axis.csv'.format(path_data))\n",
    "# y_train.drop('0',axis=1, inplace=True) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! different (0 and'0') because preprocessing above\n",
    "# y_train.to_csv('{}data_pp/y_train.csv'.format(path_data), index=False)\n",
    "# y_train = pd.read_csv('{}data_pp/y_train.csv'.format(path_data))\n",
    "# print (y_train.head(5))\n",
    "\n",
    "# X_test = pd.read_csv('{}{}/test.ark'.format(path_data,mfcc_or_fbank), header=None, delimiter=' ')\n",
    "# X_test.drop(0,axis=1, inplace=True)\n",
    "# X_test.to_csv('{}data_pp/X_test_{}.csv'.format(path_data,mfcc_or_fbank), index=False)\n",
    "# X_test = pd.read_csv('{}data_pp/X_test_{}.csv'.format(path_data,mfcc_or_fbank))\n",
    "# print (X_test.head(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #\n",
    "# # preprocessing testing data\n",
    "# #\n",
    "# test_ark = pd.read_csv('{}mfcc/test.ark'.format(path_data), header=None, delimiter=' ')\n",
    "# # print ('test.shape = ' + str(test_ark.shape))\n",
    "# # print (test_ark.head(5))\n",
    "\n",
    "# test_ark.drop(0,axis=1, inplace=True)\n",
    "# test_ark.reset_index(drop=True, inplace=True)\n",
    "# print (test_ark.head(5))\n",
    "# print ('test.shape = ' + str(test_ark.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__' :\n",
    "#     if if_conv_48_to_char_or_num :\n",
    "#         conv_48_to_char_or_num(lab_train,char_or_num='num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
