{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strating time is 1509021769.0982752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "print ('strating time is {}'.format(start_time))\n",
    "import preprocessing\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# from keras.layers import GRU, LSTM, Dropout, Dense, Input, TimeDistributed, Activation, Flatten, Concatenate\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "# from keras.callbacks import *\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# def init():\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     session = tf.Session(config=config)\n",
    "#     keras.backend.tensorflow_backend.set_session(session)\n",
    "\n",
    "# init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_only = 1\n",
    "\n",
    "# path_data = 'data/'\n",
    "# str_output = 'ans.csv'\n",
    "\n",
    "if len(sys.argv) == 1 :\n",
    "    # default setting\n",
    "    path_data = 'data/'\n",
    "    str_output = 'ans_cnn.csv'\n",
    "else :\n",
    "    path_data = sys.argv[1]\n",
    "    str_output = sys.argv[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_log_plot(log) :\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    fig = plt.figure(1,figsize=(20,10))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(log['acc'], label='train_acc')\n",
    "    plt.plot(log['val_acc'], label='val_acc')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('acc', fontsize=20, color='black')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(log['loss'], label='train_loss')\n",
    "    plt.plot(log['val_loss'], label='val_loss')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xlabel('epoch', fontsize=20, color='black')\n",
    "    plt.ylabel('loss', fontsize=20, color='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# RNN model\n",
    "#\n",
    "def RNN_model() :\n",
    "    dr_r = 0.5\n",
    "    I = Input(shape=((n_seq,dim))) # shape = (?,1,200,2)\n",
    "#     gru1 = GRU(32, activation='relu', dropout=0.0, return_sequences=True)(I)\n",
    "#     gru2 = GRU(32, activation='relu', dropout=0.0, return_sequences=True)(gru1)\n",
    "#     gru3 = GRU(64, activation='relu', dropout=0.0, return_sequences=True)(gru2)\n",
    "#     gru4 = GRU(64, activation='relu', dropout=0.0, return_sequences=True)(gru3)\n",
    "    \n",
    "#     gru12 = GRU(32, activation='relu', dropout=0.0, return_sequences=True, go_backwards=True)(I)\n",
    "#     gru22 = GRU(32, activation='relu', dropout=0.0, return_sequences=True, go_backwards=True)(gru12)\n",
    "#     gru32 = GRU(64, activation='relu', dropout=0.0, return_sequences=True, go_backwards=True)(gru22)\n",
    "#     gru42 = GRU(64, activation='relu', dropout=0.0, return_sequences=True, go_backwards=True)(gru32)\n",
    "    \n",
    "#     F1 = Flatten()(gru4)\n",
    "#     F2 = Flatten()(gru42)\n",
    "#     C1 = Concatenate()([F1,F2])\n",
    "#     Dr1 = Dropout(dr_r)(C1)\n",
    "\n",
    "    if GL == 'LSTM' :\n",
    "        B1 = wrappers.Bidirectional(LSTM(64, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(I)\n",
    "        B2 = wrappers.Bidirectional(LSTM(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B1)\n",
    "        B3 = wrappers.Bidirectional(LSTM(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        B4 = wrappers.Bidirectional(LSTM(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B3)\n",
    "    elif GL == 'GRU' :\n",
    "        #B1 = wrappers.Bidirectional(GRU(39, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(I)\n",
    "        #B2 = wrappers.Bidirectional(GRU(39, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B1)\n",
    "        #B4 = wrappers.Bidirectional(GRU(78, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        \n",
    "        B1 = wrappers.Bidirectional(GRU(39, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(I)\n",
    "        B4 = wrappers.Bidirectional(GRU(96, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B1)\n",
    "        \n",
    "        #B1 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(I)\n",
    "        #B2 = wrappers.Bidirectional(GRU(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B1)\n",
    "        #B3 = wrappers.Bidirectional(GRU(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        #B4 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        \n",
    "        \n",
    "    #gru100 = GRU(48, activation='softmax', dropout=0.0, return_sequences=True)(B4)\n",
    "    gru100 = wrappers.Bidirectional(GRU(48, activation='softmax', dropout=0.0, return_sequences=True), merge_mode='ave', weights=None)(B4)\n",
    "\n",
    "    model = Model(I,gru100)\n",
    "    model.compile(#loss='mean_squared_error',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      #loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      #optimizer='adam',\n",
    "                      #optimizer='sgd',\n",
    "                      metrics=['acc']) #'mae'\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# CNN model\n",
    "#\n",
    "def CNN_model(n_CNN_window) :\n",
    "    dr_r = 0.5\n",
    "    if mfcc_or_fbank == 'mfcc' :\n",
    "        I = Input(shape=((n_seq,n_CNN_window,int(dim/n_CNN_window),n_CNN_window))) # shape = (?,1,200,2)\n",
    "    if GL == 'LSTM' :\n",
    "        B1 = wrappers.Bidirectional(LSTM(64, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(I)\n",
    "        B2 = wrappers.Bidirectional(LSTM(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B1)\n",
    "        B3 = wrappers.Bidirectional(LSTM(128, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        B4 = wrappers.Bidirectional(LSTM(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B3)\n",
    "    elif GL == 'GRU' :\n",
    "# 7\n",
    "        T1 = TimeDistributed(Conv2D(32,(3,1), strides=(1,1), activation='elu'))(I)\n",
    "        #T2 = TimeDistributed(Conv2D(64,(1,3), strides=(1,1), activation='elu'))(T1)\n",
    "        #TM1 = TimeDistributed(MaxPooling2D(pool_size=(1,2), strides=(1,1), padding='valid'))(T2)\n",
    "        T3 = TimeDistributed(Flatten())(T1)\n",
    "        #B1 = wrappers.Bidirectional(GRU(32, activation='elu', dropout=0.0, return_sequences=True), merge_mode='concat', weights=None)(T3)\n",
    "        B2 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(T3)\n",
    "        B4 = wrappers.Bidirectional(GRU(128, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "# 5\n",
    "#         T1 = TimeDistributed(Conv2D(32,(3,1), strides=(1,1), activation='elu'))(I)\n",
    "#         T2 = TimeDistributed(Conv2D(32,(1,3), strides=(1,1), activation='elu'))(T1)\n",
    "#         T3 = TimeDistributed(Flatten())(T2)\n",
    "#         B2 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(T3)\n",
    "#         B4 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "\n",
    "# 6        \n",
    "#         #T1 = TimeDistributed(Conv2D(16,(3,2), strides=(1,1), activation='elu'))(I)\n",
    "#         T1 = TimeDistributed(Conv2D(128,(3,1), strides=(1,1), activation='elu'))(I)\n",
    "#         T3 = TimeDistributed(Flatten())(T1)\n",
    "#         B2 = wrappers.Bidirectional(GRU(32, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(T3)\n",
    "#         B4 = wrappers.Bidirectional(GRU(64, activation='elu', dropout=dr_r, return_sequences=True), merge_mode='concat', weights=None)(B2)\n",
    "        \n",
    "    gru100 = wrappers.Bidirectional(GRU(48, activation='softmax', dropout=0.0, return_sequences=True), merge_mode='ave')(B4)\n",
    "\n",
    "    model = Model(I,gru100)\n",
    "    model.compile(#loss='mean_squared_error',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      #loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      #optimizer='adam',\n",
    "                      #optimizer='sgd',\n",
    "                      metrics=['acc']) #'mae'\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_to_ans(ary_pred, model_name, mfcc_or_fbank, n_seq, GL, size_window, n_CNN_window, k) :\n",
    "    def num_to_char(ary_pred_num) :\n",
    "        map_48phone_char = pd.read_csv('{}48phone_char.map'.format(path_data), header=None, delimiter='\\t')\n",
    "        dict_map_48phone_char = dict()\n",
    "        for row in map_48phone_char.iterrows() :\n",
    "            #dict_map_48char[name[1][0]] = dict_map_39char[name[1][1]]\n",
    "            dict_map_48phone_char[row[1][1]] = row[1][2]\n",
    "        flat = ary_pred_num.flatten()\n",
    "        flat_copy = flat.copy().astype(str)\n",
    "        for i,num in enumerate(flat) :\n",
    "            flat_copy[i] = dict_map_48phone_char[num]\n",
    "        ary_pred_char = flat_copy.reshape((-1,n_seq))\n",
    "        return ary_pred_char\n",
    "\n",
    "    def find_mass_row(string) :\n",
    "        dict_count = dict()\n",
    "        for item in string :\n",
    "            try :\n",
    "                dict_count[item] += 1\n",
    "            except :\n",
    "                dict_count[item] = 1\n",
    "        max_item = max(dict_count, key=dict_count.get)\n",
    "        return max_item\n",
    "    \n",
    "    def find_mass_column(ary_pred, i_data_total) :\n",
    "        dict_count = dict()\n",
    "        for i in range(n_seq) :\n",
    "            item = ary_pred[i_data_total-n_seq+1+i][n_seq-1-i]\n",
    "            try :\n",
    "                dict_count[item] += 1\n",
    "            except :\n",
    "                dict_count[item] = 1\n",
    "        max_item = max(dict_count, key=dict_count.get)\n",
    "        return max_item\n",
    "    \n",
    "    def to_str_final(string) :\n",
    "        #\n",
    "        # combine two char if they are same\n",
    "        #\n",
    "        str_final = string[0]\n",
    "        for c in string[1:] :\n",
    "            if c != str_final[-1] :\n",
    "                str_final += c\n",
    "        #\n",
    "        # cut all sil in the begining\n",
    "        #\n",
    "        if str_final[0] == 'L' :\n",
    "            str_final = str_final[1:]\n",
    "            \n",
    "        if str_final[-1] == 'L' :\n",
    "            str_final = str_final[:-1]\n",
    "            \n",
    "        return str_final\n",
    "    \n",
    "    df_BE_test = pd.read_csv('./data_pp/beginEnd_test.csv')\n",
    "    \n",
    "    ary_pred_num = np.argmax(ary_pred, axis=2)\n",
    "    #print (ary_pred_num[200:206])\n",
    "    ary_pred_char = num_to_char(ary_pred_num)\n",
    "    \n",
    "    lst_X_data = []\n",
    "    i_data_total = 0 # for loop use\n",
    "    ans = []\n",
    "    for BE in df_BE_test.iterrows() :\n",
    "        index_begin = BE[1]['index_begin']\n",
    "        index_end = BE[1]['index_end']\n",
    "        length_BE = BE[1]['length']\n",
    "        if model_name == 'RNN' :\n",
    "            n_data = length_BE - n_seq + 1\n",
    "        elif model_name == 'CNN' :\n",
    "            n_data = length_BE - n_seq + 1 - n_CNN_window + 1\n",
    "        assert n_data >= 1, 'n_data should bigger than 1, please do checking'\n",
    "        \n",
    "        str_temp = ''\n",
    "        str_temp_2 = ''\n",
    "        for i_data in range(n_data) :\n",
    "            dic_temp = dict()\n",
    "            if (i_data < n_seq - 1) : # don't count the begining and end sequence\n",
    "                i_data_total += 1\n",
    "                continue\n",
    "            else :\n",
    "                str_temp += str(find_mass_column(ary_pred_char, i_data_total))\n",
    "                i_data_total += 1\n",
    "        assert len(str_temp) == n_data - n_seq + 1, 'len(str_temp) != n_data - n_seq + 1, please check'\n",
    "        \n",
    "        for t in range(len(str_temp) - size_window + 1) :\n",
    "            str_temp_2 += str(find_mass_row(str_temp[t:t+size_window]))\n",
    "        assert len(str_temp_2) == len(str_temp) - size_window + 1, 'len(str_temp_2) != len(str_temp) - size_window + 1, please check'\n",
    "        \n",
    "        str_final = to_str_final(str_temp_2)\n",
    "        \n",
    "        ans += [str_final]\n",
    "        \n",
    "    print ('max_len_ans : {}'.format(max(len(x) for x in ans)))\n",
    "    \n",
    "    sample = pd.read_csv('./sample.csv')\n",
    "    assert len(sample['phone_sequence']) == len(ans), 'len(sample[\\'phone_sequence\\']) != len(ans), please check'\n",
    "    \n",
    "    sample['phone_sequence'] = pd.DataFrame(ans)\n",
    "    if test_only :\n",
    "        sample.to_csv(str_output, index=False)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_training(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window) :\n",
    "    #\n",
    "    # loading data\n",
    "    #\n",
    "    X_train = np.load('./data_pp/X_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "    y_train = np.load('./data_pp/y_train_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "    \n",
    "    y_train = y_train.reshape((-1))\n",
    "    \n",
    "    if model_name == 'RNN' :\n",
    "        y_train_dummy = to_categorical(y_train, num_classes=48)\n",
    "        y_train_dummy = y_train_dummy.reshape((-1,n_seq,48))\n",
    "    \n",
    "    if model_name == 'CNN' :\n",
    "        X_train = X_train.reshape((-1,n_seq,n_CNN_window,int(dim/n_CNN_window),n_CNN_window))\n",
    "        y_train = y_train.reshape((-1,n_seq,n_CNN_window))\n",
    "        y_train_dummy = to_categorical(y_train, num_classes=48)\n",
    "        y_train_dummy = y_train_dummy.reshape((-1,n_seq,48))\n",
    "        print ('X_train.shape : ')\n",
    "        print (X_train.shape)\n",
    "        print ('y_train_dummy.shape : ')\n",
    "        print (y_train_dummy.shape)\n",
    "    \n",
    "    if not os.path.isdir('./model') :\n",
    "        os.mkdir('./model')\n",
    "\n",
    "    k = 1\n",
    "    while(1) :\n",
    "        if not os.path.isfile('./model/{}_{}_{}_{}_{}.h5'.format(model_name, mfcc_or_fbank, n_seq, GL, k)) :\n",
    "            break\n",
    "        k += 1\n",
    "    MCP = keras.callbacks.ModelCheckpoint('./model/{}_{}_{}_{}_{}.h5'.format(model_name, mfcc_or_fbank, n_seq, GL, k), monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    #RM = keras.callbacks.RemoteMonitor(root='http://localhost:12333', path='/publish/epoch/end/', field='data', headers=None)\n",
    "\n",
    "    if model_name == 'RNN' :\n",
    "        model = RNN_model()\n",
    "    elif model_name == 'CNN' :\n",
    "        model = CNN_model(n_CNN_window)\n",
    "    log = model.fit(X_train, y_train_dummy, epochs=50, batch_size=batch_size, validation_split=0.1, callbacks=[MCP,ES])\n",
    "    df_log = log.history\n",
    "    fig = keras_log_plot(df_log)\n",
    "#     df_history = pd.DataFrame(log.history)\n",
    "#     plot = df_history[['acc','val_acc']].plot()\n",
    "#     fig = plot.get_figure()\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.plot(df_history)\n",
    "    \n",
    "    if not os.path.isdir('./log_plot') :\n",
    "        os.mkdir('./log_plot')\n",
    "    fig.savefig('./log_plot/{}_{}_{}_{}_{}.png'.format(model_name, mfcc_or_fbank, n_seq, GL, k))\n",
    "    \n",
    "    return k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_testing(lst_size_window, n_CNN_window, k) :\n",
    "    #\n",
    "    # loading data\n",
    "    #\n",
    "    X_test = np.load('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "    model = load_model('./model/{}_{}_{}_{}.h5'.format(model_name, mfcc_or_fbank, n_seq, GL))\n",
    "    plot_model(model, to_file='./model/{}_{}_{}_{}.png'.format(model_name, mfcc_or_fbank, n_seq, GL))\n",
    "    \n",
    "    if model_name == 'CNN' :\n",
    "        X_test = X_test.reshape((-1,n_seq,n_CNN_window,int(dim/n_CNN_window),n_CNN_window))\n",
    "        print ('X_test.shape : ')\n",
    "        print (X_test.shape)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    for size_window in lst_size_window :\n",
    "        ans = predict_to_ans(pred, model_name, mfcc_or_fbank, n_seq, GL, size_window, n_CNN_window, k)\n",
    "        print (ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_testing_test_only(X_test, lst_size_window, n_CNN_window, k) :\n",
    "    #\n",
    "    # loading data\n",
    "    #\n",
    "    #X_test = np.load('./data_pp/X_test_{}_{}_{}.npy'.format(model_name, mfcc_or_fbank, n_seq))\n",
    "    model = load_model('./model/{}_{}_{}_{}.h5'.format(model_name, mfcc_or_fbank, n_seq, GL))\n",
    "    plot_model(model, to_file='./model/{}_{}_{}_{}.png'.format(model_name, mfcc_or_fbank, n_seq, GL))\n",
    "    \n",
    "    if model_name == 'CNN' :\n",
    "        X_test = X_test.reshape((-1,n_seq,n_CNN_window,int(dim/n_CNN_window),n_CNN_window))\n",
    "        print ('X_test.shape : ')\n",
    "        print (X_test.shape)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    for size_window in lst_size_window :\n",
    "        ans = predict_to_ans(pred, model_name, mfcc_or_fbank, n_seq, GL, size_window, n_CNN_window, k)\n",
    "        print (ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating RNN_mfcc_13.npy\n",
      "RNN_test is building...\n",
      "finished making RNN data\n",
      "making_RNN_data_test_only took 50.38582110404968 to run\n",
      "preprocess finished...\n",
      "do testing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f5ba06b3d73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmfcc_or_fbank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_CNN_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'do testing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdo_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_size_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_CNN_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"My program took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c6665924c010>\u001b[0m in \u001b[0;36mdo_testing\u001b[0;34m(lst_size_window, n_CNN_window, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msize_window\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_size_window\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_to_ans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc_or_fbank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_CNN_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lst_size_window = [7] # for pred_to_ans\n",
    "n_CNN_window = 3\n",
    "n_seq = 9\n",
    "k = 1\n",
    "\n",
    "mfcc_or_fbank = 'mfcc'\n",
    "model_name = 'CNN' # CNN or RNN\n",
    "GL = 'GRU' # GRU or LSTM \n",
    "\n",
    "if mfcc_or_fbank == 'mfcc' :\n",
    "    dim = 39\n",
    "else :\n",
    "    dim = 69\n",
    "\n",
    "# for traingin \n",
    "batch_size = 1024\n",
    "\n",
    "if test_only :\n",
    "    X_test = preprocessing.preprocessing_test_only(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window)\n",
    "    print ('do testing...')\n",
    "    do_testing_test_only(X_test, lst_size_window, n_CNN_window, k)\n",
    "else :\n",
    "    preprocessing.preprocessing(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window)\n",
    "    k = do_training(path_data,model_name,mfcc_or_fbank,n_seq,n_CNN_window)\n",
    "    print ('do testing...')\n",
    "    do_testing(lst_size_window, n_CNN_window, k)\n",
    "    \n",
    "print (\"My program took\", str(time.time() - start_time), \"to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
