{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "import scipy\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "def leaky_relu(features, alpha=0.2, name=None):\n",
    "    with ops.name_scope(name, \"LeakyRelu\", [features, alpha]):\n",
    "        features = ops.convert_to_tensor(features, name=\"features\")\n",
    "        alpha = ops.convert_to_tensor(alpha, name=\"alpha\")\n",
    "        return math_ops.maximum(alpha * features, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argument setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "img_n = 5\n",
    "batch_size = 16\n",
    "d_lda = 10\n",
    "\n",
    "if len(sys.argv) > 1 :\n",
    "    text_path = sys.argv[1]\n",
    "else :\n",
    "    text_path = './data/testing_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self) :\n",
    "        self.lr = 0.0001\n",
    "        self.lr_pre = 0.0001\n",
    "        self.momentum = 0.5\n",
    "        self.bs = batch_size # batch size is m of paper\n",
    "        self.bs_pre = 128\n",
    "        self.epoch = 10000\n",
    "        self.hair_n = 13\n",
    "        self.eyes_n = 12\n",
    "        self.lda = d_lda\n",
    "        self.epsilon = 0.5\n",
    "        self.activation = leaky_relu\n",
    "        self.initializer = tf.contrib.keras.initializers.he_normal()\n",
    "            \n",
    "    def build_G_net(self) :\n",
    "        with tf.variable_scope('G') as g_scope:\n",
    "            self.G_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.G_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.G_in_noise = tf.placeholder(tf.float32, shape=[None,100])\n",
    "            \n",
    "            self.G_H_onehot = tf.one_hot(self.G_in_hair, self.hair_n)\n",
    "            self.G_E_onehot = tf.one_hot(self.G_in_eyes, self.eyes_n)\n",
    "            g = tf.concat([self.G_H_onehot, self.G_E_onehot, self.G_in_noise], axis=1)\n",
    "            g = tf.layers.dense(g,4*4*1024,activation=None)\n",
    "            g = tf.reshape(g,(-1,4,4,1024))\n",
    "            \n",
    "            g = tf.layers.conv2d_transpose(g, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            self.g = tf.layers.conv2d_transpose(g, filters=3, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=tf.nn.tanh)\n",
    "        \n",
    "    def build_D_net(self) :\n",
    "\n",
    "        with tf.variable_scope('D') as d_scope:\n",
    "\n",
    "            ### include right and fake1\n",
    "            self.D_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.D_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.D_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3])\n",
    "#             self.D_in_img = self.D_in_img*2 - 1\n",
    "            \n",
    "            D_H_onehot = tf.one_hot(self.D_in_hair, self.hair_n)\n",
    "            D_E_onehot = tf.one_hot(self.D_in_eyes, self.eyes_n)\n",
    "            \n",
    "            self.D_in_hair_right = D_H_onehot[:self.bs]\n",
    "            self.D_in_eyes_right = D_E_onehot[:self.bs]\n",
    "            self.D_in_img_right = self.D_in_img[:self.bs]\n",
    "            \n",
    "            self.D_in_hair_fake = D_H_onehot[self.bs:]\n",
    "            self.D_in_eyes_fake = D_E_onehot[self.bs:]\n",
    "            self.D_in_img_fake = self.D_in_img[self.bs:]\n",
    "            \n",
    "            use_epsilon_uniform = 1\n",
    "            if use_epsilon_uniform :\n",
    "                self.epsilon = tf.placeholder(tf.float32, shape=[1])\n",
    "                self.D_x_hat_hair = self.epsilon*self.D_in_hair_right + (1-self.epsilon)*self.D_in_hair_fake\n",
    "                self.D_x_hat_eyes = self.epsilon*self.D_in_eyes_right + (1-self.epsilon)*self.D_in_eyes_fake\n",
    "                self.D_x_hat_img = self.epsilon*self.D_in_img_right + (1-self.epsilon)*self.D_in_img_fake\n",
    "            else :\n",
    "                self.D_x_hat_hair = self.epsilon*self.D_in_hair_right + (1-self.epsilon)*self.D_in_hair_fake\n",
    "                self.D_x_hat_eyes = self.epsilon*self.D_in_eyes_right + (1-self.epsilon)*self.D_in_eyes_fake\n",
    "                self.D_x_hat_img = self.epsilon*self.D_in_img_right + (1-self.epsilon)*self.D_in_img_fake\n",
    "                \n",
    "            self.D_img = tf.concat([self.D_in_img_right,self.D_in_img_fake,self.D_x_hat_img], axis=0)\n",
    "            self.D_hair = tf.concat([self.D_in_hair_right,self.D_in_hair_fake,self.D_x_hat_hair], axis=0)\n",
    "            self.D_eyes = tf.concat([self.D_in_eyes_right,self.D_in_eyes_fake,self.D_x_hat_eyes], axis=0)\n",
    "            \n",
    "            d = tf.layers.conv2d(self.D_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=None)\n",
    "            \n",
    "            D_tag_in = tf.concat([self.D_hair, self.D_eyes], axis=1)\n",
    "            D_tag_in = tf.layers.dense(D_tag_in,4*4*1024,activation=self.activation, name='d_d1', kernel_initializer=self.initializer, reuse=None)\n",
    "            D_tag_in = tf.reshape(D_tag_in,(-1,4,4,1024))\n",
    "            \n",
    "            d = tf.concat([d, D_tag_in], axis=3)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(1,1), strides=(1,1), \n",
    "                                 padding='same', activation=self.activation, name='d_c5', kernel_initializer=self.initializer, reuse=None)\n",
    "            d = tf.reshape(d, [-1, 4*4*256]) \n",
    "            self.d_temp = tf.layers.dense(d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=None)\n",
    "        \n",
    "            self.d_right, self.d_fake, self.d_x_hat = tf.split(self.d_temp, num_or_size_splits=3, axis=0)\n",
    "#             self.d_right, self.d_fake_temp = tf.split(self.d_temp, num_or_size_splits=2, axis=0)\n",
    "#             self.d_fake, self.d_x_hat = tf.split(self.d_fake_temp, num_or_size_splits=2, axis=0)\n",
    "            \n",
    "            ### gradient penalty\n",
    "#             gradient_temp = tf.gradients(self.d_x_hat,[self.D_x_hat_img,self.D_x_hat_hair,self.D_x_hat_eyes])\n",
    "            gradient_img_temp = tf.gradients(self.d_x_hat,self.D_x_hat_img)\n",
    "            gradient_hair_temp = tf.gradients(self.d_x_hat,self.D_x_hat_hair)\n",
    "            gradient_eyes_temp = tf.gradients(self.d_x_hat,self.D_x_hat_eyes)\n",
    "#             self.gradient_penalty = tf.maximum(tf.constant(0.0, shape=[self.bs,1]), tf.sqrt(tf.square(gradient_temp)) - tf.constant(1.0, shape=[self.bs,1]))\n",
    "            self.gradient_penalty_img = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_img_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_img = self.lda * tf.reduce_mean(self.gradient_penalty_img)\n",
    "            self.gradient_penalty_hair = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_hair_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_hair = self.lda * tf.reduce_mean(self.gradient_penalty_hair)\n",
    "            self.gradient_penalty_eyes = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_eyes_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_eyes = self.lda * tf.reduce_mean(self.gradient_penalty_eyes)\n",
    "            self.gradient_penalty = self.lda * (tf.reduce_mean(self.gradient_penalty_img)\n",
    "                                                + tf.reduce_mean(self.gradient_penalty_hair)/10\n",
    "                                                + tf.reduce_mean(self.gradient_penalty_eyes)/10)\n",
    "            \n",
    "            ### final loss\n",
    "            self.d_loss = -(tf.reduce_mean(self.d_right) - tf.reduce_mean(self.d_fake) - self.gradient_penalty)\n",
    "            self.d_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.d_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.d_loss, var_list=self.d_train_vars)\n",
    "            \n",
    "            ### G_D loss\n",
    "            self.G_D_in_hair = self.G_in_hair\n",
    "            self.G_D_in_eyes = self.G_in_eyes\n",
    "            self.G_D_in_img = self.g\n",
    "            \n",
    "            self.G_D_eyes = tf.one_hot(self.G_D_in_eyes, self.eyes_n)\n",
    "            self.G_D_hair = tf.one_hot(self.G_D_in_hair, self.hair_n)\n",
    "            \n",
    "            g_d = tf.layers.conv2d(self.G_D_in_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=True)\n",
    "            \n",
    "            G_D_tag_in = tf.concat([self.G_D_hair, self.G_D_eyes], axis=1)\n",
    "            G_D_tag_in = tf.layers.dense(G_D_tag_in,4*4*1024,activation=self.activation, name='d_d1', kernel_initializer=self.initializer, reuse=True)\n",
    "            G_D_tag_in = tf.reshape(G_D_tag_in,(-1,4,4,1024))\n",
    "            \n",
    "            g_d = tf.concat([g_d, G_D_tag_in], axis=3)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(1,1), strides=(1,1), \n",
    "                                 padding='same', activation=self.activation, name='d_c5', kernel_initializer=self.initializer, reuse=True)\n",
    "            g_d = tf.reshape(g_d, [-1, 4*4*256]) \n",
    "            self.g_d_temp = tf.layers.dense(g_d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=True)\n",
    "            \n",
    "            self.gd_loss = - tf.reduce_mean(self.g_d_temp)\n",
    "            \n",
    "            #\n",
    "            # HE classification\n",
    "            #\n",
    "            \n",
    "            # hair classification pretrained\n",
    "            self.hair_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.hair_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "\n",
    "            hair_H_onehot = tf.one_hot(self.hair_in_hair, self.hair_n)\n",
    "            hair_temp = tf.layers.batch_normalization(self.hair_in_img, name='hair_b0', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c1', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b1', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c2', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b2', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c3', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b3', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c4', reuse=None)\n",
    "            hair_temp = tf.reshape(hair_temp, [-1, 4*4*32]) \n",
    "            self.hair = tf.layers.dense(hair_temp, self.hair_n ,activation=tf.nn.softmax, name='hair_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "\n",
    "            self.hair_loss = tf.reduce_mean(-tf.reduce_sum(hair_H_onehot * tf.log(self.hair), axis=1))\n",
    "            self.hair_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.hair_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.hair_loss, var_list=self.hair_train_vars)\n",
    "            \n",
    "            # eyes classification pretrained\n",
    "            self.eyes_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.eyes_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "\n",
    "            eyes_E_onehot = tf.one_hot(self.eyes_in_eyes, self.eyes_n)\n",
    "            eyes_temp = tf.layers.batch_normalization(self.eyes_in_img, name='eyes_b0', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c1', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b1', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c2', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b2', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c3', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b3', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c4', reuse=None)\n",
    "            eyes_temp = tf.reshape(eyes_temp, [-1, 4*4*32]) \n",
    "            self.eyes = tf.layers.dense(eyes_temp, self.eyes_n ,activation=tf.nn.softmax, name='eyes_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "\n",
    "            self.eyes_loss = tf.reduce_mean(-tf.reduce_sum(eyes_E_onehot * tf.log(self.eyes), axis=1))\n",
    "            self.eyes_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.eyes_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.eyes_loss, var_list=self.eyes_train_vars)\n",
    "            \n",
    "            ### hair classification\n",
    "            gh_temp = tf.layers.batch_normalization(self.g, name='hair_b0', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c1', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b1', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c2', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b2', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c3', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b3', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c4', reuse=True)\n",
    "            gh_temp = tf.reshape(gh_temp, [-1, 4*4*32]) \n",
    "            self.gh = tf.layers.dense(gh_temp, self.hair_n ,activation=tf.nn.softmax, name='hair_s2', kernel_initializer=self.initializer, reuse=True)\n",
    "            \n",
    "            self.gh_loss = tf.reduce_mean(-tf.reduce_sum(self.G_H_onehot * tf.log(self.gh), axis=1))\n",
    "            \n",
    "            ### eyes classification\n",
    "            ge_temp = tf.layers.batch_normalization(self.g, name='eyes_b0', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c1', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b1', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c2', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b2', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c3', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b3', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c4', reuse=True)\n",
    "            ge_temp = tf.reshape(ge_temp, [-1, 4*4*32]) \n",
    "            self.ge = tf.layers.dense(ge_temp, self.eyes_n ,activation=tf.nn.softmax, name='eyes_s2', kernel_initializer=self.initializer, reuse=True)\n",
    "\n",
    "            self.ge_loss = tf.reduce_mean(-tf.reduce_sum(self.G_E_onehot * tf.log(self.ge), axis=1))\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.gd_loss_final = 1*self.gd_loss + 1*self.gh_loss + 1*self.ge_loss\n",
    "            \n",
    "            self.gd_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"G/\")\n",
    "            self.gd_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.gd_loss_final, var_list=self.gd_train_vars)\n",
    "            \n",
    "    def build_net(self) :\n",
    "        self.build_G_net()\n",
    "        self.build_D_net()\n",
    "        \n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        tf.summary.FileWriter(\"logs/\", self.sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pre(text) :\n",
    "    text = text.replace(',',' ')\n",
    "    lst_text = text.split(' ')\n",
    "    hair_i = 0\n",
    "    eyes_i = 0\n",
    "    for i,s in enumerate(lst_text) :\n",
    "        if s == 'hair' :\n",
    "            hair_i = i\n",
    "        elif s == 'eyes' :\n",
    "            eyes_i = i\n",
    "    if hair_i :\n",
    "        hair_style = lst_text[hair_i-1] + ' ' + lst_text[hair_i]\n",
    "    else :\n",
    "        hair_style = 'null'\n",
    "    if eyes_i :\n",
    "        eyes_style = lst_text[eyes_i-1] + ' ' + lst_text[eyes_i]\n",
    "    else :\n",
    "        eyes_style = 'null'\n",
    "    \n",
    "    return hair_style, eyes_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(testing_text_id,img_n=40,hair_style='null',eyes_style='null', gan=None) :\n",
    "    seed_i = 3\n",
    "    random.seed(seed_i)\n",
    "    np.random.seed(seed_i)\n",
    "    tf.set_random_seed(seed_i)\n",
    "    lst_hair = ['null', 'orange hair', 'white hair', 'aqua hair', 'gray hair',\n",
    "                'green hair', 'red hair', 'purple hair', 'pink hair',\n",
    "                'blue hair', 'black hair', 'brown hair', 'blonde hair']\n",
    "    lst_eyes = ['null', 'gray eyes', 'black eyes', 'orange eyes',\n",
    "                'pink eyes', 'yellow eyes', 'aqua eyes', 'purple eyes',\n",
    "                'green eyes', 'brown eyes', 'red eyes', 'blue eyes']\n",
    "    \n",
    "    hair_i = 0 \n",
    "    eyes_i = 0\n",
    "    for i,h in enumerate(lst_hair) :\n",
    "        if h == hair_style :\n",
    "            hair_i = i\n",
    "    for i,e in enumerate(lst_eyes) :\n",
    "        if e == eyes_style :\n",
    "            eyes_i = i\n",
    "            \n",
    "#     if hair_i == 6 :\n",
    "#         seed_i = \n",
    "    \n",
    "    \n",
    "    if hair_i != 0 :\n",
    "        gen_tag_hair = np.zeros((int(img_n),), dtype=np.int) + hair_i\n",
    "    else :\n",
    "        gen_tag_hair = np.random.randint(1,13,size=img_n)\n",
    "    if eyes_i != 0 :\n",
    "        gen_tag_eyes = np.zeros((int(img_n),), dtype=np.int) + eyes_i\n",
    "    else :\n",
    "        gen_tag_eyes = np.random.randint(1,12,size=img_n)\n",
    "    \n",
    "    ary_temp = np.random.normal(0,1,[img_n,100])\n",
    "    b_img = gan.sess.run(gan.g, feed_dict={gan.G_in_hair:gen_tag_hair, \n",
    "                                           gan.G_in_eyes:gen_tag_eyes, \n",
    "                                           gan.G_in_noise:ary_temp})\n",
    "    b_img = (b_img + 1.0) / 2.0\n",
    "        \n",
    "    if not os.path.isdir('./samples') :\n",
    "        os.makedirs('./samples')\n",
    "    \n",
    "    if testing_text_id == '1' :\n",
    "        lst_img = b_img[[4,8,10,15,21]]\n",
    "        for i,img in enumerate(lst_img) :\n",
    "            scipy.misc.imsave('./samples/sample_{}_{}.jpg'.format(int(testing_text_id),i+1),img)\n",
    "    if testing_text_id == '2' :\n",
    "        lst_img = b_img[[7,20,22,29,32]]\n",
    "        for i,img in enumerate(lst_img) :\n",
    "            scipy.misc.imsave('./samples/sample_{}_{}.jpg'.format(int(testing_text_id),i+1),img)\n",
    "\n",
    "    if testing_text_id == '3' :\n",
    "        lst_img = b_img[[1,4,16,18,25]]\n",
    "        for i,img in enumerate(lst_img) :\n",
    "            scipy.misc.imsave('./samples/sample_{}_{}.jpg'.format(int(testing_text_id),i+1),img)\n",
    "\n",
    "#     for i,img in enumerate(b_img) :\n",
    "#         scipy.misc.imsave('./samples/sample_{}_{}.jpg'.format(int(testing_text_id),i+1),img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/testing_text.txt\n",
      "INFO:tensorflow:Restoring parameters from ./model_tf/model_gan9_bs16_HEclass_original.ckpt\n",
      "[[[[ 0.92645305  0.95444441  0.9691875 ]\n",
      "   [ 0.92750311  0.96027702  0.98030066]\n",
      "   [ 0.90102094  0.9419657   0.98036385]\n",
      "   ..., \n",
      "   [ 0.41676617  0.45969728  0.62046993]\n",
      "   [ 0.54374844  0.55285853  0.67804247]\n",
      "   [ 0.68671453  0.67355764  0.77683413]]\n",
      "\n",
      "  [[ 0.93757761  0.96475852  0.97950208]\n",
      "   [ 0.92665064  0.95441747  0.98388195]\n",
      "   [ 0.91963291  0.95563096  0.98542029]\n",
      "   ..., \n",
      "   [ 0.39418799  0.45230788  0.59495401]\n",
      "   [ 0.45804662  0.49524087  0.61116385]\n",
      "   [ 0.63336968  0.65590441  0.74809045]]\n",
      "\n",
      "  [[ 0.93755001  0.95541048  0.98296893]\n",
      "   [ 0.93355262  0.95478058  0.98357636]\n",
      "   [ 0.94322211  0.96766329  0.98891729]\n",
      "   ..., \n",
      "   [ 0.4373109   0.52732641  0.65231967]\n",
      "   [ 0.40087125  0.49333361  0.58371651]\n",
      "   [ 0.50622123  0.61206245  0.66932845]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.94550967  0.91419172  0.92337751]\n",
      "   [ 0.94929749  0.91224951  0.92238909]\n",
      "   [ 0.94991279  0.92249244  0.94160652]\n",
      "   ..., \n",
      "   [ 0.97145736  0.92448908  0.92835003]\n",
      "   [ 0.99235439  0.97833252  0.98079622]\n",
      "   [ 0.98854208  0.97561562  0.97953331]]\n",
      "\n",
      "  [[ 0.94133353  0.90967005  0.92006993]\n",
      "   [ 0.94333804  0.90889919  0.91277045]\n",
      "   [ 0.95195842  0.92871428  0.93745875]\n",
      "   ..., \n",
      "   [ 0.97537374  0.93732965  0.92202973]\n",
      "   [ 0.98772132  0.97350729  0.97073793]\n",
      "   [ 0.98638248  0.98003155  0.97891748]]\n",
      "\n",
      "  [[ 0.91933894  0.87448144  0.89399475]\n",
      "   [ 0.93518507  0.89893526  0.9108184 ]\n",
      "   [ 0.94243908  0.93617857  0.9347381 ]\n",
      "   ..., \n",
      "   [ 0.97614932  0.94452822  0.93601412]\n",
      "   [ 0.9731822   0.95955729  0.95247102]\n",
      "   [ 0.97583276  0.96966434  0.96539044]]]\n",
      "\n",
      "\n",
      " [[[ 0.46935505  0.49071532  0.5103395 ]\n",
      "   [ 0.55244976  0.55687684  0.59433722]\n",
      "   [ 0.73926735  0.70884615  0.74058926]\n",
      "   ..., \n",
      "   [ 0.34511855  0.37930506  0.61090052]\n",
      "   [ 0.26791531  0.30139759  0.51415664]\n",
      "   [ 0.31519693  0.33943415  0.53382802]]\n",
      "\n",
      "  [[ 0.39839306  0.44541195  0.4974114 ]\n",
      "   [ 0.54862314  0.55661815  0.61998725]\n",
      "   [ 0.77423149  0.75021231  0.78470659]\n",
      "   ..., \n",
      "   [ 0.5039084   0.50230664  0.71687293]\n",
      "   [ 0.39215469  0.38181227  0.60695052]\n",
      "   [ 0.31589216  0.30376458  0.5296734 ]]\n",
      "\n",
      "  [[ 0.42993629  0.50573063  0.58097446]\n",
      "   [ 0.69076514  0.733612    0.76800948]\n",
      "   [ 0.80853856  0.82417953  0.8441155 ]\n",
      "   ..., \n",
      "   [ 0.80185372  0.78486568  0.88637447]\n",
      "   [ 0.53314281  0.50196087  0.7052108 ]\n",
      "   [ 0.4435285   0.41128892  0.62961876]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.80993986  0.62966967  0.57132304]\n",
      "   [ 0.96820343  0.90317202  0.85616237]\n",
      "   [ 0.98104763  0.93146306  0.90247178]\n",
      "   ..., \n",
      "   [ 0.40110245  0.18655616  0.38027641]\n",
      "   [ 0.41974765  0.19587961  0.38556191]\n",
      "   [ 0.36045775  0.18862408  0.35897917]]\n",
      "\n",
      "  [[ 0.49659708  0.3278181   0.31312513]\n",
      "   [ 0.91075361  0.79968303  0.7584129 ]\n",
      "   [ 0.9836731   0.94559222  0.92027599]\n",
      "   ..., \n",
      "   [ 0.43040153  0.22244012  0.41348672]\n",
      "   [ 0.40762278  0.20580217  0.40822136]\n",
      "   [ 0.30195528  0.1591841   0.29623318]]\n",
      "\n",
      "  [[ 0.30524659  0.19501591  0.21527979]\n",
      "   [ 0.57466644  0.42877528  0.40835467]\n",
      "   [ 0.94535625  0.88279647  0.8473267 ]\n",
      "   ..., \n",
      "   [ 0.34522659  0.1844207   0.36349884]\n",
      "   [ 0.28430188  0.13724488  0.29435515]\n",
      "   [ 0.24865019  0.14081579  0.28354788]]]\n",
      "\n",
      "\n",
      " [[[ 0.16069776  0.14815167  0.21781382]\n",
      "   [ 0.09115255  0.07917166  0.1450066 ]\n",
      "   [ 0.06982663  0.05875999  0.11850733]\n",
      "   ..., \n",
      "   [ 0.39215249  0.37534219  0.46922162]\n",
      "   [ 0.42608646  0.39634785  0.45909843]\n",
      "   [ 0.45475727  0.41988704  0.4772425 ]]\n",
      "\n",
      "  [[ 0.14224517  0.12730896  0.20939779]\n",
      "   [ 0.14178234  0.11103791  0.18545136]\n",
      "   [ 0.08159399  0.06334269  0.11015913]\n",
      "   ..., \n",
      "   [ 0.39893451  0.40371615  0.4908489 ]\n",
      "   [ 0.37900409  0.38497314  0.44101796]\n",
      "   [ 0.40079302  0.41938078  0.46745515]]\n",
      "\n",
      "  [[ 0.13622326  0.11359403  0.20362931]\n",
      "   [ 0.2527056   0.19040227  0.2827732 ]\n",
      "   [ 0.20706934  0.15664566  0.21585587]\n",
      "   ..., \n",
      "   [ 0.37986612  0.426797    0.52555549]\n",
      "   [ 0.35276046  0.40727293  0.47483873]\n",
      "   [ 0.31261003  0.38789827  0.43025553]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.10127595  0.1806061   0.34267712]\n",
      "   [ 0.12203425  0.18336976  0.39127582]\n",
      "   [ 0.25074258  0.31405321  0.55973077]\n",
      "   ..., \n",
      "   [ 0.89947438  0.8498196   0.80479705]\n",
      "   [ 0.90143955  0.8475281   0.77951682]\n",
      "   [ 0.92227459  0.87988544  0.79788685]]\n",
      "\n",
      "  [[ 0.12379676  0.24612111  0.43291396]\n",
      "   [ 0.13441294  0.25437146  0.46556345]\n",
      "   [ 0.1744408   0.24771339  0.50756818]\n",
      "   ..., \n",
      "   [ 0.93161798  0.89210445  0.8426066 ]\n",
      "   [ 0.86943913  0.81159508  0.71934146]\n",
      "   [ 0.8877638   0.85008979  0.7483902 ]]\n",
      "\n",
      "  [[ 0.25626945  0.38273343  0.57019353]\n",
      "   [ 0.18256903  0.29605359  0.52911609]\n",
      "   [ 0.14297456  0.22001511  0.47788775]\n",
      "   ..., \n",
      "   [ 0.91273838  0.86301649  0.81456912]\n",
      "   [ 0.83615696  0.78238928  0.68758357]\n",
      "   [ 0.84365225  0.80885357  0.69318014]]]\n",
      "\n",
      "\n",
      " [[[ 0.96152818  0.94757748  0.95600444]\n",
      "   [ 0.95843184  0.95421231  0.96869612]\n",
      "   [ 0.93538547  0.93900168  0.96844316]\n",
      "   ..., \n",
      "   [ 0.53105581  0.40245765  0.60590452]\n",
      "   [ 0.5474118   0.43278116  0.61432731]\n",
      "   [ 0.57679707  0.49555665  0.63935757]]\n",
      "\n",
      "  [[ 0.96783018  0.95886922  0.96724784]\n",
      "   [ 0.96186119  0.95089054  0.97409093]\n",
      "   [ 0.91341293  0.91998887  0.96014011]\n",
      "   ..., \n",
      "   [ 0.59450835  0.38766885  0.6056515 ]\n",
      "   [ 0.5595448   0.36428651  0.59737158]\n",
      "   [ 0.48912874  0.3511247   0.56782389]]\n",
      "\n",
      "  [[ 0.96889603  0.9551844   0.97553563]\n",
      "   [ 0.9570111   0.9449861   0.97240424]\n",
      "   [ 0.9146685   0.90959537  0.95912158]\n",
      "   ..., \n",
      "   [ 0.56656396  0.37398052  0.60139132]\n",
      "   [ 0.53714406  0.32353503  0.58964926]\n",
      "   [ 0.45748389  0.31835824  0.53598064]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.4984495   0.44757444  0.64010066]\n",
      "   [ 0.24574989  0.25386393  0.49422285]\n",
      "   [ 0.13334793  0.20655215  0.4770129 ]\n",
      "   ..., \n",
      "   [ 0.99689257  0.9863441   0.9804374 ]\n",
      "   [ 0.9981581   0.99128067  0.99024785]\n",
      "   [ 0.99507415  0.98588467  0.98647565]]\n",
      "\n",
      "  [[ 0.49943218  0.40811497  0.602126  ]\n",
      "   [ 0.27725086  0.260557    0.47049439]\n",
      "   [ 0.16764623  0.22934839  0.51792085]\n",
      "   ..., \n",
      "   [ 0.99642611  0.98964393  0.98198235]\n",
      "   [ 0.9970876   0.99141103  0.98726511]\n",
      "   [ 0.99247134  0.98555565  0.98320031]]\n",
      "\n",
      "  [[ 0.51326489  0.40492541  0.571504  ]\n",
      "   [ 0.40661949  0.34125102  0.54367375]\n",
      "   [ 0.23492646  0.30268657  0.56357312]\n",
      "   ..., \n",
      "   [ 0.99434149  0.98875999  0.98399615]\n",
      "   [ 0.99402475  0.98931801  0.98483241]\n",
      "   [ 0.97695661  0.9706611   0.96213192]]]\n",
      "\n",
      "\n",
      " [[[ 0.2112588   0.33292103  0.57616532]\n",
      "   [ 0.17946807  0.31774765  0.62497437]\n",
      "   [ 0.17369807  0.30385286  0.68459237]\n",
      "   ..., \n",
      "   [ 0.14561802  0.39543283  0.75322223]\n",
      "   [ 0.17728651  0.44757497  0.79145324]\n",
      "   [ 0.25088012  0.49831173  0.79447097]]\n",
      "\n",
      "  [[ 0.18012232  0.30188742  0.61171371]\n",
      "   [ 0.17869037  0.25601572  0.65229481]\n",
      "   [ 0.22526613  0.33442718  0.72788286]\n",
      "   ..., \n",
      "   [ 0.18287957  0.3718904   0.80411369]\n",
      "   [ 0.20805317  0.41547361  0.83580697]\n",
      "   [ 0.24757507  0.44703019  0.83106709]]\n",
      "\n",
      "  [[ 0.16544244  0.24077314  0.62652928]\n",
      "   [ 0.19312239  0.23871779  0.63584989]\n",
      "   [ 0.29898912  0.3775208   0.75507212]\n",
      "   ..., \n",
      "   [ 0.22754049  0.33998394  0.78031206]\n",
      "   [ 0.22773585  0.3542054   0.80948925]\n",
      "   [ 0.26630548  0.4272708   0.80609626]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.23987442  0.13703197  0.1316489 ]\n",
      "   [ 0.46927711  0.29005989  0.23165244]\n",
      "   [ 0.80049884  0.66366237  0.51019633]\n",
      "   ..., \n",
      "   [ 0.39392352  0.41330969  0.62800992]\n",
      "   [ 0.91853201  0.76802689  0.782902  ]\n",
      "   [ 0.9861207   0.93920505  0.86999393]]\n",
      "\n",
      "  [[ 0.20564148  0.14967349  0.14491543]\n",
      "   [ 0.40357351  0.34752488  0.27845621]\n",
      "   [ 0.77674663  0.69559944  0.59297997]\n",
      "   ..., \n",
      "   [ 0.37546718  0.44003451  0.69027126]\n",
      "   [ 0.6759761   0.52871299  0.6649276 ]\n",
      "   [ 0.95593238  0.89599991  0.85030591]]\n",
      "\n",
      "  [[ 0.34314397  0.2517876   0.28380096]\n",
      "   [ 0.3911579   0.3822735   0.38724816]\n",
      "   [ 0.595478    0.64674062  0.62151378]\n",
      "   ..., \n",
      "   [ 0.48504767  0.57419211  0.78934455]\n",
      "   [ 0.44621351  0.38803884  0.55037642]\n",
      "   [ 0.7869612   0.73849487  0.71504766]]]]\n",
      "[[[[ 0.92568958  0.9021883   0.88131541]\n",
      "   [ 0.92488122  0.88549954  0.87162799]\n",
      "   [ 0.8462702   0.75486302  0.74428159]\n",
      "   ..., \n",
      "   [ 0.75435776  0.69409776  0.68369466]\n",
      "   [ 0.84274596  0.77927268  0.76639539]\n",
      "   [ 0.89530587  0.8502053   0.85065067]]\n",
      "\n",
      "  [[ 0.94856429  0.91981912  0.89813554]\n",
      "   [ 0.91041398  0.86174858  0.82400119]\n",
      "   [ 0.78319424  0.67934716  0.65068454]\n",
      "   ..., \n",
      "   [ 0.68241668  0.63439733  0.63487476]\n",
      "   [ 0.80884486  0.75426465  0.76084423]\n",
      "   [ 0.90650064  0.87216282  0.87433743]]\n",
      "\n",
      "  [[ 0.88424021  0.81338274  0.78493667]\n",
      "   [ 0.8035      0.70495337  0.6532433 ]\n",
      "   [ 0.77002001  0.68885213  0.62158519]\n",
      "   ..., \n",
      "   [ 0.63272476  0.59819907  0.60287488]\n",
      "   [ 0.74366683  0.71027464  0.71560717]\n",
      "   [ 0.86799383  0.84535277  0.8386758 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.59114784  0.41910398  0.43658555]\n",
      "   [ 0.6682992   0.49085858  0.54545391]\n",
      "   [ 0.70235693  0.54048395  0.6223222 ]\n",
      "   ..., \n",
      "   [ 0.98861796  0.94564116  0.84303606]\n",
      "   [ 0.98874444  0.95601296  0.86382747]\n",
      "   [ 0.99040401  0.97219932  0.91088629]]\n",
      "\n",
      "  [[ 0.71293652  0.56035167  0.57455444]\n",
      "   [ 0.67875969  0.54582065  0.57337278]\n",
      "   [ 0.81860059  0.708368    0.72758508]\n",
      "   ..., \n",
      "   [ 0.9899478   0.94854701  0.86174738]\n",
      "   [ 0.98806524  0.93964732  0.84773022]\n",
      "   [ 0.98922968  0.96735591  0.91146922]]\n",
      "\n",
      "  [[ 0.75088447  0.66483521  0.67417252]\n",
      "   [ 0.73839831  0.65050852  0.66725528]\n",
      "   [ 0.84937656  0.76231956  0.76476169]\n",
      "   ..., \n",
      "   [ 0.98822963  0.94744796  0.89023423]\n",
      "   [ 0.98481238  0.9491691   0.88110918]\n",
      "   [ 0.98705178  0.9695828   0.9229812 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.99784976  0.99573559  0.99011111]\n",
      "   [ 0.99922973  0.99800271  0.99505436]\n",
      "   [ 0.99910909  0.99727356  0.99348825]\n",
      "   ..., \n",
      "   [ 0.80422556  0.76850152  0.74841613]\n",
      "   [ 0.88938141  0.84505665  0.82740057]\n",
      "   [ 0.93360889  0.90265369  0.8983022 ]]\n",
      "\n",
      "  [[ 0.99944186  0.99804676  0.99441844]\n",
      "   [ 0.99953258  0.99810255  0.99460888]\n",
      "   [ 0.99918211  0.99676001  0.99303597]\n",
      "   ..., \n",
      "   [ 0.67259878  0.6804986   0.64487249]\n",
      "   [ 0.91389436  0.90869379  0.88342774]\n",
      "   [ 0.92748266  0.92021096  0.9033733 ]]\n",
      "\n",
      "  [[ 0.99972373  0.99866235  0.99628222]\n",
      "   [ 0.99963093  0.99803889  0.99483854]\n",
      "   [ 0.99936259  0.99722898  0.993487  ]\n",
      "   ..., \n",
      "   [ 0.45523626  0.52643722  0.4765608 ]\n",
      "   [ 0.82345134  0.87033492  0.81029725]\n",
      "   [ 0.91137791  0.93165803  0.89892292]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.44783369  0.2001431   0.17441505]\n",
      "   [ 0.43550438  0.18738189  0.16681474]\n",
      "   [ 0.37800264  0.17835677  0.16485876]\n",
      "   ..., \n",
      "   [ 0.31153801  0.22285983  0.28084093]\n",
      "   [ 0.42659557  0.34657273  0.39050108]\n",
      "   [ 0.61355102  0.52051449  0.54568189]]\n",
      "\n",
      "  [[ 0.40954185  0.1824356   0.16433048]\n",
      "   [ 0.39197752  0.16538537  0.15768117]\n",
      "   [ 0.40230256  0.18208995  0.17485231]\n",
      "   ..., \n",
      "   [ 0.44015688  0.32186615  0.38687119]\n",
      "   [ 0.65527928  0.51724243  0.57002228]\n",
      "   [ 0.75648022  0.65306306  0.67164969]]\n",
      "\n",
      "  [[ 0.37419552  0.18933463  0.17868203]\n",
      "   [ 0.38718414  0.17861789  0.1638386 ]\n",
      "   [ 0.39699247  0.18825307  0.18567792]\n",
      "   ..., \n",
      "   [ 0.43620545  0.30268043  0.38060361]\n",
      "   [ 0.72562605  0.60346401  0.64294624]\n",
      "   [ 0.75109017  0.63962197  0.61291152]]]\n",
      "\n",
      "\n",
      " [[[ 0.97826993  0.97609508  0.97637546]\n",
      "   [ 0.99141145  0.98898089  0.99004984]\n",
      "   [ 0.98933971  0.98404366  0.98848116]\n",
      "   ..., \n",
      "   [ 0.96602613  0.98929852  0.9977566 ]\n",
      "   [ 0.96475202  0.98959488  0.99775934]\n",
      "   [ 0.90781921  0.9686439   0.99250394]]\n",
      "\n",
      "  [[ 0.99044859  0.98604298  0.9868834 ]\n",
      "   [ 0.99416614  0.98944104  0.99180353]\n",
      "   [ 0.99170196  0.98477811  0.99002612]\n",
      "   ..., \n",
      "   [ 0.95664763  0.98511922  0.99830401]\n",
      "   [ 0.97492933  0.99109495  0.99881196]\n",
      "   [ 0.93087989  0.9754923   0.99625182]]\n",
      "\n",
      "  [[ 0.99439442  0.98878944  0.99084091]\n",
      "   [ 0.99428356  0.98668206  0.9897756 ]\n",
      "   [ 0.99407876  0.98692083  0.99032533]\n",
      "   ..., \n",
      "   [ 0.96959144  0.98816258  0.99866569]\n",
      "   [ 0.97764134  0.98987216  0.99883932]\n",
      "   [ 0.92828321  0.97135556  0.99528849]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.98780888  0.98531598  0.98775816]\n",
      "   [ 0.9869715   0.97902107  0.98497146]\n",
      "   [ 0.98645544  0.9750697   0.98358345]\n",
      "   ..., \n",
      "   [ 0.99028993  0.99018466  0.98791945]\n",
      "   [ 0.99642026  0.99655831  0.99429744]\n",
      "   [ 0.98943615  0.98851252  0.98545045]]\n",
      "\n",
      "  [[ 0.98911726  0.98571998  0.98957992]\n",
      "   [ 0.98760307  0.97963715  0.98527813]\n",
      "   [ 0.98725569  0.97527725  0.9824847 ]\n",
      "   ..., \n",
      "   [ 0.98865438  0.98888642  0.98439908]\n",
      "   [ 0.9964633   0.99644971  0.99373376]\n",
      "   [ 0.98991233  0.98886728  0.98516315]]\n",
      "\n",
      "  [[ 0.97856534  0.97231281  0.98016804]\n",
      "   [ 0.98259467  0.97488868  0.98097312]\n",
      "   [ 0.98314071  0.97529519  0.97998089]\n",
      "   ..., \n",
      "   [ 0.98474455  0.98637128  0.98268557]\n",
      "   [ 0.99300086  0.99518877  0.99179268]\n",
      "   [ 0.98947638  0.99093032  0.98431695]]]\n",
      "\n",
      "\n",
      " [[[ 0.9873544   0.98435146  0.98092258]\n",
      "   [ 0.99239683  0.9884755   0.98723185]\n",
      "   [ 0.97314811  0.9653697   0.96380705]\n",
      "   ..., \n",
      "   [ 0.19146824  0.24699426  0.30585408]\n",
      "   [ 0.19781005  0.24770954  0.30750194]\n",
      "   [ 0.22975433  0.2679469   0.33983725]]\n",
      "\n",
      "  [[ 0.99262142  0.98998523  0.98702747]\n",
      "   [ 0.99556154  0.99215126  0.99153435]\n",
      "   [ 0.98020911  0.97297049  0.97409654]\n",
      "   ..., \n",
      "   [ 0.17449284  0.24081242  0.29969883]\n",
      "   [ 0.17034155  0.23011008  0.28870067]\n",
      "   [ 0.2016139   0.25312796  0.33401287]]\n",
      "\n",
      "  [[ 0.9940142   0.99126804  0.9894799 ]\n",
      "   [ 0.99452299  0.98936629  0.98818362]\n",
      "   [ 0.96483809  0.94445693  0.94635892]\n",
      "   ..., \n",
      "   [ 0.17042375  0.2345441   0.29299808]\n",
      "   [ 0.15251073  0.21697551  0.27107048]\n",
      "   [ 0.172241    0.23722333  0.30692011]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.98033655  0.97265589  0.98435754]\n",
      "   [ 0.9886058   0.97800243  0.98842931]\n",
      "   [ 0.99127334  0.97604257  0.98887694]\n",
      "   ..., \n",
      "   [ 0.98259783  0.93085277  0.92986095]\n",
      "   [ 0.99311012  0.95089269  0.95450532]\n",
      "   [ 0.99286866  0.95176864  0.95921093]]\n",
      "\n",
      "  [[ 0.96752679  0.95898318  0.97735602]\n",
      "   [ 0.98326194  0.9702096   0.98334312]\n",
      "   [ 0.99067533  0.97876585  0.98759186]\n",
      "   ..., \n",
      "   [ 0.99067211  0.95471293  0.95404172]\n",
      "   [ 0.99447495  0.95791233  0.96178192]\n",
      "   [ 0.99154115  0.95496213  0.96020865]]\n",
      "\n",
      "  [[ 0.94184095  0.92593366  0.95696831]\n",
      "   [ 0.9700619   0.95296705  0.97208846]\n",
      "   [ 0.98636621  0.97761595  0.98451662]\n",
      "   ..., \n",
      "   [ 0.98774207  0.9522115   0.95552766]\n",
      "   [ 0.99031657  0.95986378  0.96127653]\n",
      "   [ 0.98682749  0.95874858  0.95857197]]]\n",
      "\n",
      "\n",
      " [[[ 0.74847114  0.67000425  0.64083439]\n",
      "   [ 0.73010302  0.61892492  0.59947258]\n",
      "   [ 0.6262787   0.49196282  0.4769161 ]\n",
      "   ..., \n",
      "   [ 0.26480138  0.23707134  0.2624594 ]\n",
      "   [ 0.25711799  0.21408814  0.2469781 ]\n",
      "   [ 0.25320107  0.20916873  0.2487399 ]]\n",
      "\n",
      "  [[ 0.73061121  0.63247293  0.61549193]\n",
      "   [ 0.6021719   0.48592743  0.46570319]\n",
      "   [ 0.48170483  0.36633468  0.36144835]\n",
      "   ..., \n",
      "   [ 0.24954635  0.23464471  0.27510095]\n",
      "   [ 0.23583373  0.21714175  0.25690013]\n",
      "   [ 0.22497439  0.19807523  0.24427509]]\n",
      "\n",
      "  [[ 0.56754178  0.46503821  0.46647215]\n",
      "   [ 0.41037703  0.31659979  0.31791455]\n",
      "   [ 0.40160006  0.33174366  0.32045442]\n",
      "   ..., \n",
      "   [ 0.23899245  0.23721039  0.27977979]\n",
      "   [ 0.22230151  0.22741097  0.27110839]\n",
      "   [ 0.22940409  0.2235381   0.27400929]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.78154039  0.61041749  0.60570407]\n",
      "   [ 0.8416822   0.682181    0.7112354 ]\n",
      "   [ 0.84965235  0.69003224  0.74070758]\n",
      "   ..., \n",
      "   [ 0.75840706  0.69093001  0.61993146]\n",
      "   [ 0.46155804  0.37852746  0.3315891 ]\n",
      "   [ 0.38945508  0.29497635  0.27233368]]\n",
      "\n",
      "  [[ 0.78756893  0.63339579  0.61897802]\n",
      "   [ 0.80238438  0.66502577  0.67780042]\n",
      "   [ 0.82684594  0.71049887  0.75351518]\n",
      "   ..., \n",
      "   [ 0.77067786  0.70081627  0.62523496]\n",
      "   [ 0.48732406  0.37627885  0.33527094]\n",
      "   [ 0.38359565  0.28299648  0.26291168]]\n",
      "\n",
      "  [[ 0.72214246  0.61605698  0.60499781]\n",
      "   [ 0.80322367  0.70755696  0.73091   ]\n",
      "   [ 0.84053075  0.76240629  0.79708862]\n",
      "   ..., \n",
      "   [ 0.69179088  0.59162921  0.53007078]\n",
      "   [ 0.46087259  0.35333848  0.32175002]\n",
      "   [ 0.45161444  0.35130709  0.3211723 ]]]]\n",
      "[[[[ 0.89028746  0.62672663  0.6300239 ]\n",
      "   [ 0.92043734  0.5758056   0.61175483]\n",
      "   [ 0.94712275  0.61606723  0.63929361]\n",
      "   ..., \n",
      "   [ 0.98688704  0.78811878  0.66673917]\n",
      "   [ 0.97899389  0.73643136  0.63773453]\n",
      "   [ 0.96863765  0.74485821  0.6347158 ]]\n",
      "\n",
      "  [[ 0.91917872  0.58568639  0.59650135]\n",
      "   [ 0.93880349  0.54520619  0.56797105]\n",
      "   [ 0.94635868  0.53967106  0.5755958 ]\n",
      "   ..., \n",
      "   [ 0.9884733   0.7714054   0.67809272]\n",
      "   [ 0.98411262  0.76400983  0.66413957]\n",
      "   [ 0.98170698  0.78903812  0.70344758]]\n",
      "\n",
      "  [[ 0.92117041  0.57331884  0.58318156]\n",
      "   [ 0.90538412  0.45877123  0.49629909]\n",
      "   [ 0.88364911  0.39122841  0.43691236]\n",
      "   ..., \n",
      "   [ 0.99025393  0.79446387  0.6945498 ]\n",
      "   [ 0.98716569  0.78992146  0.68779045]\n",
      "   [ 0.98202634  0.8113212   0.71110511]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.86774075  0.4348228   0.58883822]\n",
      "   [ 0.88904703  0.4444271   0.61821985]\n",
      "   [ 0.89904737  0.45624331  0.62337565]\n",
      "   ..., \n",
      "   [ 0.95098603  0.68863285  0.66796064]\n",
      "   [ 0.94843531  0.71106607  0.68253756]\n",
      "   [ 0.91116863  0.64843559  0.62223661]]\n",
      "\n",
      "  [[ 0.85700274  0.40865242  0.53852457]\n",
      "   [ 0.89479733  0.42687625  0.59747928]\n",
      "   [ 0.90798891  0.43603536  0.61217427]\n",
      "   ..., \n",
      "   [ 0.95416939  0.69861686  0.67674279]\n",
      "   [ 0.95780396  0.73399228  0.69424844]\n",
      "   [ 0.92475379  0.66378438  0.625664  ]]\n",
      "\n",
      "  [[ 0.81112266  0.39318931  0.50573051]\n",
      "   [ 0.88675392  0.4193089   0.5662387 ]\n",
      "   [ 0.90878165  0.4397307   0.59046811]\n",
      "   ..., \n",
      "   [ 0.94471824  0.72687376  0.68815881]\n",
      "   [ 0.94548106  0.73923147  0.68512541]\n",
      "   [ 0.91188335  0.68634224  0.6394853 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.04194614  0.03726599  0.04175913]\n",
      "   [ 0.04000723  0.02996328  0.03898737]\n",
      "   [ 0.18008059  0.10511363  0.12422809]\n",
      "   ..., \n",
      "   [ 0.92826092  0.43693018  0.5322907 ]\n",
      "   [ 0.93990076  0.51686597  0.59026968]\n",
      "   [ 0.92664504  0.58187068  0.60836411]]\n",
      "\n",
      "  [[ 0.02513826  0.02206814  0.02810961]\n",
      "   [ 0.04868108  0.04367912  0.04943609]\n",
      "   [ 0.41539752  0.31266069  0.31914622]\n",
      "   ..., \n",
      "   [ 0.89842296  0.35436964  0.4820388 ]\n",
      "   [ 0.94240785  0.53118777  0.59823447]\n",
      "   [ 0.93969667  0.56013459  0.63151598]]\n",
      "\n",
      "  [[ 0.02481261  0.0210709   0.02576235]\n",
      "   [ 0.25829232  0.21622103  0.22658718]\n",
      "   [ 0.88786066  0.8300612   0.78904599]\n",
      "   ..., \n",
      "   [ 0.84850246  0.30122316  0.39534444]\n",
      "   [ 0.91830808  0.45106405  0.51423174]\n",
      "   [ 0.94043154  0.56915569  0.6088146 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.57551306  0.41384733  0.52209395]\n",
      "   [ 0.63971817  0.43201554  0.5547787 ]\n",
      "   [ 0.644207    0.42633438  0.58243614]\n",
      "   ..., \n",
      "   [ 0.9144038   0.8684994   0.85830885]\n",
      "   [ 0.90732938  0.86417639  0.83961791]\n",
      "   [ 0.7657572   0.68333161  0.66457427]]\n",
      "\n",
      "  [[ 0.61545813  0.47145158  0.60121781]\n",
      "   [ 0.70228964  0.54272532  0.68804836]\n",
      "   [ 0.74900836  0.61174107  0.77233565]\n",
      "   ..., \n",
      "   [ 0.97010815  0.94978005  0.93390119]\n",
      "   [ 0.95172989  0.92345452  0.89906865]\n",
      "   [ 0.80387276  0.73980403  0.72321796]]\n",
      "\n",
      "  [[ 0.67304289  0.56071687  0.66411328]\n",
      "   [ 0.7529304   0.63704753  0.77014637]\n",
      "   [ 0.75510573  0.66437936  0.79077059]\n",
      "   ..., \n",
      "   [ 0.97114491  0.95341551  0.94069028]\n",
      "   [ 0.91868424  0.89222115  0.86685872]\n",
      "   [ 0.67496037  0.63147718  0.60611606]]]\n",
      "\n",
      "\n",
      " [[[ 0.96936017  0.73556548  0.65002429]\n",
      "   [ 0.97855115  0.74297237  0.67545068]\n",
      "   [ 0.97214961  0.69972086  0.649207  ]\n",
      "   ..., \n",
      "   [ 0.57677078  0.57218742  0.83540475]\n",
      "   [ 0.5772748   0.53042221  0.8254056 ]\n",
      "   [ 0.62326121  0.58188117  0.78077251]]\n",
      "\n",
      "  [[ 0.98291159  0.7065419   0.60939032]\n",
      "   [ 0.99038231  0.77193147  0.70748639]\n",
      "   [ 0.98028153  0.69432354  0.66977489]\n",
      "   ..., \n",
      "   [ 0.44446281  0.522291    0.84282166]\n",
      "   [ 0.55456805  0.59927869  0.85255373]\n",
      "   [ 0.62598187  0.5794186   0.8357389 ]]\n",
      "\n",
      "  [[ 0.98686475  0.68982488  0.61402738]\n",
      "   [ 0.99107599  0.7437461   0.71267933]\n",
      "   [ 0.98453093  0.65273875  0.682338  ]\n",
      "   ..., \n",
      "   [ 0.36802554  0.47437817  0.77578771]\n",
      "   [ 0.47541428  0.56893826  0.83663559]\n",
      "   [ 0.67850298  0.59782028  0.82399988]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.84665513  0.68199998  0.79151887]\n",
      "   [ 0.82366949  0.6792208   0.8090657 ]\n",
      "   [ 0.74235147  0.62789518  0.78814793]\n",
      "   ..., \n",
      "   [ 0.99737358  0.97040296  0.94392091]\n",
      "   [ 0.99913204  0.98470235  0.9643122 ]\n",
      "   [ 0.99766171  0.96918488  0.93954402]]\n",
      "\n",
      "  [[ 0.83622652  0.66709459  0.78492713]\n",
      "   [ 0.81653392  0.66143197  0.79280543]\n",
      "   [ 0.7339195   0.62440306  0.79124349]\n",
      "   ..., \n",
      "   [ 0.99855781  0.98281866  0.96069062]\n",
      "   [ 0.99802113  0.9714976   0.93277311]\n",
      "   [ 0.99241406  0.93379927  0.87223423]]\n",
      "\n",
      "  [[ 0.76435173  0.61154968  0.72792697]\n",
      "   [ 0.81174612  0.66110861  0.78936124]\n",
      "   [ 0.75390786  0.64717835  0.77045387]\n",
      "   ..., \n",
      "   [ 0.99494815  0.96444678  0.92458355]\n",
      "   [ 0.98763525  0.91583204  0.81586343]\n",
      "   [ 0.97184646  0.86407363  0.76161009]]]\n",
      "\n",
      "\n",
      " [[[ 0.92305076  0.68459088  0.66744375]\n",
      "   [ 0.91527438  0.52145725  0.5626694 ]\n",
      "   [ 0.91534817  0.41696709  0.49327171]\n",
      "   ..., \n",
      "   [ 0.97467232  0.48872906  0.57520205]\n",
      "   [ 0.96501273  0.45384324  0.55682224]\n",
      "   [ 0.94810319  0.51788312  0.54119033]]\n",
      "\n",
      "  [[ 0.9443832   0.67105424  0.65815508]\n",
      "   [ 0.90860879  0.46403295  0.52908087]\n",
      "   [ 0.89292115  0.33952981  0.46152982]\n",
      "   ..., \n",
      "   [ 0.97175878  0.41238776  0.60755336]\n",
      "   [ 0.9700436   0.46778673  0.60852802]\n",
      "   [ 0.97375983  0.5735541   0.66198778]]\n",
      "\n",
      "  [[ 0.93726259  0.63410598  0.62637037]\n",
      "   [ 0.85878754  0.38833141  0.48837507]\n",
      "   [ 0.86769533  0.30714282  0.44962478]\n",
      "   ..., \n",
      "   [ 0.96700883  0.39496484  0.60218036]\n",
      "   [ 0.96513242  0.42246005  0.59641832]\n",
      "   [ 0.97896123  0.63344455  0.694547  ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.99430138  0.96886528  0.94887698]\n",
      "   [ 0.9933902   0.96019995  0.92594129]\n",
      "   [ 0.9926213   0.95915878  0.92723787]\n",
      "   ..., \n",
      "   [ 0.85145873  0.4717871   0.54933947]\n",
      "   [ 0.86492825  0.57252628  0.61418915]\n",
      "   [ 0.75999868  0.43637675  0.44506863]]\n",
      "\n",
      "  [[ 0.99524415  0.96782732  0.95096731]\n",
      "   [ 0.99455309  0.95584977  0.92183924]\n",
      "   [ 0.99213624  0.94091308  0.89721394]\n",
      "   ..., \n",
      "   [ 0.84629959  0.4515999   0.53632402]\n",
      "   [ 0.89386594  0.5785653   0.62136394]\n",
      "   [ 0.81139934  0.46353185  0.47243175]]\n",
      "\n",
      "  [[ 0.99154043  0.95245707  0.93950468]\n",
      "   [ 0.99452806  0.95221972  0.92957807]\n",
      "   [ 0.99313718  0.94865298  0.91933692]\n",
      "   ..., \n",
      "   [ 0.83248353  0.48132342  0.50811762]\n",
      "   [ 0.871324    0.54701257  0.55882388]\n",
      "   [ 0.84097421  0.55061764  0.54154903]]]\n",
      "\n",
      "\n",
      " [[[ 0.97025603  0.90368474  0.83419394]\n",
      "   [ 0.98336917  0.92970538  0.87737197]\n",
      "   [ 0.99348938  0.9644556   0.92851889]\n",
      "   ..., \n",
      "   [ 0.92819291  0.47338423  0.44465724]\n",
      "   [ 0.89394796  0.41611007  0.40640789]\n",
      "   [ 0.8902837   0.51273656  0.47615755]]\n",
      "\n",
      "  [[ 0.97466826  0.89063931  0.77183324]\n",
      "   [ 0.99053574  0.94842267  0.87723172]\n",
      "   [ 0.99690056  0.97862947  0.94980049]\n",
      "   ..., \n",
      "   [ 0.94668722  0.44619057  0.47975335]\n",
      "   [ 0.9121052   0.38918877  0.40664178]\n",
      "   [ 0.9115445   0.46083927  0.4877165 ]]\n",
      "\n",
      "  [[ 0.98133624  0.90050393  0.77777147]\n",
      "   [ 0.99659348  0.9745152   0.93094945]\n",
      "   [ 0.99878329  0.98942137  0.97116667]\n",
      "   ..., \n",
      "   [ 0.96494401  0.46574947  0.53006989]\n",
      "   [ 0.93966746  0.39343125  0.4586547 ]\n",
      "   [ 0.91555637  0.44409946  0.48425758]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.95569551  0.7318362   0.67364812]\n",
      "   [ 0.96375394  0.74038833  0.6564489 ]\n",
      "   [ 0.96476269  0.74682999  0.69184494]\n",
      "   ..., \n",
      "   [ 0.99751973  0.95851344  0.82949144]\n",
      "   [ 0.99760544  0.96822733  0.85954684]\n",
      "   [ 0.99683195  0.97635806  0.90172458]]\n",
      "\n",
      "  [[ 0.91007483  0.58189452  0.50246   ]\n",
      "   [ 0.93237054  0.64749277  0.56595534]\n",
      "   [ 0.90721363  0.59077126  0.5404343 ]\n",
      "   ..., \n",
      "   [ 0.99708796  0.95662999  0.81661022]\n",
      "   [ 0.99696076  0.96773279  0.84711057]\n",
      "   [ 0.99328959  0.96607357  0.87498051]]\n",
      "\n",
      "  [[ 0.89614373  0.61363989  0.55900854]\n",
      "   [ 0.89765638  0.58112997  0.51744062]\n",
      "   [ 0.80455261  0.44438046  0.42490715]\n",
      "   ..., \n",
      "   [ 0.99598444  0.94544882  0.82950878]\n",
      "   [ 0.99494469  0.96182793  0.87036556]\n",
      "   [ 0.98280305  0.94982719  0.84004742]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nas-5.1/thchu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/nfs/nas-5.1/thchu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/nfs/nas-5.1/thchu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:59: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "print (text_path)\n",
    "tf.reset_default_graph()\n",
    "gan = GAN()\n",
    "gan.build_net()\n",
    "gan.saver.restore(gan.sess, './model_tf/model_gan9_bs16_HEclass_original.ckpt')\n",
    "# gan.saver.restore(gan.sess, './model_tf/model_gan9_bs16_HEclass_more.ckpt')\n",
    "# gan.saver.restore(gan.sess, './model_tf/model_gan.ckpt')\n",
    "with open(text_path, 'r') as f :\n",
    "#     lst_text = f.readlines()\n",
    "    for text in f.readlines() :\n",
    "        lst_temp = text.split(',')\n",
    "        testing_text_id = lst_temp[0]\n",
    "        testing_text = lst_temp[1]\n",
    "        hair_style, eyes_style = text_pre(text)\n",
    "        generate_img(testing_text_id=testing_text_id,hair_style=hair_style,eyes_style=eyes_style,gan=gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
