{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "# from skimage.viewer import ImageViewer\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import scipy\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "def leaky_relu(features, alpha=0.2, name=None):\n",
    "    \"\"\"Compute the Leaky ReLU activation function.\n",
    "    \"Rectifier Nonlinearities Improve Neural Network Acoustic Models\"\n",
    "    AL Maas, AY Hannun, AY Ng - Proc. ICML, 2013\n",
    "    http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf\n",
    "    Args:\n",
    "    features: A `Tensor` representing preactivation values.\n",
    "    alpha: Slope of the activation function at x < 0.\n",
    "    name: A name for the operation (optional).\n",
    "    Returns:\n",
    "    The activation value.\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name, \"LeakyRelu\", [features, alpha]):\n",
    "        features = ops.convert_to_tensor(features, name=\"features\")\n",
    "        alpha = ops.convert_to_tensor(alpha, name=\"alpha\")\n",
    "        return math_ops.maximum(alpha * features, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argument setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# def init():\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     session = tf.Session(config=config)\n",
    "#     keras.backend.tensorflow_backend.set_session(session)\n",
    "# init()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "img_path = './data'\n",
    "len_img_all = 33431\n",
    "condition = True\n",
    "load_data = True\n",
    "tag_img_only = True\n",
    "batch_size = 16\n",
    "iteration = 100000\n",
    "D_ITER = 1\n",
    "G_ITER = 1\n",
    "d_lda = 10\n",
    "\n",
    "toy_test = False\n",
    "if toy_test :\n",
    "    len_img_all = 512\n",
    "    load_data = False\n",
    "if tag_img_only :\n",
    "    len_img_all = 11568\n",
    "output_str = 'gan9_bs16_HEclass_original'\n",
    "load_model = False\n",
    "\n",
    "pretrain_hair = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ary_tag_hair shape : (11568,)\n",
      "ary_tag_eyes shape : (11568,)\n",
      "ary_img shape : (11568, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "def img_prep(save=False, lst_null=None) :\n",
    "    print ('img_prep is runing')\n",
    "    if tag_img_only :\n",
    "        lst_img = []\n",
    "        for img_i in range(len_img_all) :\n",
    "            if img_i in lst_null :\n",
    "                continue\n",
    "            img_temp = skimage.io.imread('{}/faces/{}.jpg'.format(img_path,img_i))\n",
    "            img_temp = skimage.transform.resize(img_temp, (64,64))\n",
    "            lst_img += [img_temp]\n",
    "    else :\n",
    "        ary_img = np.zeros((len_img_all,64,64,3))\n",
    "        for img_i in range(len_img_all) :\n",
    "            img_temp = skimage.io.imread('{}/faces/{}.jpg'.format(img_path,img_i))\n",
    "            img_temp = skimage.transform.resize(img_temp, (64,64))\n",
    "            ary_img[img_i] = img_temp\n",
    "    if save :\n",
    "        if tag_img_only :\n",
    "            print ('./data_pp/ary_img_withtag is saving')\n",
    "            ary_img = np.asarray(lst_img)\n",
    "            np.save('./data_pp/ary_img_withtag', ary_img)\n",
    "        else :\n",
    "            np.save('./data_pp/ary_img', ary_img)\n",
    "            \n",
    "    print ('len_ary_img : {}'.format(len(ary_img)))\n",
    "    return ary_img\n",
    "    \n",
    "def tag_prep(save=False) :\n",
    "    # 1,6\n",
    "    # 2,4,12\n",
    "    # 3,5,9\n",
    "    # 7,10\n",
    "    lst_hair = ['null', 'orange hair', 'white hair', 'aqua hair', 'gray hair',\n",
    "                'green hair', 'red hair', 'purple hair', 'pink hair',\n",
    "                'blue hair', 'black hair', 'brown hair', 'blonde hair']\n",
    "    lst_eyes = ['null', 'gray eyes', 'black eyes', 'orange eyes',\n",
    "                'pink eyes', 'yellow eyes', 'aqua eyes', 'purple eyes',\n",
    "                'green eyes', 'brown eyes', 'red eyes', 'blue eyes']\n",
    "    \n",
    "    h_n = 0\n",
    "    e_n = 0  \n",
    "    lst_null = []\n",
    "    if tag_img_only :\n",
    "        lst_tag_hair = []\n",
    "        lst_tag_eyes = []\n",
    "        with open('{}/tags_clean.csv'.format(img_path), 'r') as f :\n",
    "            for line_i,line in enumerate(f.readlines()[:len_img_all]) :\n",
    "        #         sys.stdout.write(\"\\r{}\\t\".format(line_i))\n",
    "        #         sys.stdout.flush()\n",
    "\n",
    "                FLAG_h = False\n",
    "                FLAG_e = False\n",
    "                FLAG_double_tag = False\n",
    "                for h_i,h in enumerate(lst_hair) :\n",
    "                    if h in line :\n",
    "                        if FLAG_h :\n",
    "                            # double tag\n",
    "                            lst_tag_hair = lst_tag_hair[:-1]\n",
    "                            lst_null += [line_i]\n",
    "                            FLAG_double_tag = True\n",
    "                            break\n",
    "                        FLAG_h = 1\n",
    "                        lst_tag_hair += [h_i]\n",
    "                        h_n += 1\n",
    "                if not FLAG_h :\n",
    "                    lst_null += [line_i]\n",
    "                    continue\n",
    "                if FLAG_double_tag :\n",
    "                    continue\n",
    "                for e_i,e in enumerate(lst_eyes) :\n",
    "                    if e in line :\n",
    "                        if FLAG_e :\n",
    "                            # double tag\n",
    "                            lst_tag_eyes = lst_tag_eyes[:-1]\n",
    "                            lst_null += [line_i]\n",
    "                            lst_tag_hair = lst_tag_hair[:-1]\n",
    "                            break\n",
    "                        FLAG_e = 1\n",
    "                        lst_tag_eyes += [e_i]\n",
    "                        e_n += 1\n",
    "                if not FLAG_e :\n",
    "                    lst_null += [line_i]\n",
    "                    lst_tag_hair = lst_tag_hair[:-1]\n",
    "            print (len(lst_tag_hair))\n",
    "            print (len(lst_tag_eyes))\n",
    "            print ('number of hair tag : {}'.format(h_n))\n",
    "            print ('number of eyes tag : {}'.format(e_n))\n",
    "            print ('number of total img : {}'.format(line_i+1))\n",
    "            print ('number of total both tag : {}'.format(len(lst_tag_hair)))\n",
    "            print ('number of drop tag : {}'.format(len(lst_null)))\n",
    "            assert len(lst_tag_hair) == len(lst_tag_eyes), 'error'\n",
    "            print ('tag preprocessing done')\n",
    "            \n",
    "    else :\n",
    "        ary_tag_hair = np.zeros((len_img_all))\n",
    "        ary_tag_eyes = np.zeros((len_img_all))\n",
    "        with open('{}/tags_clean.csv'.format(img_path), 'r') as f :\n",
    "            for line_i,line in enumerate(f.readlines()[:len_img_all]) :\n",
    "        #         sys.stdout.write(\"\\r{}\\t\".format(line_i))\n",
    "        #         sys.stdout.flush()\n",
    "\n",
    "                flag_h = 0\n",
    "                flag_e = 0\n",
    "                for h_i,h in enumerate(lst_hair) :\n",
    "                    if h in line :\n",
    "                        ary_tag_hair[line_i] = h_i\n",
    "                        h_n += 1\n",
    "                for e_i,e in enumerate(lst_eyes) :\n",
    "                    if e in line :\n",
    "                        ary_tag_eyes[line_i] = e_i\n",
    "                        e_n += 1\n",
    "            assert len(ary_tag_hair) == len(ary_tag_eyes), 'error'\n",
    "            print ('number of hair tag : {}'.format(h_n))\n",
    "            print ('number of eyes tag : {}'.format(e_n))\n",
    "            print ('number of total img : {}'.format(line_i))\n",
    "            print ('tag preprocessing done')\n",
    "        \n",
    "    if save :\n",
    "        if not os.path.isdir('./data_pp') :\n",
    "            os.makedirs('./data_pp')\n",
    "        if tag_img_only :\n",
    "            print ('./data_pp/ary_tag_hair_withtag is saving')\n",
    "            ary_tag_hair = np.asarray(lst_tag_hair)\n",
    "            ary_tag_eyes = np.asarray(lst_tag_eyes)\n",
    "            np.save('./data_pp/ary_tag_hair_withtag', ary_tag_hair)\n",
    "            np.save('./data_pp/ary_tag_eyes_withtag', ary_tag_eyes)\n",
    "        else :\n",
    "            print ('./data_pp/ary_tag_hair is saving')\n",
    "            np.save('./data_pp/ary_tag_hair', ary_tag_hair)\n",
    "            np.save('./data_pp/ary_tag_eyes', ary_tag_eyes)\n",
    "    \n",
    "    return ary_tag_hair, ary_tag_eyes, lst_null\n",
    "    \n",
    "def preprocess(show=True, save=False, load=False) :\n",
    "    if load :\n",
    "        if tag_img_only :\n",
    "            ary_tag_hair = np.load('./data_pp/ary_tag_hair_withtag.npy')\n",
    "            ary_tag_eyes = np.load('./data_pp/ary_tag_eyes_withtag.npy')\n",
    "            ary_img = np.load('./data_pp/ary_img_withtag.npy')\n",
    "        else :\n",
    "            ary_tag_hair = np.load('./data_pp/ary_tag_hair.npy')\n",
    "            ary_tag_eyes = np.load('./data_pp/ary_tag_eyes.npy')\n",
    "            ary_img = np.load('./data_pp/ary_img.npy')\n",
    "    else :\n",
    "        ary_tag_hair, ary_tag_eyes, lst_null = tag_prep(save=save)\n",
    "        ary_img = img_prep(save=save, lst_null=lst_null)\n",
    "\n",
    "    if show :\n",
    "        print ('ary_tag_hair shape : {}'.format(ary_tag_hair.shape))\n",
    "        print ('ary_tag_eyes shape : {}'.format(ary_tag_eyes.shape))\n",
    "        print ('ary_img shape : {}'.format(ary_img.shape))\n",
    "#         imshow(ary_img[1])\n",
    "    \n",
    "    return ary_tag_hair, ary_tag_eyes, ary_img\n",
    "\n",
    "ary_tag_hair, ary_tag_eyes, ary_img = preprocess(show=True,save=False,load=load_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_no_condition(object):\n",
    "    def __init__(self) :\n",
    "        self.lr = 0.0001\n",
    "        self.momentum = 0.5\n",
    "        self.bs = batch_size # batch size is m of paper\n",
    "        self.bs_pre = 64\n",
    "        self.epoch = 10000\n",
    "        self.hair_n = 13\n",
    "        self.eyes_n = 12\n",
    "        self.lda = d_lda\n",
    "        self.epsilon = 0.5\n",
    "        self.activation = leaky_relu\n",
    "        self.initializer = tf.contrib.keras.initializers.he_normal()\n",
    "        \n",
    "    def build_G_net(self) :\n",
    "        with tf.variable_scope('G') as g_scope:\n",
    "#             self.G_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "#             self.G_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.G_in_noise = tf.placeholder(tf.float32, shape=[None,100])\n",
    "#             self.G_in_noise = tf.distributions.Normal(loc=0., scale=1.).sample([self.bs,100])\n",
    "            \n",
    "#             G_H_onehot = tf.one_hot(self.G_in_hair, self.hair_n)\n",
    "#             G_E_onehot = tf.one_hot(self.G_in_eyes, self.eyes_n)\n",
    "#             g = tf.concat([G_H_onehot, G_E_onehot, self.G_in_noise], axis=1)\n",
    "            \n",
    "#             g = keras.layers.Dense(4*4*1024, activation='linear')(g)\n",
    "            g = tf.layers.dense(self.G_in_noise,4*4*1024,activation=None)\n",
    "            g = tf.reshape(g,(-1,4,4,1024))\n",
    "#             g = self.activation(g)\n",
    "            \n",
    "            g = tf.layers.conv2d_transpose(g, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            self.g = tf.layers.conv2d_transpose(g, filters=3, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            \n",
    "            ####\n",
    "#             d = tf.layers.conv2d(self.D_img, filters=128, kernel_size=(5,5), strides=(2,2), \n",
    "#                                  padding='same', activation=self.activation, name='d_c1', reuse=None)\n",
    "#             d = tf.layers.conv2d(d, filters=256, kernel_size=(5,5), strides=(2,2), \n",
    "#                                  padding='same', activation=self.activation, name='d_c2', reuse=None)\n",
    "#             print (d)\n",
    "            \n",
    "        \n",
    "    def build_D_net(self) :\n",
    "        with tf.variable_scope('D') as d_scope:\n",
    "            self.D_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3])\n",
    "\n",
    "            self.D_in_img_right = self.D_in_img[:self.bs]\n",
    "            self.D_in_img_fake = self.D_in_img[self.bs:]\n",
    "            \n",
    "            use_epsilon_uniform = 1\n",
    "            if use_epsilon_uniform :\n",
    "                epsilon = np.random.random_sample()\n",
    "                self.D_x_hat_img = epsilon*self.D_in_img_right + (1-epsilon)*self.D_in_img_fake\n",
    "            else :\n",
    "                self.D_x_hat_img = self.epsilon*self.D_in_img_right + (1-self.epsilon)*self.D_in_img_fake\n",
    "                \n",
    "            self.D_img = tf.concat([self.D_in_img_right,self.D_in_img_fake,self.D_x_hat_img], axis=0)\n",
    "            \n",
    "            d = tf.layers.conv2d(self.D_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(1,1), strides=(1,1), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c5', reuse=None)\n",
    "            d = tf.reshape(d, [-1, 4*4*256]) \n",
    "            self.d_temp = tf.layers.dense(d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=None)\n",
    "            \n",
    "            self.d_right, self.d_fake, self.d_x_hat = tf.split(self.d_temp, num_or_size_splits=3, axis=0)\n",
    "#             self.d_right, self.d_fake_temp = tf.split(self.d_temp, num_or_size_splits=2, axis=0)\n",
    "#             self.d_fake, self.d_x_hat = tf.split(self.d_fake_temp, num_or_size_splits=2, axis=0)\n",
    "            \n",
    "#             ### wgan loss\n",
    "#             self.d = tf.concat([self.d_right, self.d_fake], axis=0)\n",
    "            \n",
    "            ### gradient penalty\n",
    "#             gradient_temp = tf.gradients(self.d_x_hat,[self.D_x_hat_img,self.D_x_hat_hair,self.D_x_hat_eyes])\n",
    "            gradient_temp = tf.gradients(self.d_x_hat,self.D_x_hat_img)\n",
    "            print (gradient_temp)\n",
    "#             self.gradient_penalty = tf.maximum(tf.constant(0.0, shape=[self.bs,1]), tf.sqrt(tf.square(gradient_temp)) - tf.constant(1.0, shape=[self.bs,1]))\n",
    "            self.gradient_penalty = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_temp), axis=1)) - 1)\n",
    "            self.gradient_penalty = self.lda * tf.reduce_mean(self.gradient_penalty)\n",
    "            \n",
    "            ### final loss\n",
    "            self.d_loss = - (tf.reduce_mean(self.d_right) - tf.reduce_mean(self.d_fake) - self.gradient_penalty)\n",
    "            \n",
    "            \n",
    "            self.d_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.d_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.d_loss, var_list=self.d_train_vars)\n",
    "            \n",
    "            ###\n",
    "            ### G loss\n",
    "            ###\n",
    "            self.G_D_in_img = self.g\n",
    "            \n",
    "            g_d = tf.layers.conv2d(self.G_D_in_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=True)\n",
    "            \n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(1,1), strides=(1,1), \n",
    "                                 padding='same', activation=self.activation, name='d_c5', kernel_initializer=self.initializer, reuse=True)\n",
    "            g_d = tf.reshape(g_d, [-1, 4*4*256]) \n",
    "            self.g_d_temp = tf.layers.dense(g_d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=True)\n",
    "            \n",
    "            self.gd_loss = - tf.reduce_mean(self.g_d_temp)\n",
    "            \n",
    "            self.gd_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"G/\")\n",
    "            print (self.gd_train_vars)\n",
    "            self.gd_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.gd_loss, var_list=self.gd_train_vars)\n",
    "            \n",
    "    def build_net(self) :\n",
    "        self.build_G_net()\n",
    "        self.build_D_net()\n",
    "        \n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        tf.summary.FileWriter(\"logs/\", self.sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self) :\n",
    "        self.lr = 0.0001\n",
    "        self.lr_pre = 0.0001\n",
    "        self.momentum = 0.5\n",
    "        self.bs = batch_size # batch size is m of paper\n",
    "        self.bs_pre = 128\n",
    "        self.epoch = 10000\n",
    "        self.hair_n = 13\n",
    "        self.eyes_n = 12\n",
    "        self.lda = d_lda\n",
    "        self.epsilon = 0.5\n",
    "        self.activation = leaky_relu\n",
    "        self.initializer = tf.contrib.keras.initializers.he_normal()\n",
    "        \n",
    "#     def build_hair_net(self) :\n",
    "#         with tf.variable_scope('hair') as hair_scope:\n",
    "#             self.hair_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "#             self.hair_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "            \n",
    "#             hair_H_onehot = tf.one_hot(self.hair_in_hair, self.hair_n)\n",
    "#             hair_temp = tf.layers.batch_normalization(self.hair_in_img, name='hair_b0', reuse=None)\n",
    "#             hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "#                                  padding='same', activation=self.activation, name='hair_c1', reuse=None)\n",
    "#             hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b1', reuse=None)\n",
    "#             hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "#                                  padding='same', activation=self.activation, name='hair_c2', reuse=None)\n",
    "#             hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b2', reuse=None)\n",
    "#             hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "#                                  padding='same', activation=self.activation, name='hair_c3', reuse=None)\n",
    "#             hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b3', reuse=None)\n",
    "#             hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "#                                  padding='same', activation=self.activation, name='hair_c4', reuse=None)\n",
    "#             hair_temp = tf.reshape(hair_temp, [-1, 4*4*32]) \n",
    "#             self.hair = tf.layers.dense(hair_temp, self.hair_n ,activation=tf.nn.softmax, name='hair_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "            \n",
    "#             self.hair_loss = tf.reduce_mean(-tf.reduce_sum(hair_H_onehot * tf.log(self.hair)))\n",
    "#             self.hair_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"hair/\")\n",
    "#             self.hair_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.hair_loss, var_list=self.hair_train_vars)\n",
    "            \n",
    "    def build_eyes_net(self) :\n",
    "        with tf.variable_scope('eyes') as eyes_scope:\n",
    "            self.eyes_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.eyes_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "\n",
    "            eyes_E_onehot = tf.one_hot(self.eyes_in_eyes, self.eyes_n)\n",
    "            eyes_temp = tf.layers.batch_normalization(self.eyes_in_img, name='eyes_b0', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c1', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b1', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c2', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b2', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c3', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b3', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c4', reuse=None)\n",
    "            eyes_temp = tf.reshape(eyes_temp, [-1, 4*4*32]) \n",
    "            self.eyes = tf.layers.dense(eyes_temp, self.eyes_n ,activation=tf.nn.softmax, name='eyes_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "\n",
    "            self.eyes_loss = tf.reduce_mean(-tf.reduce_sum(eyes_E_onehot * tf.log(self.eyes), reduction_indices=[1]))\n",
    "            self.eyes_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"eyes/\")\n",
    "            self.eyes_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.eyes_loss, var_list=self.eyes_train_vars)\n",
    "            \n",
    "            \n",
    "    def build_G_net(self) :\n",
    "        with tf.variable_scope('G') as g_scope:\n",
    "            self.G_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.G_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.G_in_noise = tf.placeholder(tf.float32, shape=[None,100])\n",
    "            \n",
    "            self.G_H_onehot = tf.one_hot(self.G_in_hair, self.hair_n)\n",
    "            self.G_E_onehot = tf.one_hot(self.G_in_eyes, self.eyes_n)\n",
    "            g = tf.concat([self.G_H_onehot, self.G_E_onehot, self.G_in_noise], axis=1)\n",
    "            g = tf.layers.dense(g,4*4*1024,activation=None)\n",
    "            g = tf.reshape(g,(-1,4,4,1024))\n",
    "            \n",
    "            g = tf.layers.conv2d_transpose(g, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            g = tf.layers.conv2d_transpose(g, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=self.activation)\n",
    "            g = tf.layers.batch_normalization(g)\n",
    "            self.g = tf.layers.conv2d_transpose(g, filters=3, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                           padding='same', activation=tf.nn.tanh)\n",
    "        \n",
    "    def build_D_net(self) :\n",
    "\n",
    "        with tf.variable_scope('D') as d_scope:\n",
    "\n",
    "            ### include right and fake1\n",
    "            self.D_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.D_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.D_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3])\n",
    "#             self.D_in_img = self.D_in_img*2 - 1\n",
    "            \n",
    "            D_H_onehot = tf.one_hot(self.D_in_hair, self.hair_n)\n",
    "            D_E_onehot = tf.one_hot(self.D_in_eyes, self.eyes_n)\n",
    "            \n",
    "            self.D_in_hair_right = D_H_onehot[:self.bs]\n",
    "            self.D_in_eyes_right = D_E_onehot[:self.bs]\n",
    "            self.D_in_img_right = self.D_in_img[:self.bs]\n",
    "            \n",
    "            self.D_in_hair_fake = D_H_onehot[self.bs:]\n",
    "            self.D_in_eyes_fake = D_E_onehot[self.bs:]\n",
    "            self.D_in_img_fake = self.D_in_img[self.bs:]\n",
    "            \n",
    "            use_epsilon_uniform = 1\n",
    "            if use_epsilon_uniform :\n",
    "                self.epsilon = tf.placeholder(tf.float32, shape=[1])\n",
    "                self.D_x_hat_hair = self.epsilon*self.D_in_hair_right + (1-self.epsilon)*self.D_in_hair_fake\n",
    "                self.D_x_hat_eyes = self.epsilon*self.D_in_eyes_right + (1-self.epsilon)*self.D_in_eyes_fake\n",
    "                self.D_x_hat_img = self.epsilon*self.D_in_img_right + (1-self.epsilon)*self.D_in_img_fake\n",
    "            else :\n",
    "                self.D_x_hat_hair = self.epsilon*self.D_in_hair_right + (1-self.epsilon)*self.D_in_hair_fake\n",
    "                self.D_x_hat_eyes = self.epsilon*self.D_in_eyes_right + (1-self.epsilon)*self.D_in_eyes_fake\n",
    "                self.D_x_hat_img = self.epsilon*self.D_in_img_right + (1-self.epsilon)*self.D_in_img_fake\n",
    "                \n",
    "            self.D_img = tf.concat([self.D_in_img_right,self.D_in_img_fake,self.D_x_hat_img], axis=0)\n",
    "            self.D_hair = tf.concat([self.D_in_hair_right,self.D_in_hair_fake,self.D_x_hat_hair], axis=0)\n",
    "            self.D_eyes = tf.concat([self.D_in_eyes_right,self.D_in_eyes_fake,self.D_x_hat_eyes], axis=0)\n",
    "            \n",
    "            d = tf.layers.conv2d(self.D_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=None)\n",
    "            d = tf.layers.conv2d(d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=None)\n",
    "            \n",
    "            D_tag_in = tf.concat([self.D_hair, self.D_eyes], axis=1)\n",
    "            D_tag_in = tf.layers.dense(D_tag_in,4*4*1024,activation=self.activation, name='d_d1', kernel_initializer=self.initializer, reuse=None)\n",
    "            D_tag_in = tf.reshape(D_tag_in,(-1,4,4,1024))\n",
    "            \n",
    "            d = tf.concat([d, D_tag_in], axis=3)\n",
    "            d = tf.layers.conv2d(d, filters=256, kernel_size=(1,1), strides=(1,1), \n",
    "                                 padding='same', activation=self.activation, name='d_c5', kernel_initializer=self.initializer, reuse=None)\n",
    "            d = tf.reshape(d, [-1, 4*4*256]) \n",
    "            self.d_temp = tf.layers.dense(d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=None)\n",
    "        \n",
    "            self.d_right, self.d_fake, self.d_x_hat = tf.split(self.d_temp, num_or_size_splits=3, axis=0)\n",
    "#             self.d_right, self.d_fake_temp = tf.split(self.d_temp, num_or_size_splits=2, axis=0)\n",
    "#             self.d_fake, self.d_x_hat = tf.split(self.d_fake_temp, num_or_size_splits=2, axis=0)\n",
    "            \n",
    "            ### gradient penalty\n",
    "#             gradient_temp = tf.gradients(self.d_x_hat,[self.D_x_hat_img,self.D_x_hat_hair,self.D_x_hat_eyes])\n",
    "            gradient_img_temp = tf.gradients(self.d_x_hat,self.D_x_hat_img)\n",
    "            gradient_hair_temp = tf.gradients(self.d_x_hat,self.D_x_hat_hair)\n",
    "            gradient_eyes_temp = tf.gradients(self.d_x_hat,self.D_x_hat_eyes)\n",
    "#             self.gradient_penalty = tf.maximum(tf.constant(0.0, shape=[self.bs,1]), tf.sqrt(tf.square(gradient_temp)) - tf.constant(1.0, shape=[self.bs,1]))\n",
    "            self.gradient_penalty_img = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_img_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_img = self.lda * tf.reduce_mean(self.gradient_penalty_img)\n",
    "            self.gradient_penalty_hair = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_hair_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_hair = self.lda * tf.reduce_mean(self.gradient_penalty_hair)\n",
    "            self.gradient_penalty_eyes = tf.square(tf.sqrt(tf.reduce_sum(tf.square(gradient_eyes_temp), axis=1)) - 1)\n",
    "#             self.gradient_penalty_eyes = self.lda * tf.reduce_mean(self.gradient_penalty_eyes)\n",
    "            self.gradient_penalty = self.lda * (tf.reduce_mean(self.gradient_penalty_img)\n",
    "                                                + tf.reduce_mean(self.gradient_penalty_hair)/10\n",
    "                                                + tf.reduce_mean(self.gradient_penalty_eyes)/10)\n",
    "            \n",
    "            ### final loss\n",
    "            self.d_loss = -(tf.reduce_mean(self.d_right) - tf.reduce_mean(self.d_fake) - self.gradient_penalty)\n",
    "            self.d_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.d_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.d_loss, var_list=self.d_train_vars)\n",
    "            \n",
    "            ### G_D loss\n",
    "            self.G_D_in_hair = self.G_in_hair\n",
    "            self.G_D_in_eyes = self.G_in_eyes\n",
    "            self.G_D_in_img = self.g\n",
    "            \n",
    "            self.G_D_eyes = tf.one_hot(self.G_D_in_eyes, self.eyes_n)\n",
    "            self.G_D_hair = tf.one_hot(self.G_D_in_hair, self.hair_n)\n",
    "            \n",
    "            g_d = tf.layers.conv2d(self.G_D_in_img, filters=128, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c1', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c2', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=512, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c3', reuse=True)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=1024, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='d_c4', reuse=True)\n",
    "            \n",
    "            G_D_tag_in = tf.concat([self.G_D_hair, self.G_D_eyes], axis=1)\n",
    "            G_D_tag_in = tf.layers.dense(G_D_tag_in,4*4*1024,activation=self.activation, name='d_d1', kernel_initializer=self.initializer, reuse=True)\n",
    "            G_D_tag_in = tf.reshape(G_D_tag_in,(-1,4,4,1024))\n",
    "            \n",
    "            g_d = tf.concat([g_d, G_D_tag_in], axis=3)\n",
    "            g_d = tf.layers.conv2d(g_d, filters=256, kernel_size=(1,1), strides=(1,1), \n",
    "                                 padding='same', activation=self.activation, name='d_c5', kernel_initializer=self.initializer, reuse=True)\n",
    "            g_d = tf.reshape(g_d, [-1, 4*4*256]) \n",
    "            self.g_d_temp = tf.layers.dense(g_d, 1 ,activation=None, name='d_d2', kernel_initializer=self.initializer, reuse=True)\n",
    "            \n",
    "            self.gd_loss = - tf.reduce_mean(self.g_d_temp)\n",
    "            \n",
    "            #\n",
    "            # HE classification\n",
    "            #\n",
    "            \n",
    "            # hair classification pretrained\n",
    "            self.hair_in_hair = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.hair_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "\n",
    "            hair_H_onehot = tf.one_hot(self.hair_in_hair, self.hair_n)\n",
    "            hair_temp = tf.layers.batch_normalization(self.hair_in_img, name='hair_b0', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c1', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b1', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c2', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b2', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c3', reuse=None)\n",
    "            hair_temp = tf.layers.batch_normalization(hair_temp, name='hair_b3', reuse=None)\n",
    "            hair_temp = tf.layers.conv2d(hair_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c4', reuse=None)\n",
    "            hair_temp = tf.reshape(hair_temp, [-1, 4*4*32]) \n",
    "            self.hair = tf.layers.dense(hair_temp, self.hair_n ,activation=tf.nn.softmax, name='hair_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "\n",
    "            self.hair_loss = tf.reduce_mean(-tf.reduce_sum(hair_H_onehot * tf.log(self.hair), axis=1))\n",
    "            self.hair_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.hair_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.hair_loss, var_list=self.hair_train_vars)\n",
    "            \n",
    "            # eyes classification pretrained\n",
    "            self.eyes_in_eyes = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.eyes_in_img = tf.placeholder(tf.float32, shape=[None,64,64,3]) \n",
    "\n",
    "            eyes_E_onehot = tf.one_hot(self.eyes_in_eyes, self.eyes_n)\n",
    "            eyes_temp = tf.layers.batch_normalization(self.eyes_in_img, name='eyes_b0', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c1', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b1', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c2', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b2', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c3', reuse=None)\n",
    "            eyes_temp = tf.layers.batch_normalization(eyes_temp, name='eyes_b3', reuse=None)\n",
    "            eyes_temp = tf.layers.conv2d(eyes_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c4', reuse=None)\n",
    "            eyes_temp = tf.reshape(eyes_temp, [-1, 4*4*32]) \n",
    "            self.eyes = tf.layers.dense(eyes_temp, self.eyes_n ,activation=tf.nn.softmax, name='eyes_s2', kernel_initializer=self.initializer, reuse=None)\n",
    "\n",
    "            self.eyes_loss = tf.reduce_mean(-tf.reduce_sum(eyes_E_onehot * tf.log(self.eyes), axis=1))\n",
    "            self.eyes_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"D/\")\n",
    "            self.eyes_train = tf.train.AdamOptimizer(learning_rate=self.lr_pre).minimize(self.eyes_loss, var_list=self.eyes_train_vars)\n",
    "            \n",
    "            ### hair classification\n",
    "            gh_temp = tf.layers.batch_normalization(self.g, name='hair_b0', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c1', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b1', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c2', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b2', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c3', reuse=True)\n",
    "            gh_temp = tf.layers.batch_normalization(gh_temp, name='hair_b3', reuse=True)\n",
    "            gh_temp = tf.layers.conv2d(gh_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='hair_c4', reuse=True)\n",
    "            gh_temp = tf.reshape(gh_temp, [-1, 4*4*32]) \n",
    "            self.gh = tf.layers.dense(gh_temp, self.hair_n ,activation=tf.nn.softmax, name='hair_s2', kernel_initializer=self.initializer, reuse=True)\n",
    "            \n",
    "            self.gh_loss = tf.reduce_mean(-tf.reduce_sum(self.G_H_onehot * tf.log(self.gh), axis=1))\n",
    "            \n",
    "            ### eyes classification\n",
    "            ge_temp = tf.layers.batch_normalization(self.g, name='eyes_b0', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c1', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b1', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c2', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b2', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c3', reuse=True)\n",
    "            ge_temp = tf.layers.batch_normalization(ge_temp, name='eyes_b3', reuse=True)\n",
    "            ge_temp = tf.layers.conv2d(ge_temp, filters=32, kernel_size=(5,5), strides=(2,2), kernel_initializer=self.initializer,\n",
    "                                 padding='same', activation=self.activation, name='eyes_c4', reuse=True)\n",
    "            ge_temp = tf.reshape(ge_temp, [-1, 4*4*32]) \n",
    "            self.ge = tf.layers.dense(ge_temp, self.eyes_n ,activation=tf.nn.softmax, name='eyes_s2', kernel_initializer=self.initializer, reuse=True)\n",
    "\n",
    "            self.ge_loss = tf.reduce_mean(-tf.reduce_sum(self.G_E_onehot * tf.log(self.ge), axis=1))\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.gd_loss_final = 1*self.gd_loss + 1*self.gh_loss + 1*self.ge_loss\n",
    "            \n",
    "            self.gd_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"G/\")\n",
    "            self.gd_train = tf.train.AdamOptimizer(learning_rate=self.lr,beta1=0.0,beta2=0.9).minimize(self.gd_loss_final, var_list=self.gd_train_vars)\n",
    "            \n",
    "    def build_net(self) :\n",
    "#         self.build_hair_net()\n",
    "#         self.build_eyes_net()\n",
    "        \n",
    "        self.build_G_net()\n",
    "        self.build_D_net()\n",
    "        \n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        tf.summary.FileWriter(\"logs/\", self.sess.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ary_tag_hair shape : (11568,)\n",
      "ary_tag_eyes shape : (11568,)\n",
      "ary_img shape : (11568, 64, 64, 3)\n",
      "0\n",
      "10368\tacc : 0.226\n",
      "1\n",
      "10368\tacc : 0.274\n",
      "2\n",
      "10368\tacc : 0.366\n",
      "3\n",
      "10368\tacc : 0.416\n",
      "4\n",
      "10368\tacc : 0.394\n",
      "5\n",
      "10368\tacc : 0.444\n",
      "6\n",
      "10368\tacc : 0.428\n",
      "7\n",
      "10368\tacc : 0.426\n",
      "8\n",
      "10368\tacc : 0.428\n",
      "9\n",
      "10368\tacc : 0.418\n",
      "0\n",
      "10368\tacc : 0.248\n",
      "1\n",
      "10368\tacc : 0.248\n",
      "2\n",
      "10368\tacc : 0.344\n",
      "3\n",
      "10368\tacc : 0.374\n",
      "4\n",
      "10368\tacc : 0.39\n",
      "5\n",
      "10368\tacc : 0.412\n",
      "6\n",
      "10368\tacc : 0.384\n",
      "7\n",
      "10368\tacc : 0.438\n",
      "8\n",
      "10368\tacc : 0.438\n",
      "9\n",
      "10368\tacc : 0.416\n",
      "0\n",
      "D loss : 10.282978057861328\n",
      "G loss : -0.1346791535615921\n",
      "saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nas-5.1/thchu/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:152: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_2.ckpt\n",
      "D loss : 8.656083106994629\n",
      "G loss : -0.5927639007568359\n",
      "D loss : 6.8685526847839355\n",
      "G loss : -1.3103978633880615\n",
      "D loss : 2.4678211212158203\n",
      "G loss : -3.703327178955078\n",
      "D loss : -6.225380897521973\n",
      "G loss : -11.144969940185547\n",
      "D loss : -10.782952308654785\n",
      "G loss : -30.037612915039062\n",
      "D loss : -25.789569854736328\n",
      "G loss : -77.09284973144531\n",
      "D loss : -22.52804183959961\n",
      "G loss : -141.54800415039062\n",
      "D loss : -16.150760650634766\n",
      "G loss : -120.32685852050781\n",
      "D loss : -17.696094512939453\n",
      "G loss : -83.56758117675781\n",
      "D loss : -53.90604019165039\n",
      "G loss : -71.4716796875\n",
      "D loss : -54.74716567993164\n",
      "G loss : -52.463645935058594\n",
      "D loss : -111.36660766601562\n",
      "G loss : 17.77989387512207\n",
      "D loss : -178.67739868164062\n",
      "G loss : -9.405557632446289\n",
      "D loss : -428.8134765625\n",
      "G loss : 57.68729782104492\n",
      "D loss : -456.6224365234375\n",
      "G loss : 106.26968383789062\n",
      "D loss : -523.5787353515625\n",
      "G loss : -93.41796875\n",
      "D loss : -201.11497497558594\n",
      "G loss : -629.778564453125\n",
      "D loss : -76.64222717285156\n",
      "G loss : -975.7051391601562\n",
      "D loss : 872.072021484375\n",
      "G loss : -1027.80615234375\n",
      "D loss : 242.72471618652344\n",
      "G loss : -1098.77099609375\n",
      "D loss : 220.08978271484375\n",
      "G loss : -997.6197509765625\n",
      "D loss : 64.54019165039062\n",
      "G loss : -874.24560546875\n",
      "D loss : -74.58460235595703\n",
      "G loss : -690.1620483398438\n",
      "D loss : -445.706787109375\n",
      "G loss : -577.9102783203125\n",
      "D loss : -571.04296875\n",
      "G loss : -530.39111328125\n",
      "D loss : -721.812255859375\n",
      "G loss : -267.896240234375\n",
      "D loss : -1022.3463745117188\n",
      "G loss : -1.8857383728027344\n",
      "D loss : -1786.681640625\n",
      "G loss : 171.65731811523438\n",
      "D loss : -2184.664794921875\n",
      "G loss : 286.07061767578125\n",
      "D loss : -3022.604736328125\n",
      "G loss : 532.823974609375\n",
      "D loss : -3750.720947265625\n",
      "G loss : 614.8347778320312\n",
      "D loss : -5215.9736328125\n",
      "G loss : 978.694091796875\n",
      "D loss : -4151.46630859375\n",
      "G loss : 952.4293212890625\n",
      "D loss : -6876.8525390625\n",
      "G loss : 1293.3404541015625\n",
      "D loss : -9106.10546875\n",
      "G loss : 974.71484375\n",
      "D loss : -616.10546875\n",
      "G loss : -2758.58349609375\n",
      "D loss : -2479.14404296875\n",
      "G loss : -7888.662109375\n",
      "D loss : 6175.228515625\n",
      "G loss : -7655.70361328125\n",
      "D loss : 1412.7198486328125\n",
      "G loss : -9746.466796875\n",
      "D loss : 2438.517578125\n",
      "G loss : -9443.642578125\n",
      "D loss : 495.52587890625\n",
      "G loss : -9130.408203125\n",
      "D loss : 637.01220703125\n",
      "G loss : -7488.9453125\n",
      "D loss : 1654.6712646484375\n",
      "G loss : -6118.31982421875\n",
      "D loss : 1101.0550537109375\n",
      "G loss : -5232.6982421875\n",
      "D loss : 1959.08740234375\n",
      "G loss : -4019.75048828125\n",
      "D loss : 462.8877868652344\n",
      "G loss : -2024.6024169921875\n",
      "D loss : 731.3878173828125\n",
      "G loss : 1508.247802734375\n",
      "D loss : -303.4034423828125\n",
      "G loss : 4664.763671875\n",
      "D loss : -946.3828735351562\n",
      "G loss : 6067.60888671875\n",
      "D loss : -1542.8187255859375\n",
      "G loss : 8526.78515625\n",
      "D loss : -2739.369384765625\n",
      "G loss : 11426.166015625\n",
      "D loss : -1848.9500732421875\n",
      "G loss : 12006.1015625\n",
      "D loss : -2014.8533935546875\n",
      "G loss : 11700.3466796875\n",
      "D loss : -735.59619140625\n",
      "G loss : 11905.1982421875\n",
      "D loss : -2071.427001953125\n",
      "G loss : 12160.0322265625\n",
      "D loss : -1056.165771484375\n",
      "G loss : 11386.8095703125\n",
      "D loss : -1326.26123046875\n",
      "G loss : 9662.6533203125\n",
      "D loss : -785.011474609375\n",
      "G loss : 10080.75\n",
      "D loss : -697.5616455078125\n",
      "G loss : 8230.91015625\n",
      "D loss : -61.36065673828125\n",
      "G loss : 4785.9931640625\n",
      "D loss : -565.3367919921875\n",
      "G loss : 3629.5693359375\n",
      "D loss : -390.95965576171875\n",
      "G loss : 1555.738525390625\n",
      "D loss : -242.09059143066406\n",
      "G loss : 171.186767578125\n",
      "D loss : -208.04110717773438\n",
      "G loss : -915.068359375\n",
      "D loss : -51.505828857421875\n",
      "G loss : 423.88372802734375\n",
      "D loss : -288.09344482421875\n",
      "G loss : -1560.9990234375\n",
      "D loss : -607.0137939453125\n",
      "G loss : -1813.1748046875\n",
      "D loss : -522.3983154296875\n",
      "G loss : -2371.949951171875\n",
      "D loss : 112.57699584960938\n",
      "G loss : -150.2360382080078\n",
      "D loss : -401.830078125\n",
      "G loss : 2781.81689453125\n",
      "D loss : -148.14830017089844\n",
      "G loss : 839.4476928710938\n",
      "D loss : -5.7535400390625\n",
      "G loss : -784.4154052734375\n",
      "D loss : -257.197021484375\n",
      "G loss : -2182.582275390625\n",
      "D loss : -335.84405517578125\n",
      "G loss : -2814.008544921875\n",
      "D loss : 144.15362548828125\n",
      "G loss : 86.7967529296875\n",
      "D loss : -823.4473266601562\n",
      "G loss : 2884.474609375\n",
      "D loss : -388.0440368652344\n",
      "G loss : 1916.2255859375\n",
      "D loss : -366.86053466796875\n",
      "G loss : 179.9714813232422\n",
      "D loss : -416.4835510253906\n",
      "G loss : -1147.79052734375\n",
      "D loss : -994.176513671875\n",
      "G loss : -608.3240356445312\n",
      "D loss : -631.8004150390625\n",
      "G loss : -2050.19384765625\n",
      "D loss : -464.0430908203125\n",
      "G loss : -10.2845458984375\n",
      "D loss : -1173.978759765625\n",
      "G loss : 2454.440185546875\n",
      "D loss : -1413.668701171875\n",
      "G loss : 2720.51171875\n",
      "D loss : -131.91928100585938\n",
      "G loss : -1001.5443725585938\n",
      "D loss : -945.248291015625\n",
      "G loss : -2769.35595703125\n",
      "D loss : -602.56982421875\n",
      "G loss : -2073.3173828125\n",
      "D loss : -1156.29345703125\n",
      "G loss : -418.0162353515625\n",
      "D loss : -1268.829345703125\n",
      "G loss : 2593.22802734375\n",
      "D loss : -1108.472900390625\n",
      "G loss : 636.1486206054688\n",
      "D loss : -834.267822265625\n",
      "G loss : -550.156494140625\n",
      "D loss : -1370.3714599609375\n",
      "G loss : 615.3416748046875\n",
      "D loss : -2406.368896484375\n",
      "G loss : 1377.7791748046875\n",
      "D loss : 1424.4293212890625\n",
      "G loss : -1824.303466796875\n",
      "D loss : -1884.1580810546875\n",
      "G loss : -2960.184326171875\n",
      "D loss : -2273.980712890625\n",
      "G loss : -4999.154296875\n",
      "D loss : -1354.9127197265625\n",
      "G loss : -6182.71533203125\n",
      "D loss : -1122.9063720703125\n",
      "G loss : -4143.974609375\n",
      "D loss : -1949.599609375\n",
      "G loss : -1826.8243408203125\n",
      "D loss : -1364.035888671875\n",
      "G loss : -3966.521240234375\n",
      "D loss : -1637.8968505859375\n",
      "G loss : -2163.8232421875\n",
      "D loss : -1534.2373046875\n",
      "G loss : -4168.423828125\n",
      "D loss : -2531.533203125\n",
      "G loss : -1998.2772216796875\n",
      "D loss : -2347.4296875\n",
      "G loss : 1766.60400390625\n",
      "D loss : -2637.604248046875\n",
      "G loss : 4316.70703125\n",
      "D loss : -789.1111450195312\n",
      "G loss : 2325.73388671875\n",
      "D loss : 241.95318603515625\n",
      "G loss : -1710.6063232421875\n",
      "D loss : -1881.556640625\n",
      "G loss : -3681.7197265625\n",
      "D loss : -1379.6923828125\n",
      "G loss : -2822.8046875\n",
      "D loss : -876.4285278320312\n",
      "G loss : -6069.3095703125\n",
      "D loss : -771.60498046875\n",
      "G loss : -5653.3828125\n",
      "D loss : -1157.8814697265625\n",
      "G loss : -7435.33984375\n",
      "D loss : 470.6302490234375\n",
      "G loss : -792.080810546875\n",
      "D loss : -461.9864501953125\n",
      "G loss : 166.15814208984375\n",
      "D loss : -67.70346069335938\n",
      "G loss : -176.81591796875\n",
      "D loss : 715.0289306640625\n",
      "G loss : -4826.87255859375\n",
      "D loss : -1041.795166015625\n",
      "G loss : -6394.3076171875\n",
      "D loss : -1220.0181884765625\n",
      "G loss : -7002.9619140625\n",
      "D loss : -692.849853515625\n",
      "G loss : -5505.02392578125\n",
      "D loss : -45.00909423828125\n",
      "G loss : -4220.517578125\n",
      "D loss : -562.3218994140625\n",
      "G loss : -1578.8065185546875\n",
      "D loss : -1427.333251953125\n",
      "G loss : -691.1951904296875\n",
      "D loss : -1484.575927734375\n",
      "G loss : 2133.684814453125\n",
      "D loss : -1135.8656005859375\n",
      "G loss : 1233.527099609375\n",
      "D loss : 571.7284545898438\n",
      "G loss : -454.61968994140625\n",
      "D loss : 91.58856201171875\n",
      "G loss : -4645.89892578125\n",
      "D loss : 147.71926879882812\n",
      "G loss : -3383.903564453125\n",
      "D loss : -288.19586181640625\n",
      "G loss : 661.864501953125\n",
      "D loss : 870.734619140625\n",
      "G loss : -1632.10107421875\n",
      "D loss : -622.1082763671875\n",
      "G loss : -3260.458984375\n",
      "D loss : 25.0048828125\n",
      "G loss : -2444.85986328125\n",
      "D loss : 551.0403442382812\n",
      "G loss : -4108.56005859375\n",
      "D loss : 201.2755126953125\n",
      "G loss : -2665.358642578125\n",
      "D loss : -922.6552734375\n",
      "G loss : -6156.5224609375\n",
      "D loss : 282.31085205078125\n",
      "G loss : -1243.5325927734375\n",
      "D loss : 395.12127685546875\n",
      "G loss : 3051.0341796875\n",
      "D loss : -958.97900390625\n",
      "G loss : 4586.8359375\n",
      "D loss : -949.886474609375\n",
      "G loss : 5750.7578125\n",
      "D loss : -807.7359008789062\n",
      "G loss : 8345.681640625\n",
      "D loss : 390.52874755859375\n",
      "G loss : 6654.83349609375\n",
      "D loss : -226.0084228515625\n",
      "G loss : 6227.939453125\n",
      "D loss : 43.884735107421875\n",
      "G loss : 7216.0478515625\n",
      "D loss : 433.0533447265625\n",
      "G loss : 2205.4755859375\n",
      "D loss : -1029.970947265625\n",
      "G loss : 1258.115234375\n",
      "D loss : -278.92071533203125\n",
      "G loss : 3156.048095703125\n",
      "D loss : 779.672119140625\n",
      "G loss : 10063.96875\n",
      "D loss : -102.63864135742188\n",
      "G loss : 5285.14208984375\n",
      "D loss : -428.36297607421875\n",
      "G loss : 2961.03759765625\n",
      "D loss : 525.0628662109375\n",
      "G loss : 2305.337890625\n",
      "D loss : 300.4925537109375\n",
      "G loss : 1756.3668212890625\n",
      "D loss : 337.3596496582031\n",
      "G loss : 819.93896484375\n",
      "D loss : 438.58953857421875\n",
      "G loss : 2934.0224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 514.9998168945312\n",
      "G loss : -747.0230712890625\n",
      "D loss : -151.32196044921875\n",
      "G loss : -940.6925659179688\n",
      "D loss : 570.7925415039062\n",
      "G loss : -1684.50634765625\n",
      "D loss : 91.48237609863281\n",
      "G loss : -614.5416870117188\n",
      "D loss : 646.8262939453125\n",
      "G loss : 660.4102783203125\n",
      "D loss : 367.95452880859375\n",
      "G loss : 1821.98779296875\n",
      "D loss : 422.2912292480469\n",
      "G loss : -266.9112548828125\n",
      "D loss : 159.04759216308594\n",
      "G loss : -1584.956787109375\n",
      "D loss : 356.50341796875\n",
      "G loss : -1749.0970458984375\n",
      "D loss : 74.4718017578125\n",
      "G loss : -1742.7420654296875\n",
      "D loss : 243.8710479736328\n",
      "G loss : 1420.97509765625\n",
      "D loss : 308.10626220703125\n",
      "G loss : 492.30096435546875\n",
      "D loss : 327.5150451660156\n",
      "G loss : -119.13943481445312\n",
      "D loss : 169.46461486816406\n",
      "G loss : -1313.44189453125\n",
      "D loss : -116.7326889038086\n",
      "G loss : -23.21529769897461\n",
      "D loss : -161.44570922851562\n",
      "G loss : -202.2698974609375\n",
      "D loss : 240.36016845703125\n",
      "G loss : -1154.281494140625\n",
      "D loss : 40.38686752319336\n",
      "G loss : -1935.498779296875\n",
      "D loss : 55.9066047668457\n",
      "G loss : -1225.851318359375\n",
      "D loss : -242.99752807617188\n",
      "G loss : -1253.054931640625\n",
      "D loss : -247.24160766601562\n",
      "G loss : -1088.9111328125\n",
      "D loss : -161.48611450195312\n",
      "G loss : -1473.374267578125\n",
      "D loss : 50.494441986083984\n",
      "G loss : -389.996826171875\n",
      "D loss : 504.94012451171875\n",
      "G loss : 1195.082275390625\n",
      "D loss : -236.84555053710938\n",
      "G loss : 1332.10693359375\n",
      "D loss : -447.6241149902344\n",
      "G loss : 1161.872802734375\n",
      "D loss : -503.1330261230469\n",
      "G loss : 913.0211181640625\n",
      "D loss : 11.248218536376953\n",
      "G loss : 900.0410766601562\n",
      "D loss : -160.34820556640625\n",
      "G loss : -211.49612426757812\n",
      "D loss : -74.96490478515625\n",
      "G loss : -599.2120361328125\n",
      "D loss : -245.08468627929688\n",
      "G loss : -108.93865966796875\n",
      "D loss : 33.69373321533203\n",
      "G loss : 171.06971740722656\n",
      "D loss : -204.25625610351562\n",
      "G loss : 830.072021484375\n",
      "D loss : -381.1822509765625\n",
      "G loss : 349.7614440917969\n",
      "D loss : 309.9850769042969\n",
      "G loss : 29.06848907470703\n",
      "D loss : -75.97179412841797\n",
      "G loss : 122.02131652832031\n",
      "D loss : -287.85955810546875\n",
      "G loss : -569.0061645507812\n",
      "D loss : -111.74240112304688\n",
      "G loss : -307.48779296875\n",
      "D loss : -203.32269287109375\n",
      "G loss : -1759.458984375\n",
      "D loss : -491.1560974121094\n",
      "G loss : -1734.0008544921875\n",
      "D loss : -176.52536010742188\n",
      "G loss : 8.277786254882812\n",
      "D loss : 28.90821075439453\n",
      "G loss : -581.7738037109375\n",
      "D loss : 522.678466796875\n",
      "G loss : 2461.34033203125\n",
      "D loss : -192.91696166992188\n",
      "G loss : 4271.8857421875\n",
      "D loss : -400.3703918457031\n",
      "G loss : 4046.951171875\n",
      "D loss : 144.1044464111328\n",
      "G loss : 2729.560302734375\n",
      "D loss : 85.45042419433594\n",
      "G loss : 858.2486572265625\n",
      "D loss : 135.18508911132812\n",
      "G loss : -273.65020751953125\n",
      "D loss : -242.4230194091797\n",
      "G loss : -813.216796875\n",
      "D loss : -4.759971618652344\n",
      "G loss : 108.037353515625\n",
      "D loss : 33.53406524658203\n",
      "G loss : -454.60076904296875\n",
      "D loss : -44.80470275878906\n",
      "G loss : -508.82958984375\n",
      "D loss : 234.86361694335938\n",
      "G loss : -1807.5859375\n",
      "D loss : 140.76168823242188\n",
      "G loss : -1098.7647705078125\n",
      "D loss : 180.5745391845703\n",
      "G loss : 764.3713989257812\n",
      "D loss : -158.9786834716797\n",
      "G loss : 1045.398193359375\n",
      "D loss : -166.26812744140625\n",
      "G loss : 1368.8994140625\n",
      "D loss : -27.801429748535156\n",
      "G loss : 730.3648681640625\n",
      "D loss : 512.0624389648438\n",
      "G loss : 837.3096313476562\n",
      "D loss : -54.23590850830078\n",
      "G loss : 727.3267211914062\n",
      "D loss : -75.00373840332031\n",
      "G loss : 491.8257141113281\n",
      "D loss : 130.07400512695312\n",
      "G loss : -1290.414306640625\n",
      "D loss : 262.03662109375\n",
      "G loss : -975.13623046875\n",
      "D loss : -23.069969177246094\n",
      "G loss : -429.01104736328125\n",
      "D loss : 104.87349700927734\n",
      "G loss : -376.96136474609375\n",
      "D loss : -112.56541442871094\n",
      "G loss : 640.3689575195312\n",
      "D loss : -47.608741760253906\n",
      "G loss : 633.5467529296875\n",
      "D loss : -1.7030830383300781\n",
      "G loss : 304.67181396484375\n",
      "D loss : -133.1166229248047\n",
      "G loss : -202.06150817871094\n",
      "D loss : -162.7822265625\n",
      "G loss : -257.39776611328125\n",
      "D loss : 15.337369918823242\n",
      "G loss : 1008.4671630859375\n",
      "D loss : 217.40110778808594\n",
      "G loss : 370.8843994140625\n",
      "D loss : 49.24440383911133\n",
      "G loss : -1150.493896484375\n",
      "D loss : -43.494163513183594\n",
      "G loss : -864.3519287109375\n",
      "D loss : 39.539337158203125\n",
      "G loss : 1768.3641357421875\n",
      "D loss : 123.74320983886719\n",
      "G loss : 297.92999267578125\n",
      "D loss : 11.490842819213867\n",
      "G loss : -1089.1339111328125\n",
      "D loss : -218.96139526367188\n",
      "G loss : -2022.199462890625\n",
      "D loss : -263.4586181640625\n",
      "G loss : -2836.85107421875\n",
      "D loss : 724.5414428710938\n",
      "G loss : 588.0228271484375\n",
      "D loss : -353.00048828125\n",
      "G loss : 3206.53369140625\n",
      "D loss : -372.61981201171875\n",
      "G loss : 2706.62841796875\n",
      "D loss : -82.10823059082031\n",
      "G loss : 2469.5888671875\n",
      "D loss : 340.8382263183594\n",
      "G loss : 250.25125122070312\n",
      "D loss : -125.32354736328125\n",
      "G loss : -1032.6024169921875\n",
      "D loss : -72.20274353027344\n",
      "G loss : -1114.7791748046875\n",
      "D loss : -258.48736572265625\n",
      "G loss : -1419.79248046875\n",
      "D loss : -228.21168518066406\n",
      "G loss : -1615.66259765625\n",
      "D loss : -385.2319641113281\n",
      "G loss : -2509.34423828125\n",
      "D loss : 458.4645690917969\n",
      "G loss : 661.360107421875\n",
      "D loss : -337.81353759765625\n",
      "G loss : 1151.246826171875\n",
      "D loss : -154.24560546875\n",
      "G loss : 3777.7412109375\n",
      "D loss : 118.36665344238281\n",
      "G loss : 1589.3466796875\n",
      "D loss : 196.77471923828125\n",
      "G loss : 620.238037109375\n",
      "D loss : 227.7708282470703\n",
      "G loss : -592.14599609375\n",
      "D loss : -33.60624694824219\n",
      "G loss : -165.0448760986328\n",
      "D loss : -10.958309173583984\n",
      "G loss : -373.96856689453125\n",
      "D loss : -77.92054748535156\n",
      "G loss : -1457.843017578125\n",
      "D loss : -81.81645202636719\n",
      "G loss : -1889.203125\n",
      "D loss : -58.48529815673828\n",
      "G loss : -2423.6904296875\n",
      "D loss : -48.00094223022461\n",
      "G loss : -2022.234130859375\n",
      "D loss : 41.57400131225586\n",
      "G loss : -2391.1650390625\n",
      "D loss : 61.25935363769531\n",
      "G loss : -1906.374267578125\n",
      "D loss : 133.86827087402344\n",
      "G loss : -681.0657958984375\n",
      "D loss : -122.53648376464844\n",
      "G loss : -1073.5849609375\n",
      "D loss : 55.93635940551758\n",
      "G loss : 1709.730224609375\n",
      "D loss : -132.49346923828125\n",
      "G loss : 2057.61474609375\n",
      "D loss : 253.92245483398438\n",
      "G loss : 2303.6875\n",
      "D loss : -74.81578063964844\n",
      "G loss : 2369.4208984375\n",
      "D loss : 45.95384216308594\n",
      "G loss : 1163.9622802734375\n",
      "D loss : -134.64630126953125\n",
      "G loss : 1158.188720703125\n",
      "D loss : -134.3343505859375\n",
      "G loss : 808.2933959960938\n",
      "D loss : 64.18511962890625\n",
      "G loss : -148.89028930664062\n",
      "D loss : 58.97876739501953\n",
      "G loss : -381.91473388671875\n",
      "D loss : -111.5406494140625\n",
      "G loss : -880.9884033203125\n",
      "D loss : -128.82867431640625\n",
      "G loss : -1016.9967651367188\n",
      "D loss : -285.0357666015625\n",
      "G loss : -3096.39111328125\n",
      "D loss : -62.000694274902344\n",
      "G loss : -2351.78173828125\n",
      "D loss : 138.42625427246094\n",
      "G loss : -890.4381713867188\n",
      "D loss : 325.33001708984375\n",
      "G loss : 1661.3350830078125\n",
      "D loss : -277.8888244628906\n",
      "G loss : 1696.040283203125\n",
      "D loss : -99.42366027832031\n",
      "G loss : 1153.701416015625\n",
      "D loss : -93.28594970703125\n",
      "G loss : 743.36962890625\n",
      "D loss : -126.18192291259766\n",
      "G loss : -173.93572998046875\n",
      "D loss : 475.16302490234375\n",
      "G loss : 548.7638549804688\n",
      "D loss : -116.68167877197266\n",
      "G loss : 2653.786865234375\n",
      "D loss : 38.714813232421875\n",
      "G loss : 1711.4720458984375\n",
      "D loss : -184.72230529785156\n",
      "G loss : 2387.454833984375\n",
      "D loss : -277.30035400390625\n",
      "G loss : 2511.58984375\n",
      "D loss : -303.8468322753906\n",
      "G loss : 1735.740478515625\n",
      "D loss : -344.6099853515625\n",
      "G loss : 1457.09912109375\n",
      "D loss : 892.6100463867188\n",
      "G loss : 722.6615600585938\n",
      "D loss : 125.68212890625\n",
      "G loss : 309.56024169921875\n",
      "D loss : -31.79895782470703\n",
      "G loss : 400.2478332519531\n",
      "D loss : -10.118006706237793\n",
      "G loss : 107.91627502441406\n",
      "D loss : -175.46531677246094\n",
      "G loss : 0.1502685546875\n",
      "D loss : 206.92657470703125\n",
      "G loss : -379.04022216796875\n",
      "D loss : -131.86505126953125\n",
      "G loss : -488.2915954589844\n",
      "D loss : -114.07038879394531\n",
      "G loss : -1092.158447265625\n",
      "D loss : -76.50447845458984\n",
      "G loss : -1785.7392578125\n",
      "D loss : -138.44699096679688\n",
      "G loss : -2060.275390625\n",
      "D loss : -293.9151916503906\n",
      "G loss : -3327.631103515625\n",
      "D loss : 216.95608520507812\n",
      "G loss : -2793.966796875\n",
      "D loss : 77.44973754882812\n",
      "G loss : -2073.090576171875\n",
      "D loss : 197.81411743164062\n",
      "G loss : -459.35931396484375\n",
      "D loss : -23.16541290283203\n",
      "G loss : 2028.7249755859375\n",
      "D loss : -344.6070861816406\n",
      "G loss : 2945.75146484375\n",
      "D loss : -159.98065185546875\n",
      "G loss : 2962.779052734375\n",
      "D loss : 21.213302612304688\n",
      "G loss : 2662.52783203125\n",
      "D loss : 215.306884765625\n",
      "G loss : 1748.0985107421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : -63.51777267456055\n",
      "G loss : 2299.509765625\n",
      "D loss : 165.5795135498047\n",
      "G loss : 1255.07080078125\n",
      "D loss : 152.4681396484375\n",
      "G loss : 37.008338928222656\n",
      "D loss : 194.27926635742188\n",
      "G loss : -327.150634765625\n",
      "D loss : -48.6016960144043\n",
      "G loss : -875.3851318359375\n",
      "D loss : -239.9550323486328\n",
      "G loss : -1331.5299072265625\n",
      "D loss : -278.9176025390625\n",
      "G loss : -1855.5015869140625\n",
      "D loss : 10.334604263305664\n",
      "G loss : -1224.619140625\n",
      "D loss : -183.89056396484375\n",
      "G loss : -663.2001953125\n",
      "D loss : -86.50570678710938\n",
      "G loss : -1215.56103515625\n",
      "D loss : -81.70867919921875\n",
      "G loss : -1011.6103515625\n",
      "D loss : 138.50599670410156\n",
      "G loss : -461.5142517089844\n",
      "D loss : 30.07234001159668\n",
      "G loss : -478.74395751953125\n",
      "D loss : -159.81089782714844\n",
      "G loss : 496.219482421875\n",
      "D loss : 290.3668212890625\n",
      "G loss : 1500.4078369140625\n",
      "D loss : -1.0594844818115234\n",
      "G loss : 1683.2152099609375\n",
      "D loss : 150.12860107421875\n",
      "G loss : 1183.5794677734375\n",
      "D loss : -89.75062561035156\n",
      "G loss : 1010.482177734375\n",
      "D loss : -158.56478881835938\n",
      "G loss : 626.0408325195312\n",
      "D loss : -22.047710418701172\n",
      "G loss : 790.2922973632812\n",
      "D loss : -322.2618103027344\n",
      "G loss : 1334.242919921875\n",
      "D loss : 171.35580444335938\n",
      "G loss : 107.43150329589844\n",
      "D loss : -90.09384155273438\n",
      "G loss : -298.8248291015625\n",
      "D loss : -80.99016571044922\n",
      "G loss : 189.8861083984375\n",
      "D loss : 70.71168518066406\n",
      "G loss : -650.2305908203125\n",
      "D loss : 6.352560043334961\n",
      "G loss : -1242.486083984375\n",
      "D loss : 34.028038024902344\n",
      "G loss : -543.390869140625\n",
      "D loss : 108.61121368408203\n",
      "G loss : -637.7938232421875\n",
      "D loss : 167.90090942382812\n",
      "G loss : 702.4486694335938\n",
      "D loss : -51.529354095458984\n",
      "G loss : 1081.5772705078125\n",
      "D loss : 168.30313110351562\n",
      "G loss : 1405.8221435546875\n",
      "D loss : -7.557385444641113\n",
      "G loss : 1462.5654296875\n",
      "D loss : -11.774993896484375\n",
      "G loss : 854.0747680664062\n",
      "D loss : 143.71949768066406\n",
      "G loss : 407.5541076660156\n",
      "D loss : 14.222543716430664\n",
      "G loss : 276.87615966796875\n",
      "D loss : -77.4296646118164\n",
      "G loss : 260.7313232421875\n",
      "D loss : -154.88638305664062\n",
      "G loss : -248.58360290527344\n",
      "D loss : -139.32174682617188\n",
      "G loss : -670.0281372070312\n",
      "D loss : 154.12490844726562\n",
      "G loss : -1875.0172119140625\n",
      "D loss : 66.03862762451172\n",
      "G loss : -1308.8961181640625\n",
      "D loss : 181.1232147216797\n",
      "G loss : -542.0938720703125\n",
      "D loss : 110.8512954711914\n",
      "G loss : 652.3795776367188\n",
      "D loss : -106.46710968017578\n",
      "G loss : 809.8790893554688\n",
      "D loss : -75.1337661743164\n",
      "G loss : 161.38372802734375\n",
      "D loss : -225.2482147216797\n",
      "G loss : 1168.8765869140625\n",
      "D loss : -108.44607543945312\n",
      "G loss : 1481.838623046875\n",
      "D loss : -13.834718704223633\n",
      "G loss : 645.9383544921875\n",
      "D loss : 204.71701049804688\n",
      "G loss : -48.252567291259766\n",
      "D loss : -238.79454040527344\n",
      "G loss : 187.98007202148438\n",
      "D loss : -247.56373596191406\n",
      "G loss : -178.8396759033203\n",
      "D loss : -246.37908935546875\n",
      "G loss : -1883.06787109375\n",
      "D loss : 280.1917724609375\n",
      "G loss : -723.0980224609375\n",
      "D loss : -122.0531005859375\n",
      "G loss : 309.0915832519531\n",
      "D loss : 16.734390258789062\n",
      "G loss : 150.08123779296875\n",
      "D loss : 183.70306396484375\n",
      "G loss : 615.7623291015625\n",
      "D loss : 132.4493865966797\n",
      "G loss : 753.08544921875\n",
      "D loss : 16.281993865966797\n",
      "G loss : 627.9320068359375\n",
      "D loss : 222.10000610351562\n",
      "G loss : 271.17974853515625\n",
      "D loss : -0.01844501495361328\n",
      "G loss : 406.2922668457031\n",
      "D loss : -107.103515625\n",
      "G loss : 383.7388000488281\n",
      "D loss : 0.9653444290161133\n",
      "G loss : -92.28555297851562\n",
      "D loss : 5.33729362487793\n",
      "G loss : -13.284473419189453\n",
      "D loss : 158.98475646972656\n",
      "G loss : -489.9075012207031\n",
      "D loss : -85.3089828491211\n",
      "G loss : -991.2215576171875\n",
      "D loss : -53.283145904541016\n",
      "G loss : -1410.1947021484375\n",
      "D loss : -65.41835021972656\n",
      "G loss : -1497.977294921875\n",
      "D loss : -0.03225898742675781\n",
      "G loss : -2032.94091796875\n",
      "D loss : 238.4871368408203\n",
      "G loss : -989.1986083984375\n",
      "D loss : 1.62257719039917\n",
      "G loss : -253.44581604003906\n",
      "D loss : 54.5865592956543\n",
      "G loss : 565.6192626953125\n",
      "D loss : -46.155662536621094\n",
      "G loss : 816.5046997070312\n",
      "D loss : 66.59385681152344\n",
      "G loss : -57.33598709106445\n",
      "D loss : 56.545989990234375\n",
      "G loss : 536.6226806640625\n",
      "D loss : -50.803653717041016\n",
      "G loss : 642.5640869140625\n",
      "D loss : 11.724084854125977\n",
      "G loss : 154.13523864746094\n",
      "D loss : -92.98954772949219\n",
      "G loss : -789.7697143554688\n",
      "D loss : -159.96502685546875\n",
      "G loss : -1481.3482666015625\n",
      "D loss : 378.49456787109375\n",
      "G loss : -509.6405029296875\n",
      "D loss : -31.56346893310547\n",
      "G loss : -599.2100830078125\n",
      "D loss : -32.95866394042969\n",
      "G loss : -170.91575622558594\n",
      "D loss : 27.934663772583008\n",
      "G loss : 585.4796142578125\n",
      "D loss : -216.5620574951172\n",
      "G loss : 944.1862182617188\n",
      "D loss : -171.3152618408203\n",
      "G loss : 2232.2333984375\n",
      "D loss : -25.81198501586914\n",
      "G loss : 3366.52685546875\n",
      "D loss : 98.32171630859375\n",
      "G loss : 2137.087890625\n",
      "D loss : 397.0860595703125\n",
      "G loss : 1419.584716796875\n",
      "D loss : 298.1877136230469\n",
      "G loss : 546.144775390625\n",
      "D loss : 37.966819763183594\n",
      "G loss : 188.9139404296875\n",
      "D loss : -34.10276412963867\n",
      "G loss : -260.21630859375\n",
      "D loss : 106.25321960449219\n",
      "G loss : -284.52587890625\n",
      "D loss : 163.06472778320312\n",
      "G loss : -431.79052734375\n",
      "D loss : 44.47525405883789\n",
      "G loss : -296.3398742675781\n",
      "D loss : 42.386165618896484\n",
      "G loss : 41.12114715576172\n",
      "D loss : 102.42985534667969\n",
      "G loss : -108.51570129394531\n",
      "D loss : -14.531877517700195\n",
      "G loss : -701.454345703125\n",
      "D loss : -22.573768615722656\n",
      "G loss : -467.71368408203125\n",
      "D loss : -106.69921875\n",
      "G loss : -749.4859619140625\n",
      "D loss : -151.874267578125\n",
      "G loss : -719.3970336914062\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_3.ckpt\n",
      "D loss : -236.8277130126953\n",
      "G loss : -1441.5140380859375\n",
      "D loss : -70.06478881835938\n",
      "G loss : -1309.523681640625\n",
      "D loss : -51.721893310546875\n",
      "G loss : -906.088623046875\n",
      "D loss : 199.39590454101562\n",
      "G loss : -1099.18115234375\n",
      "D loss : 199.10606384277344\n",
      "G loss : -911.4876708984375\n",
      "D loss : 237.43017578125\n",
      "G loss : -680.510498046875\n",
      "D loss : 224.61940002441406\n",
      "G loss : -289.2307434082031\n",
      "D loss : 76.90856170654297\n",
      "G loss : 793.67333984375\n",
      "D loss : -230.36856079101562\n",
      "G loss : 1637.943359375\n",
      "D loss : -275.8381652832031\n",
      "G loss : 1358.02734375\n",
      "D loss : -239.9716339111328\n",
      "G loss : 971.051513671875\n",
      "D loss : 55.717132568359375\n",
      "G loss : 1274.8402099609375\n",
      "D loss : 138.4761962890625\n",
      "G loss : 1573.350341796875\n",
      "D loss : -144.75144958496094\n",
      "G loss : 1560.810546875\n",
      "D loss : -56.76123046875\n",
      "G loss : 1238.821533203125\n",
      "D loss : -104.81744384765625\n",
      "G loss : 1007.3043212890625\n",
      "D loss : 342.5816650390625\n",
      "G loss : 939.900146484375\n",
      "D loss : 567.1763916015625\n",
      "G loss : 715.3072509765625\n",
      "D loss : 109.39673614501953\n",
      "G loss : 416.5987548828125\n",
      "D loss : 170.6904754638672\n",
      "G loss : 29.513870239257812\n",
      "D loss : 28.671072006225586\n",
      "G loss : -50.268333435058594\n",
      "D loss : -10.6214017868042\n",
      "G loss : -199.0248260498047\n",
      "D loss : -36.294742584228516\n",
      "G loss : -491.3411865234375\n",
      "D loss : -95.73590087890625\n",
      "G loss : -711.1044311523438\n",
      "D loss : -128.60719299316406\n",
      "G loss : -1015.8867797851562\n",
      "D loss : -173.50914001464844\n",
      "G loss : -1315.9017333984375\n",
      "D loss : -106.56732177734375\n",
      "G loss : -1630.763427734375\n",
      "D loss : -13.391304016113281\n",
      "G loss : -1635.66650390625\n",
      "D loss : 15.568439483642578\n",
      "G loss : -1379.64111328125\n",
      "D loss : 105.28861999511719\n",
      "G loss : -1136.4669189453125\n",
      "D loss : 309.6825866699219\n",
      "G loss : -1127.10302734375\n",
      "D loss : 324.8282165527344\n",
      "G loss : -450.7067565917969\n",
      "D loss : 40.458553314208984\n",
      "G loss : 85.97889709472656\n",
      "D loss : -44.17863845825195\n",
      "G loss : 672.2811279296875\n",
      "D loss : -175.67681884765625\n",
      "G loss : 258.6143798828125\n",
      "D loss : -20.58550262451172\n",
      "G loss : 813.6923828125\n",
      "D loss : 4.97188138961792\n",
      "G loss : 980.7257080078125\n",
      "D loss : 54.428585052490234\n",
      "G loss : 1210.02685546875\n",
      "D loss : -34.61832046508789\n",
      "G loss : 1715.2235107421875\n",
      "D loss : 56.07883071899414\n",
      "G loss : 1455.209716796875\n",
      "D loss : 138.15756225585938\n",
      "G loss : 982.164306640625\n",
      "D loss : 11.754287719726562\n",
      "G loss : 1017.6083374023438\n",
      "D loss : 96.173828125\n",
      "G loss : 612.1574096679688\n",
      "D loss : -24.095468521118164\n",
      "G loss : 494.147705078125\n",
      "D loss : 23.618392944335938\n",
      "G loss : 356.4300537109375\n",
      "D loss : 54.952911376953125\n",
      "G loss : -38.913848876953125\n",
      "D loss : -60.19020462036133\n",
      "G loss : -363.0145263671875\n",
      "D loss : -14.142656326293945\n",
      "G loss : -819.4168090820312\n",
      "D loss : 38.23402786254883\n",
      "G loss : -655.0823974609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 23.489395141601562\n",
      "G loss : -479.2659912109375\n",
      "D loss : 71.25386810302734\n",
      "G loss : -494.19610595703125\n",
      "D loss : -17.28238296508789\n",
      "G loss : -362.96734619140625\n",
      "D loss : -100.61742401123047\n",
      "G loss : -208.57666015625\n",
      "D loss : -218.40438842773438\n",
      "G loss : -368.38665771484375\n",
      "D loss : 117.93087768554688\n",
      "G loss : -129.24819946289062\n",
      "D loss : 219.90170288085938\n",
      "G loss : 22.305076599121094\n",
      "D loss : 26.56406593322754\n",
      "G loss : -21.81778907775879\n",
      "D loss : -14.423985481262207\n",
      "G loss : 411.15313720703125\n",
      "D loss : -122.81500244140625\n",
      "G loss : 849.1851196289062\n",
      "D loss : 21.06951904296875\n",
      "G loss : 350.76043701171875\n",
      "D loss : 114.10303497314453\n",
      "G loss : -312.8582458496094\n",
      "D loss : 23.645938873291016\n",
      "G loss : -33.74789047241211\n",
      "D loss : 1.5343680381774902\n",
      "G loss : -346.5831298828125\n",
      "D loss : -29.758258819580078\n",
      "G loss : -422.9356994628906\n",
      "D loss : 20.587739944458008\n",
      "G loss : -185.53793334960938\n",
      "D loss : -26.450607299804688\n",
      "G loss : -69.36786651611328\n",
      "D loss : 141.295654296875\n",
      "G loss : 223.83131408691406\n",
      "D loss : 97.50527954101562\n",
      "G loss : 154.1546630859375\n",
      "D loss : 28.046232223510742\n",
      "G loss : 45.53694152832031\n",
      "D loss : 34.111507415771484\n",
      "G loss : 173.56820678710938\n",
      "D loss : 26.243284225463867\n",
      "G loss : 439.52587890625\n",
      "D loss : 3.125711441040039\n",
      "G loss : 331.5102844238281\n",
      "D loss : 57.61418533325195\n",
      "G loss : 190.76864624023438\n",
      "D loss : -45.78358840942383\n",
      "G loss : 253.86659240722656\n",
      "D loss : -38.84340286254883\n",
      "G loss : 379.51361083984375\n",
      "D loss : -17.05912971496582\n",
      "G loss : 421.6870422363281\n",
      "D loss : 26.686199188232422\n",
      "G loss : 110.53306579589844\n",
      "D loss : 29.706979751586914\n",
      "G loss : 26.216459274291992\n",
      "D loss : -1.5725903511047363\n",
      "G loss : -60.151546478271484\n",
      "D loss : 7.657125473022461\n",
      "G loss : -142.61376953125\n",
      "D loss : 15.653301239013672\n",
      "G loss : -193.12612915039062\n",
      "D loss : -83.80338287353516\n",
      "G loss : -475.210205078125\n",
      "D loss : 31.461355209350586\n",
      "G loss : -463.0409851074219\n",
      "D loss : -53.77085494995117\n",
      "G loss : -398.3686828613281\n",
      "D loss : 89.0792465209961\n",
      "G loss : 91.75502014160156\n",
      "D loss : -76.22115325927734\n",
      "G loss : 142.6968231201172\n",
      "D loss : 125.85273742675781\n",
      "G loss : -67.49710845947266\n",
      "D loss : -14.243884086608887\n",
      "G loss : -127.25303649902344\n",
      "D loss : -55.342987060546875\n",
      "G loss : -224.921142578125\n",
      "D loss : -27.703344345092773\n",
      "G loss : -43.77417755126953\n",
      "D loss : -42.75901794433594\n",
      "G loss : -163.76800537109375\n",
      "D loss : -53.533058166503906\n",
      "G loss : 159.7152557373047\n",
      "D loss : 0.7203185558319092\n",
      "G loss : 327.9190673828125\n",
      "D loss : 49.41552734375\n",
      "G loss : 560.0294189453125\n",
      "D loss : 3.6480867862701416\n",
      "G loss : 254.82369995117188\n",
      "D loss : -4.846007347106934\n",
      "G loss : 320.49188232421875\n",
      "D loss : -37.30744171142578\n",
      "G loss : 280.9781494140625\n",
      "D loss : -8.743631362915039\n",
      "G loss : -50.631595611572266\n",
      "D loss : -21.436458587646484\n",
      "G loss : 30.722034454345703\n",
      "D loss : -17.48530387878418\n",
      "G loss : -184.35501098632812\n",
      "D loss : -14.891009330749512\n",
      "G loss : -27.940099716186523\n",
      "D loss : -39.39920425415039\n",
      "G loss : -184.4749298095703\n",
      "D loss : -126.65126037597656\n",
      "G loss : -82.2524185180664\n",
      "D loss : -115.16455078125\n",
      "G loss : -223.38621520996094\n",
      "D loss : -82.39752960205078\n",
      "G loss : -729.6315307617188\n",
      "D loss : 404.9862060546875\n",
      "G loss : -678.4976806640625\n",
      "D loss : -4.450674057006836\n",
      "G loss : -621.6238403320312\n",
      "D loss : 59.377288818359375\n",
      "G loss : -161.46182250976562\n",
      "D loss : -122.14201354980469\n",
      "G loss : -300.02569580078125\n",
      "D loss : -202.72756958007812\n",
      "G loss : -220.84735107421875\n",
      "D loss : -337.1675720214844\n",
      "G loss : -148.98191833496094\n",
      "D loss : -257.144287109375\n",
      "G loss : -891.1639404296875\n",
      "D loss : 484.8719787597656\n",
      "G loss : -903.097412109375\n",
      "D loss : 235.4517822265625\n",
      "G loss : -254.15235900878906\n",
      "D loss : -27.25768280029297\n",
      "G loss : 441.1026916503906\n",
      "D loss : -62.94325256347656\n",
      "G loss : 1370.313232421875\n",
      "D loss : -157.92852783203125\n",
      "G loss : 2597.988525390625\n",
      "D loss : -222.1718292236328\n",
      "G loss : 3377.0380859375\n",
      "D loss : -114.93182373046875\n",
      "G loss : 3157.268310546875\n",
      "D loss : 60.97627639770508\n",
      "G loss : 2321.295166015625\n",
      "D loss : 382.35296630859375\n",
      "G loss : 1496.5860595703125\n",
      "D loss : 121.89640045166016\n",
      "G loss : 1008.555908203125\n",
      "D loss : 127.05110931396484\n",
      "G loss : 932.3126831054688\n",
      "D loss : 144.65562438964844\n",
      "G loss : 786.8489379882812\n",
      "D loss : 111.61058044433594\n",
      "G loss : 403.979736328125\n",
      "D loss : 7.7577433586120605\n",
      "G loss : 58.06398010253906\n",
      "D loss : 98.97173309326172\n",
      "G loss : 6.0070037841796875\n",
      "D loss : 70.7904281616211\n",
      "G loss : -167.2192840576172\n",
      "D loss : -2.1353628635406494\n",
      "G loss : -437.46112060546875\n",
      "D loss : -45.05693054199219\n",
      "G loss : -396.9471740722656\n",
      "D loss : 16.505895614624023\n",
      "G loss : -442.3770446777344\n",
      "D loss : 22.56008529663086\n",
      "G loss : -322.0543212890625\n",
      "D loss : -78.00275421142578\n",
      "G loss : -450.4385986328125\n",
      "D loss : -14.949355125427246\n",
      "G loss : -488.1092224121094\n",
      "D loss : 9.560667037963867\n",
      "G loss : -357.66802978515625\n",
      "D loss : -10.273107528686523\n",
      "G loss : -52.16278076171875\n",
      "D loss : -33.599971771240234\n",
      "G loss : -53.6402702331543\n",
      "D loss : 60.11019515991211\n",
      "G loss : -100.55990600585938\n",
      "D loss : -50.594459533691406\n",
      "G loss : -249.1531524658203\n",
      "D loss : 109.15189361572266\n",
      "G loss : -218.30288696289062\n",
      "D loss : 52.015933990478516\n",
      "G loss : -422.01202392578125\n",
      "D loss : 21.754533767700195\n",
      "G loss : -443.2441711425781\n",
      "D loss : 28.31417465209961\n",
      "G loss : -382.4435729980469\n",
      "D loss : -27.772342681884766\n",
      "G loss : -389.7615966796875\n",
      "D loss : -90.1441421508789\n",
      "G loss : -724.333740234375\n",
      "D loss : 52.452693939208984\n",
      "G loss : -271.209228515625\n",
      "D loss : -21.71070098876953\n",
      "G loss : -16.6695556640625\n",
      "D loss : -64.93763732910156\n",
      "G loss : 199.32937622070312\n",
      "D loss : -91.72845458984375\n",
      "G loss : 616.0948486328125\n",
      "D loss : -87.31551361083984\n",
      "G loss : 1160.01171875\n",
      "D loss : -75.56544494628906\n",
      "G loss : 1391.116943359375\n",
      "D loss : -46.63972473144531\n",
      "G loss : 878.9549560546875\n",
      "D loss : 31.37051773071289\n",
      "G loss : 1185.8828125\n",
      "D loss : 111.19646453857422\n",
      "G loss : 508.35125732421875\n",
      "D loss : 51.060462951660156\n",
      "G loss : 473.9173889160156\n",
      "D loss : -5.737085342407227\n",
      "G loss : 330.4199523925781\n",
      "D loss : 31.29844093322754\n",
      "G loss : 249.58779907226562\n",
      "D loss : -65.07971954345703\n",
      "G loss : -4.837284088134766\n",
      "D loss : 71.1744155883789\n",
      "G loss : -385.3387145996094\n",
      "D loss : -13.326836585998535\n",
      "G loss : -623.53076171875\n",
      "D loss : -68.90919494628906\n",
      "G loss : -821.447998046875\n",
      "D loss : 9.588213920593262\n",
      "G loss : -974.4349975585938\n",
      "D loss : 103.3623275756836\n",
      "G loss : -779.5615234375\n",
      "D loss : -24.39373016357422\n",
      "G loss : -729.2735595703125\n",
      "D loss : 11.249253273010254\n",
      "G loss : -922.9921264648438\n",
      "D loss : -17.28730010986328\n",
      "G loss : -1007.712646484375\n",
      "D loss : 20.11503028869629\n",
      "G loss : -856.2122192382812\n",
      "D loss : 97.089599609375\n",
      "G loss : -396.0499267578125\n",
      "D loss : 71.1496353149414\n",
      "G loss : -178.10415649414062\n",
      "D loss : -39.13066864013672\n",
      "G loss : -119.29863739013672\n",
      "D loss : 60.747615814208984\n",
      "G loss : 505.79022216796875\n",
      "D loss : -27.240921020507812\n",
      "G loss : 654.6165771484375\n",
      "D loss : -106.07268524169922\n",
      "G loss : 1215.31201171875\n",
      "D loss : -271.74951171875\n",
      "G loss : 2017.16943359375\n",
      "D loss : 107.52430725097656\n",
      "G loss : 1187.4815673828125\n",
      "D loss : 150.87490844726562\n",
      "G loss : 1083.256103515625\n",
      "D loss : -185.94248962402344\n",
      "G loss : 1184.45703125\n",
      "D loss : -60.57870101928711\n",
      "G loss : 391.15484619140625\n",
      "D loss : -3.9674386978149414\n",
      "G loss : 493.16827392578125\n",
      "D loss : 39.11235809326172\n",
      "G loss : -189.17808532714844\n",
      "D loss : 159.48387145996094\n",
      "G loss : -147.37026977539062\n",
      "D loss : 34.36741256713867\n",
      "G loss : -342.68023681640625\n",
      "D loss : -24.270456314086914\n",
      "G loss : -428.21337890625\n",
      "D loss : 94.01358032226562\n",
      "G loss : -72.22936248779297\n",
      "D loss : 111.57759094238281\n",
      "G loss : -210.67845153808594\n",
      "D loss : 33.592185974121094\n",
      "G loss : -406.89923095703125\n",
      "D loss : 26.0600643157959\n",
      "G loss : -191.14566040039062\n",
      "D loss : -38.32882308959961\n",
      "G loss : -118.0389175415039\n",
      "D loss : -89.83057403564453\n",
      "G loss : -252.802978515625\n",
      "D loss : -84.38264465332031\n",
      "G loss : -263.64312744140625\n",
      "D loss : -92.45926666259766\n",
      "G loss : -691.4699096679688\n",
      "D loss : -143.742919921875\n",
      "G loss : -558.1315307617188\n",
      "D loss : 477.6148376464844\n",
      "G loss : -463.0557861328125\n",
      "D loss : 65.07732391357422\n",
      "G loss : -461.64617919921875\n",
      "D loss : -6.995588302612305\n",
      "G loss : -8.065330505371094\n",
      "D loss : -58.25694274902344\n",
      "G loss : -8.053993225097656\n",
      "D loss : -33.95642852783203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G loss : -306.5246276855469\n",
      "D loss : -58.49181365966797\n",
      "G loss : -438.16729736328125\n",
      "D loss : 99.08499908447266\n",
      "G loss : -252.64019775390625\n",
      "D loss : -12.180224418640137\n",
      "G loss : -358.47760009765625\n",
      "D loss : 15.136798858642578\n",
      "G loss : 54.320552825927734\n",
      "D loss : 9.090530395507812\n",
      "G loss : 368.67425537109375\n",
      "D loss : -47.721771240234375\n",
      "G loss : 412.640869140625\n",
      "D loss : -31.376052856445312\n",
      "G loss : 432.97076416015625\n",
      "D loss : -20.1906681060791\n",
      "G loss : 244.81800842285156\n",
      "D loss : 14.174444198608398\n",
      "G loss : -44.66325759887695\n",
      "D loss : 3.3878657817840576\n",
      "G loss : 237.75538635253906\n",
      "D loss : -27.634817123413086\n",
      "G loss : 274.51531982421875\n",
      "D loss : 60.58340835571289\n",
      "G loss : 79.50331115722656\n",
      "D loss : 0.6524820327758789\n",
      "G loss : 105.24911499023438\n",
      "D loss : -46.57645797729492\n",
      "G loss : 140.46165466308594\n",
      "D loss : 75.72776794433594\n",
      "G loss : -119.9295883178711\n",
      "D loss : -50.335201263427734\n",
      "G loss : 68.43234252929688\n",
      "D loss : 39.54021072387695\n",
      "G loss : 168.1326904296875\n",
      "D loss : 10.73564338684082\n",
      "G loss : -201.33993530273438\n",
      "D loss : 43.037391662597656\n",
      "G loss : -48.63595199584961\n",
      "D loss : 33.125335693359375\n",
      "G loss : 25.490028381347656\n",
      "D loss : 2.1863529682159424\n",
      "G loss : 156.28439331054688\n",
      "D loss : -51.43039321899414\n",
      "G loss : 304.5006408691406\n",
      "D loss : -90.17535400390625\n",
      "G loss : 190.70144653320312\n",
      "D loss : -66.34245300292969\n",
      "G loss : -114.1854248046875\n",
      "D loss : -152.13320922851562\n",
      "G loss : -106.03888702392578\n",
      "D loss : 237.7123565673828\n",
      "G loss : -86.34515380859375\n",
      "D loss : -18.380176544189453\n",
      "G loss : -412.02081298828125\n",
      "D loss : 134.84498596191406\n",
      "G loss : -102.81796264648438\n",
      "D loss : -29.02661895751953\n",
      "G loss : -216.14358520507812\n",
      "D loss : -95.47075653076172\n",
      "G loss : -56.872703552246094\n",
      "D loss : -7.382835388183594\n",
      "G loss : -183.42269897460938\n",
      "D loss : -37.836666107177734\n",
      "G loss : -39.96806335449219\n",
      "D loss : -68.45612335205078\n",
      "G loss : -311.99151611328125\n",
      "D loss : 77.38239288330078\n",
      "G loss : 216.39071655273438\n",
      "D loss : 92.72126770019531\n",
      "G loss : 566.70068359375\n",
      "D loss : -28.839397430419922\n",
      "G loss : 803.0831298828125\n",
      "D loss : -16.05353355407715\n",
      "G loss : 841.072509765625\n",
      "D loss : -48.55182647705078\n",
      "G loss : 1177.677734375\n",
      "D loss : -151.68548583984375\n",
      "G loss : 1249.3839111328125\n",
      "D loss : 255.436279296875\n",
      "G loss : 328.31597900390625\n",
      "D loss : 116.67596435546875\n",
      "G loss : 20.086627960205078\n",
      "D loss : -40.03789138793945\n",
      "G loss : -289.9736022949219\n",
      "D loss : -99.8149642944336\n",
      "G loss : -519.5270385742188\n",
      "D loss : -83.7096176147461\n",
      "G loss : -842.662841796875\n",
      "D loss : -12.353385925292969\n",
      "G loss : -767.6800537109375\n",
      "D loss : -85.95832824707031\n",
      "G loss : -1135.593994140625\n",
      "D loss : 37.5361328125\n",
      "G loss : -1242.32958984375\n",
      "D loss : -120.4433364868164\n",
      "G loss : -1536.063720703125\n",
      "D loss : 190.06349182128906\n",
      "G loss : -1343.61962890625\n",
      "D loss : 27.152976989746094\n",
      "G loss : -984.14892578125\n",
      "D loss : 274.57281494140625\n",
      "G loss : -304.6932067871094\n",
      "D loss : 30.508180618286133\n",
      "G loss : 360.1119079589844\n",
      "D loss : -45.87836456298828\n",
      "G loss : 409.98651123046875\n",
      "D loss : -12.756736755371094\n",
      "G loss : 782.1397705078125\n",
      "D loss : 3.3018932342529297\n",
      "G loss : 1196.3555908203125\n",
      "D loss : -51.790287017822266\n",
      "G loss : 1423.093505859375\n",
      "D loss : -108.39595794677734\n",
      "G loss : 1420.478515625\n",
      "D loss : -46.7142219543457\n",
      "G loss : 1140.093994140625\n",
      "D loss : -174.8554229736328\n",
      "G loss : 425.78961181640625\n",
      "D loss : -132.5460662841797\n",
      "G loss : 397.50384521484375\n",
      "D loss : 106.67645263671875\n",
      "G loss : 738.3273315429688\n",
      "D loss : 203.2318115234375\n",
      "G loss : 1191.3897705078125\n",
      "D loss : 226.9990997314453\n",
      "G loss : 1037.7744140625\n",
      "D loss : 3.781102180480957\n",
      "G loss : 1127.314697265625\n",
      "D loss : 81.22843933105469\n",
      "G loss : 897.7835693359375\n",
      "D loss : 94.91521453857422\n",
      "G loss : 439.1766357421875\n",
      "D loss : 113.38379669189453\n",
      "G loss : 424.8867492675781\n",
      "D loss : -17.83584976196289\n",
      "G loss : 81.9781265258789\n",
      "D loss : -39.12913513183594\n",
      "G loss : -68.41377258300781\n",
      "D loss : -119.26493835449219\n",
      "G loss : -354.3212585449219\n",
      "D loss : -139.75131225585938\n",
      "G loss : -571.936279296875\n",
      "D loss : -74.64403533935547\n",
      "G loss : -896.3507690429688\n",
      "D loss : -57.112918853759766\n",
      "G loss : -573.1580810546875\n",
      "D loss : 40.01852798461914\n",
      "G loss : -684.7734375\n",
      "D loss : -74.24431610107422\n",
      "G loss : -823.2034301757812\n",
      "D loss : 102.59144592285156\n",
      "G loss : -553.4906005859375\n",
      "D loss : 180.08587646484375\n",
      "G loss : -654.1392822265625\n",
      "D loss : 92.46492767333984\n",
      "G loss : -708.6412353515625\n",
      "D loss : -39.737579345703125\n",
      "G loss : -594.3184814453125\n",
      "D loss : 101.58033752441406\n",
      "G loss : -238.09661865234375\n",
      "D loss : 26.265539169311523\n",
      "G loss : 150.04562377929688\n",
      "D loss : 32.1332893371582\n",
      "G loss : 310.439453125\n",
      "D loss : -126.92321014404297\n",
      "G loss : 780.9134521484375\n",
      "D loss : -160.63694763183594\n",
      "G loss : 1046.053955078125\n",
      "D loss : -237.75527954101562\n",
      "G loss : 1371.020263671875\n",
      "D loss : 14.454455375671387\n",
      "G loss : 719.3150634765625\n",
      "D loss : 32.14125442504883\n",
      "G loss : 321.611328125\n",
      "D loss : -45.842529296875\n",
      "G loss : 363.78155517578125\n",
      "D loss : -56.21611785888672\n",
      "G loss : 617.4708251953125\n",
      "D loss : -15.372221946716309\n",
      "G loss : 656.2239990234375\n",
      "D loss : 75.49452209472656\n",
      "G loss : 320.797119140625\n",
      "D loss : -58.731292724609375\n",
      "G loss : 7.492118835449219\n",
      "D loss : -114.72478485107422\n",
      "G loss : -328.8525695800781\n",
      "D loss : -72.53326416015625\n",
      "G loss : -738.1190795898438\n",
      "D loss : -88.19896697998047\n",
      "G loss : -1408.950439453125\n",
      "D loss : 84.88265228271484\n",
      "G loss : -1044.87646484375\n",
      "D loss : 3.976956367492676\n",
      "G loss : -1161.433837890625\n",
      "D loss : -77.58196258544922\n",
      "G loss : -1120.551513671875\n",
      "D loss : 213.811767578125\n",
      "G loss : -772.6925659179688\n",
      "D loss : 52.01560592651367\n",
      "G loss : -583.5750732421875\n",
      "D loss : -24.628549575805664\n",
      "G loss : -83.5220947265625\n",
      "D loss : -109.65229034423828\n",
      "G loss : 231.6300048828125\n",
      "D loss : -8.411994934082031\n",
      "G loss : 225.9144287109375\n",
      "D loss : 31.643280029296875\n",
      "G loss : 898.1895751953125\n",
      "D loss : -185.5294952392578\n",
      "G loss : 1419.541259765625\n",
      "D loss : -256.2926330566406\n",
      "G loss : 2150.205078125\n",
      "D loss : -380.5135192871094\n",
      "G loss : 2313.374755859375\n",
      "D loss : 237.65304565429688\n",
      "G loss : 2018.953369140625\n",
      "D loss : 173.1991424560547\n",
      "G loss : 1269.8145751953125\n",
      "D loss : 109.950439453125\n",
      "G loss : 1017.4779052734375\n",
      "D loss : 53.43569564819336\n",
      "G loss : 806.4220581054688\n",
      "D loss : 55.13257598876953\n",
      "G loss : 660.1689453125\n",
      "D loss : 37.92053985595703\n",
      "G loss : 19.06871795654297\n",
      "D loss : -48.68988800048828\n",
      "G loss : -271.1556396484375\n",
      "D loss : -259.9808349609375\n",
      "G loss : -154.07826232910156\n",
      "D loss : -420.0293273925781\n",
      "G loss : -136.23440551757812\n",
      "D loss : 180.25782775878906\n",
      "G loss : -734.494384765625\n",
      "D loss : 82.82588195800781\n",
      "G loss : -1732.0419921875\n",
      "D loss : 255.66607666015625\n",
      "G loss : -1945.7559814453125\n",
      "D loss : 269.8692321777344\n",
      "G loss : -1780.4072265625\n",
      "D loss : 108.1710205078125\n",
      "G loss : -1424.899658203125\n",
      "D loss : 230.8903045654297\n",
      "G loss : -845.0966186523438\n",
      "D loss : 223.89451599121094\n",
      "G loss : -404.05657958984375\n",
      "D loss : 165.5416259765625\n",
      "G loss : 122.70414733886719\n",
      "D loss : -62.07215118408203\n",
      "G loss : 114.49769592285156\n",
      "1\n",
      "D loss : -49.367923736572266\n",
      "G loss : 710.0979614257812\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_4.ckpt\n",
      "D loss : -73.79059600830078\n",
      "G loss : 1286.214111328125\n",
      "D loss : -207.7722930908203\n",
      "G loss : 1655.0408935546875\n",
      "D loss : -115.85704803466797\n",
      "G loss : 1611.778564453125\n",
      "D loss : -165.7972412109375\n",
      "G loss : 2083.23291015625\n",
      "D loss : -81.3958740234375\n",
      "G loss : 1863.5595703125\n",
      "D loss : 66.83375549316406\n",
      "G loss : 1658.3511962890625\n",
      "D loss : -0.4995088577270508\n",
      "G loss : 842.4844970703125\n",
      "D loss : -13.475271224975586\n",
      "G loss : 356.71527099609375\n",
      "D loss : -72.51201629638672\n",
      "G loss : 652.0283813476562\n",
      "D loss : 180.07528686523438\n",
      "G loss : -103.13868713378906\n",
      "D loss : -68.6260986328125\n",
      "G loss : -409.9677734375\n",
      "D loss : 84.30223083496094\n",
      "G loss : -613.9495239257812\n",
      "D loss : 69.00617218017578\n",
      "G loss : -1061.9088134765625\n",
      "D loss : 102.99861907958984\n",
      "G loss : -976.7972412109375\n",
      "D loss : 110.92646789550781\n",
      "G loss : -478.29925537109375\n",
      "D loss : 14.996521949768066\n",
      "G loss : -86.54470825195312\n",
      "D loss : -157.24285888671875\n",
      "G loss : 163.3348846435547\n",
      "D loss : -314.1778259277344\n",
      "G loss : 383.82110595703125\n",
      "D loss : -432.2184143066406\n",
      "G loss : 267.79107666015625\n",
      "D loss : 118.60757446289062\n",
      "G loss : -87.39352416992188\n",
      "D loss : -55.96705627441406\n",
      "G loss : -285.25341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 443.5887756347656\n",
      "G loss : -293.41241455078125\n",
      "D loss : 216.37606811523438\n",
      "G loss : -307.1407165527344\n",
      "D loss : 110.93456268310547\n",
      "G loss : 128.66775512695312\n",
      "D loss : 75.77783966064453\n",
      "G loss : 599.7073974609375\n",
      "D loss : -180.08621215820312\n",
      "G loss : 523.846923828125\n",
      "D loss : 43.81740951538086\n",
      "G loss : 384.1339111328125\n",
      "D loss : -10.91007137298584\n",
      "G loss : 363.7020263671875\n",
      "D loss : -31.164562225341797\n",
      "G loss : 324.855712890625\n",
      "D loss : 50.315574645996094\n",
      "G loss : 385.35247802734375\n",
      "D loss : -53.37329864501953\n",
      "G loss : 444.3819885253906\n",
      "D loss : 0.8960285186767578\n",
      "G loss : 285.5924072265625\n",
      "D loss : -49.49024200439453\n",
      "G loss : -52.84734344482422\n",
      "D loss : 41.63560485839844\n",
      "G loss : -414.2066955566406\n",
      "D loss : -109.44930267333984\n",
      "G loss : -414.84228515625\n",
      "D loss : 98.73737335205078\n",
      "G loss : -559.2598876953125\n",
      "D loss : 12.545747756958008\n",
      "G loss : -419.8695068359375\n",
      "D loss : 55.65914535522461\n",
      "G loss : -578.877197265625\n",
      "D loss : -4.583178520202637\n",
      "G loss : -357.5894470214844\n",
      "D loss : -73.22298431396484\n",
      "G loss : -526.968017578125\n",
      "D loss : 35.6676139831543\n",
      "G loss : -347.60003662109375\n",
      "D loss : 27.186288833618164\n",
      "G loss : -252.2552032470703\n",
      "D loss : 19.711381912231445\n",
      "G loss : -294.1540832519531\n",
      "D loss : 14.72433090209961\n",
      "G loss : -40.12510681152344\n",
      "D loss : -32.9553108215332\n",
      "G loss : 66.3641586303711\n",
      "D loss : -48.66251754760742\n",
      "G loss : 123.2977294921875\n",
      "D loss : 49.593055725097656\n",
      "G loss : 36.49510192871094\n",
      "D loss : 27.894773483276367\n",
      "G loss : -18.65514373779297\n",
      "D loss : 83.19384002685547\n",
      "G loss : -36.419647216796875\n",
      "D loss : 77.419677734375\n",
      "G loss : -290.0337219238281\n",
      "D loss : 56.06258010864258\n",
      "G loss : -594.062744140625\n",
      "D loss : 70.60057067871094\n",
      "G loss : -521.68017578125\n",
      "D loss : 7.675492763519287\n",
      "G loss : -640.756103515625\n",
      "D loss : 10.151998519897461\n",
      "G loss : -769.3140869140625\n",
      "D loss : -52.73625564575195\n",
      "G loss : -898.329833984375\n",
      "D loss : 62.583072662353516\n",
      "G loss : -770.93603515625\n",
      "D loss : 36.48588180541992\n",
      "G loss : -600.666259765625\n",
      "D loss : 82.31034851074219\n",
      "G loss : -240.44888305664062\n",
      "D loss : 3.724743366241455\n",
      "G loss : -87.27729797363281\n",
      "D loss : -61.2513427734375\n",
      "G loss : 272.34552001953125\n",
      "D loss : -13.965341567993164\n",
      "G loss : 833.2679443359375\n",
      "D loss : -168.28167724609375\n",
      "G loss : 986.8164672851562\n",
      "D loss : -178.6957244873047\n",
      "G loss : 1228.001953125\n",
      "D loss : 463.32763671875\n",
      "G loss : 1262.9140625\n",
      "D loss : -49.38713073730469\n",
      "G loss : 1290.64453125\n",
      "D loss : 25.060604095458984\n",
      "G loss : 1195.91796875\n",
      "D loss : -25.45551300048828\n",
      "G loss : 1261.0618896484375\n",
      "D loss : 36.513423919677734\n",
      "G loss : 922.6766357421875\n",
      "D loss : 29.194549560546875\n",
      "G loss : 1019.6412353515625\n",
      "D loss : 21.352746963500977\n",
      "G loss : 588.8045654296875\n",
      "D loss : -81.91786193847656\n",
      "G loss : 281.9953918457031\n",
      "D loss : 71.57048034667969\n",
      "G loss : -97.12538146972656\n",
      "D loss : -14.257810592651367\n",
      "G loss : -335.13299560546875\n",
      "D loss : -97.10285949707031\n",
      "G loss : -769.8463134765625\n",
      "D loss : -89.2754135131836\n",
      "G loss : -1023.6087646484375\n",
      "D loss : -62.015926361083984\n",
      "G loss : -1504.533935546875\n",
      "D loss : 45.13379669189453\n",
      "G loss : -1469.23681640625\n",
      "D loss : 30.70110511779785\n",
      "G loss : -1171.4893798828125\n",
      "D loss : 92.77281188964844\n",
      "G loss : -1045.9501953125\n",
      "D loss : 10.026878356933594\n",
      "G loss : -575.9263916015625\n",
      "D loss : 42.37827682495117\n",
      "G loss : -254.48526000976562\n",
      "D loss : 24.04769515991211\n",
      "G loss : 635.4505615234375\n",
      "D loss : -2.210378646850586\n",
      "G loss : 1571.7178955078125\n",
      "D loss : -315.94183349609375\n",
      "G loss : 2693.2705078125\n",
      "D loss : -381.9927062988281\n",
      "G loss : 3070.70166015625\n",
      "D loss : -206.68707275390625\n",
      "G loss : 3261.08984375\n",
      "D loss : 729.2849731445312\n",
      "G loss : 1901.621337890625\n",
      "D loss : 251.50633239746094\n",
      "G loss : 1570.400634765625\n",
      "D loss : 202.88626098632812\n",
      "G loss : 1004.3873291015625\n",
      "D loss : 134.21807861328125\n",
      "G loss : 816.058349609375\n",
      "D loss : 10.015714645385742\n",
      "G loss : 594.6436767578125\n",
      "D loss : 59.70213317871094\n",
      "G loss : 511.34625244140625\n",
      "D loss : -11.234607696533203\n",
      "G loss : 199.3377685546875\n",
      "D loss : 178.96214294433594\n",
      "G loss : -78.56851196289062\n",
      "D loss : -76.71532440185547\n",
      "G loss : -255.11727905273438\n",
      "D loss : 33.806854248046875\n",
      "G loss : -428.5274963378906\n",
      "D loss : -3.806204319000244\n",
      "G loss : -523.9952392578125\n",
      "D loss : -96.44497680664062\n",
      "G loss : -1008.0925903320312\n",
      "D loss : -67.77088928222656\n",
      "G loss : -922.2130126953125\n",
      "D loss : -174.54074096679688\n",
      "G loss : -1019.7830810546875\n",
      "D loss : -222.7965850830078\n",
      "G loss : -1641.63818359375\n",
      "D loss : -338.19775390625\n",
      "G loss : -1346.6571044921875\n",
      "D loss : -175.55152893066406\n",
      "G loss : -1051.3642578125\n",
      "D loss : 109.74555206298828\n",
      "G loss : -657.4953002929688\n",
      "D loss : 313.55560302734375\n",
      "G loss : -730.1952514648438\n",
      "D loss : 165.4697265625\n",
      "G loss : -1057.9893798828125\n",
      "D loss : 152.28700256347656\n",
      "G loss : -869.70458984375\n",
      "D loss : 186.73330688476562\n",
      "G loss : -646.7847290039062\n",
      "D loss : 146.8021240234375\n",
      "G loss : -239.16635131835938\n",
      "D loss : 23.740886688232422\n",
      "G loss : -193.12741088867188\n",
      "D loss : 0.4549539089202881\n",
      "G loss : 275.2972412109375\n",
      "D loss : 65.16626739501953\n",
      "G loss : 555.0379028320312\n",
      "D loss : -84.93824005126953\n",
      "G loss : 1106.24560546875\n",
      "D loss : -62.788414001464844\n",
      "G loss : 1209.74951171875\n",
      "D loss : -118.70211791992188\n",
      "G loss : 1612.35009765625\n",
      "D loss : -34.971797943115234\n",
      "G loss : 1876.383056640625\n",
      "D loss : 143.62294006347656\n",
      "G loss : 1499.920166015625\n",
      "D loss : 10.178096771240234\n",
      "G loss : 1416.883056640625\n",
      "D loss : 120.8753662109375\n",
      "G loss : 1527.010009765625\n",
      "D loss : 75.5703125\n",
      "G loss : 993.7476806640625\n",
      "D loss : 125.64456176757812\n",
      "G loss : 462.93328857421875\n",
      "D loss : 9.68770980834961\n",
      "G loss : 359.2562255859375\n",
      "D loss : 139.1704864501953\n",
      "G loss : 204.30734252929688\n",
      "D loss : 64.79218292236328\n",
      "G loss : -16.1173095703125\n",
      "D loss : 39.94962692260742\n",
      "G loss : 117.84441375732422\n",
      "D loss : 17.485994338989258\n",
      "G loss : 138.1097412109375\n",
      "D loss : -54.98066329956055\n",
      "G loss : 90.83453369140625\n",
      "D loss : 39.68033981323242\n",
      "G loss : -215.59738159179688\n",
      "D loss : -99.69806671142578\n",
      "G loss : -125.55697631835938\n",
      "D loss : 22.56330108642578\n",
      "G loss : -393.364013671875\n",
      "D loss : -46.92070388793945\n",
      "G loss : -442.0461730957031\n",
      "D loss : -124.93574523925781\n",
      "G loss : -529.7584228515625\n",
      "D loss : 205.00030517578125\n",
      "G loss : -370.00238037109375\n",
      "D loss : 1.7548332214355469\n",
      "G loss : -346.3093566894531\n",
      "D loss : 157.40176391601562\n",
      "G loss : -306.71246337890625\n",
      "D loss : 21.92636489868164\n",
      "G loss : -201.01797485351562\n",
      "D loss : -111.76258850097656\n",
      "G loss : -200.70693969726562\n",
      "D loss : -180.68873596191406\n",
      "G loss : -415.4454345703125\n",
      "D loss : -150.38023376464844\n",
      "G loss : -233.25575256347656\n",
      "D loss : -46.30267333984375\n",
      "G loss : -173.58851623535156\n",
      "D loss : -140.26441955566406\n",
      "G loss : -667.2431640625\n",
      "D loss : -188.03057861328125\n",
      "G loss : -874.568115234375\n",
      "D loss : 608.2290649414062\n",
      "G loss : -544.7724609375\n",
      "D loss : 31.996028900146484\n",
      "G loss : -1145.2025146484375\n",
      "D loss : 571.6372680664062\n",
      "G loss : -210.06918334960938\n",
      "D loss : 108.98517608642578\n",
      "G loss : 311.67584228515625\n",
      "D loss : -211.4190216064453\n",
      "G loss : 1488.341064453125\n",
      "D loss : -278.48583984375\n",
      "G loss : 1629.0146484375\n",
      "D loss : -316.7428283691406\n",
      "G loss : 1795.192626953125\n",
      "D loss : -200.70236206054688\n",
      "G loss : 1173.7989501953125\n",
      "D loss : -202.84300231933594\n",
      "G loss : 446.827392578125\n",
      "D loss : 766.9251098632812\n",
      "G loss : 413.416748046875\n",
      "D loss : 189.84324645996094\n",
      "G loss : 438.2548828125\n",
      "D loss : 22.490917205810547\n",
      "G loss : 1015.6064453125\n",
      "D loss : 130.40472412109375\n",
      "G loss : 758.068603515625\n",
      "D loss : 53.863014221191406\n",
      "G loss : 853.7994384765625\n",
      "D loss : 92.3041763305664\n",
      "G loss : 740.5091552734375\n",
      "D loss : 4.138618469238281\n",
      "G loss : 497.42108154296875\n",
      "D loss : 35.6222038269043\n",
      "G loss : 627.1331787109375\n",
      "D loss : -78.96676635742188\n",
      "G loss : 549.8865966796875\n",
      "D loss : -52.66007995605469\n",
      "G loss : 207.33216857910156\n",
      "D loss : -107.14080047607422\n",
      "G loss : -56.69286346435547\n",
      "D loss : -154.34312438964844\n",
      "G loss : 73.87784576416016\n",
      "D loss : -123.56063842773438\n",
      "G loss : 158.03968811035156\n",
      "D loss : -13.969459533691406\n",
      "G loss : -207.64437866210938\n",
      "D loss : -122.82310485839844\n",
      "G loss : -685.47900390625\n",
      "D loss : 385.1993103027344\n",
      "G loss : -611.2330932617188\n",
      "D loss : 283.06396484375\n",
      "G loss : -495.3811950683594\n",
      "D loss : -36.47412109375\n",
      "G loss : -726.417724609375\n",
      "D loss : 136.32765197753906\n",
      "G loss : -569.92333984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 152.57882690429688\n",
      "G loss : -395.513916015625\n",
      "D loss : -73.7405776977539\n",
      "G loss : -350.36737060546875\n",
      "D loss : -51.4942626953125\n",
      "G loss : -104.93568420410156\n",
      "D loss : -72.96778106689453\n",
      "G loss : 377.9690246582031\n",
      "D loss : -151.28965759277344\n",
      "G loss : 999.4344482421875\n",
      "D loss : -140.43594360351562\n",
      "G loss : 1071.087646484375\n",
      "D loss : 14.013179779052734\n",
      "G loss : 896.3294677734375\n",
      "D loss : -87.58321380615234\n",
      "G loss : 1479.0390625\n",
      "D loss : -84.97732543945312\n",
      "G loss : 1795.454345703125\n",
      "D loss : 416.9697570800781\n",
      "G loss : 1893.47802734375\n",
      "D loss : 163.75347900390625\n",
      "G loss : 1019.5478515625\n",
      "D loss : 76.15843963623047\n",
      "G loss : 816.0250244140625\n",
      "D loss : 143.5101776123047\n",
      "G loss : 585.3547973632812\n",
      "D loss : 177.65216064453125\n",
      "G loss : 144.07339477539062\n",
      "D loss : -20.84029769897461\n",
      "G loss : -58.10337448120117\n",
      "D loss : -52.90009689331055\n",
      "G loss : -529.5777587890625\n",
      "D loss : -156.8547821044922\n",
      "G loss : -979.1640625\n",
      "D loss : 20.567359924316406\n",
      "G loss : -1247.616943359375\n",
      "D loss : 20.717239379882812\n",
      "G loss : -1234.3564453125\n",
      "D loss : 252.9348602294922\n",
      "G loss : -907.1450805664062\n",
      "D loss : -1.1729583740234375\n",
      "G loss : -806.0358276367188\n",
      "D loss : -33.77881622314453\n",
      "G loss : -582.7400512695312\n",
      "D loss : -133.46437072753906\n",
      "G loss : -477.65460205078125\n",
      "D loss : -30.407054901123047\n",
      "G loss : -218.46591186523438\n",
      "D loss : -95.65471649169922\n",
      "G loss : -88.1795425415039\n",
      "D loss : -170.69847106933594\n",
      "G loss : 111.50386047363281\n",
      "D loss : -247.40147399902344\n",
      "G loss : -263.28759765625\n",
      "D loss : 505.94158935546875\n",
      "G loss : -682.48291015625\n",
      "D loss : 344.2465515136719\n",
      "G loss : -801.828369140625\n",
      "D loss : 280.0217590332031\n",
      "G loss : -477.69189453125\n",
      "D loss : 205.5631561279297\n",
      "G loss : -338.26202392578125\n",
      "D loss : 72.85807800292969\n",
      "G loss : -65.46354675292969\n",
      "D loss : -15.570782661437988\n",
      "G loss : 289.8798828125\n",
      "D loss : -52.345970153808594\n",
      "G loss : 434.6028137207031\n",
      "D loss : -23.43617820739746\n",
      "G loss : 789.6795654296875\n",
      "D loss : -31.47750473022461\n",
      "G loss : 599.17138671875\n",
      "D loss : 33.84720230102539\n",
      "G loss : 990.2678833007812\n",
      "D loss : -25.77281951904297\n",
      "G loss : 636.8567504882812\n",
      "D loss : 53.38621520996094\n",
      "G loss : 445.9235534667969\n",
      "D loss : -14.089520454406738\n",
      "G loss : 486.93853759765625\n",
      "D loss : 52.83350372314453\n",
      "G loss : 508.0850524902344\n",
      "D loss : 17.227134704589844\n",
      "G loss : 335.7235412597656\n",
      "D loss : 81.04053497314453\n",
      "G loss : 95.88555908203125\n",
      "D loss : 26.694774627685547\n",
      "G loss : 153.49696350097656\n",
      "D loss : -45.4909553527832\n",
      "G loss : -23.132213592529297\n",
      "D loss : -42.47428512573242\n",
      "G loss : -82.54156494140625\n",
      "D loss : -133.56578063964844\n",
      "G loss : -176.22891235351562\n",
      "D loss : 7.769390106201172\n",
      "G loss : -766.708740234375\n",
      "D loss : 10.97906494140625\n",
      "G loss : -392.5995788574219\n",
      "D loss : -55.82594680786133\n",
      "G loss : -668.2015380859375\n",
      "D loss : 253.24835205078125\n",
      "G loss : -639.040771484375\n",
      "D loss : 138.9757843017578\n",
      "G loss : -377.1680908203125\n",
      "D loss : -25.359771728515625\n",
      "G loss : -288.8082275390625\n",
      "D loss : 49.99516296386719\n",
      "G loss : -91.41107177734375\n",
      "D loss : -1.2875959873199463\n",
      "G loss : 46.68416213989258\n",
      "D loss : -33.49003219604492\n",
      "G loss : 8.4195556640625\n",
      "D loss : -22.02342987060547\n",
      "G loss : 407.350341796875\n",
      "D loss : -46.510372161865234\n",
      "G loss : 607.587890625\n",
      "D loss : -17.883766174316406\n",
      "G loss : 486.33447265625\n",
      "D loss : -17.332719802856445\n",
      "G loss : 512.1063232421875\n",
      "D loss : -5.108316898345947\n",
      "G loss : 305.9829406738281\n",
      "D loss : 149.4226531982422\n",
      "G loss : 350.9716796875\n",
      "D loss : 59.3351936340332\n",
      "G loss : 858.196533203125\n",
      "D loss : 23.814064025878906\n",
      "G loss : 875.9359741210938\n",
      "D loss : 46.4732666015625\n",
      "G loss : 589.9949951171875\n",
      "D loss : 3.716909885406494\n",
      "G loss : 278.9769287109375\n",
      "D loss : -20.455894470214844\n",
      "G loss : -44.80691909790039\n",
      "D loss : 74.52430725097656\n",
      "G loss : -185.15829467773438\n",
      "D loss : -46.33879089355469\n",
      "G loss : -402.4833068847656\n",
      "D loss : 20.457164764404297\n",
      "G loss : -531.5560302734375\n",
      "D loss : -20.539125442504883\n",
      "G loss : -589.5975341796875\n",
      "D loss : -65.63040924072266\n",
      "G loss : -926.8173828125\n",
      "D loss : 46.391380310058594\n",
      "G loss : -669.3302001953125\n",
      "D loss : 73.19397735595703\n",
      "G loss : -596.5517578125\n",
      "D loss : 123.58084106445312\n",
      "G loss : -240.94076538085938\n",
      "D loss : 20.78392791748047\n",
      "G loss : -24.70852279663086\n",
      "D loss : 0.357541561126709\n",
      "G loss : 472.5032958984375\n",
      "D loss : -38.21548080444336\n",
      "G loss : 954.275146484375\n",
      "D loss : -25.453338623046875\n",
      "G loss : 722.9606323242188\n",
      "D loss : -96.17566680908203\n",
      "G loss : 1065.148193359375\n",
      "D loss : 30.185680389404297\n",
      "G loss : 816.8712158203125\n",
      "D loss : 205.76902770996094\n",
      "G loss : 513.0882568359375\n",
      "D loss : 7.519804000854492\n",
      "G loss : 545.9688720703125\n",
      "D loss : -2.8152928352355957\n",
      "G loss : 418.2056884765625\n",
      "D loss : -27.192527770996094\n",
      "G loss : 440.6001281738281\n",
      "D loss : 51.016258239746094\n",
      "G loss : 182.3882598876953\n",
      "D loss : 56.751625061035156\n",
      "G loss : 194.76077270507812\n",
      "D loss : 20.419845581054688\n",
      "G loss : 0.7404499053955078\n",
      "D loss : 52.42192840576172\n",
      "G loss : -132.901611328125\n",
      "D loss : 24.399627685546875\n",
      "G loss : -207.12884521484375\n",
      "D loss : 5.967227458953857\n",
      "G loss : -194.61419677734375\n",
      "D loss : -8.024168014526367\n",
      "G loss : -229.64471435546875\n",
      "D loss : -16.518281936645508\n",
      "G loss : -52.1131591796875\n",
      "D loss : 40.684146881103516\n",
      "G loss : -142.5465850830078\n",
      "D loss : 19.767719268798828\n",
      "G loss : -214.0478973388672\n",
      "D loss : -19.404985427856445\n",
      "G loss : -53.047603607177734\n",
      "D loss : -75.07421112060547\n",
      "G loss : 2.9665870666503906\n",
      "D loss : -112.20039367675781\n",
      "G loss : 131.6429443359375\n",
      "D loss : 221.59765625\n",
      "G loss : -100.87726593017578\n",
      "D loss : 47.37201690673828\n",
      "G loss : -215.0374755859375\n",
      "D loss : 67.65968322753906\n",
      "G loss : -166.0233917236328\n",
      "D loss : 66.0938720703125\n",
      "G loss : 144.9075927734375\n",
      "D loss : 15.626758575439453\n",
      "G loss : 11.964810371398926\n",
      "D loss : 42.755069732666016\n",
      "G loss : 89.85116577148438\n",
      "D loss : -18.446521759033203\n",
      "G loss : 285.9015197753906\n",
      "D loss : -7.504060745239258\n",
      "G loss : 196.45950317382812\n",
      "D loss : -5.9932427406311035\n",
      "G loss : 78.99388122558594\n",
      "D loss : 29.830089569091797\n",
      "G loss : 102.26399230957031\n",
      "D loss : -21.543798446655273\n",
      "G loss : 90.33380889892578\n",
      "D loss : 82.61235046386719\n",
      "G loss : 81.83174133300781\n",
      "D loss : 93.50157928466797\n",
      "G loss : 44.17304229736328\n",
      "D loss : -0.6753621101379395\n",
      "G loss : -12.530312538146973\n",
      "D loss : 3.087090015411377\n",
      "G loss : 45.84862518310547\n",
      "D loss : 5.5195512771606445\n",
      "G loss : 42.11697769165039\n",
      "D loss : 15.527581214904785\n",
      "G loss : 28.804458618164062\n",
      "D loss : -14.467753410339355\n",
      "G loss : 50.00627136230469\n",
      "D loss : 14.677653312683105\n",
      "G loss : 41.821693420410156\n",
      "D loss : 25.015716552734375\n",
      "G loss : 8.277685165405273\n",
      "D loss : 13.827315330505371\n",
      "G loss : -16.062427520751953\n",
      "D loss : 8.864749908447266\n",
      "G loss : -32.903194427490234\n",
      "D loss : -21.898677825927734\n",
      "G loss : -77.10511779785156\n",
      "D loss : -12.294364929199219\n",
      "G loss : -51.40990447998047\n",
      "D loss : -18.94048309326172\n",
      "G loss : -92.60360717773438\n",
      "D loss : -36.4801025390625\n",
      "G loss : -77.9652099609375\n",
      "D loss : 12.746355056762695\n",
      "G loss : -70.83306884765625\n",
      "D loss : 10.883796691894531\n",
      "G loss : -103.28053283691406\n",
      "D loss : 45.15937042236328\n",
      "G loss : 2.524294376373291\n",
      "D loss : 10.890790939331055\n",
      "G loss : 61.53227996826172\n",
      "D loss : 2.65700626373291\n",
      "G loss : 97.94593811035156\n",
      "D loss : -18.4939022064209\n",
      "G loss : 215.39804077148438\n",
      "D loss : 13.663905143737793\n",
      "G loss : 135.31277465820312\n",
      "D loss : 23.093544006347656\n",
      "G loss : 68.86593627929688\n",
      "D loss : -1.7273683547973633\n",
      "G loss : 101.79102325439453\n",
      "D loss : -4.451277732849121\n",
      "G loss : 101.53617858886719\n",
      "D loss : 24.275156021118164\n",
      "G loss : 73.27275848388672\n",
      "D loss : 31.916152954101562\n",
      "G loss : 49.173240661621094\n",
      "D loss : 4.31755256652832\n",
      "G loss : 24.202516555786133\n",
      "D loss : 3.2394495010375977\n",
      "G loss : -4.179929733276367\n",
      "D loss : 27.976409912109375\n",
      "G loss : 39.962738037109375\n",
      "D loss : -13.26443099975586\n",
      "G loss : 77.00225830078125\n",
      "D loss : -51.58186340332031\n",
      "G loss : 93.59640502929688\n",
      "D loss : -13.225740432739258\n",
      "G loss : 88.97113037109375\n",
      "D loss : 42.91233825683594\n",
      "G loss : 26.538118362426758\n",
      "D loss : -22.81908416748047\n",
      "G loss : 36.816932678222656\n",
      "D loss : 7.1854658126831055\n",
      "G loss : 10.15102767944336\n",
      "D loss : 11.216195106506348\n",
      "G loss : -1.0902652740478516\n",
      "D loss : -21.54939842224121\n",
      "G loss : -0.4804201126098633\n",
      "D loss : 10.657466888427734\n",
      "G loss : 39.832923889160156\n",
      "D loss : -1.4384713172912598\n",
      "G loss : 162.28195190429688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : -25.65573501586914\n",
      "G loss : 228.22854614257812\n",
      "D loss : 62.27302932739258\n",
      "G loss : 73.81433868408203\n",
      "D loss : -11.034273147583008\n",
      "G loss : 147.24301147460938\n",
      "D loss : 7.589195251464844\n",
      "G loss : 85.94090270996094\n",
      "D loss : 27.155792236328125\n",
      "G loss : 161.67630004882812\n",
      "D loss : -10.628179550170898\n",
      "G loss : 279.33026123046875\n",
      "D loss : 89.21392822265625\n",
      "G loss : 50.930084228515625\n",
      "D loss : -7.129543304443359\n",
      "G loss : 69.41812896728516\n",
      "D loss : 9.455245971679688\n",
      "G loss : 59.040184020996094\n",
      "D loss : 26.72577476501465\n",
      "G loss : 23.795209884643555\n",
      "D loss : 9.518930435180664\n",
      "G loss : -1.5817012786865234\n",
      "D loss : -1.4414129257202148\n",
      "G loss : -54.224674224853516\n",
      "D loss : -4.148924827575684\n",
      "G loss : -34.9024658203125\n",
      "D loss : 30.390316009521484\n",
      "G loss : -29.68534278869629\n",
      "D loss : 40.58810806274414\n",
      "G loss : -29.57298469543457\n",
      "D loss : 4.188712120056152\n",
      "G loss : -5.661376953125\n",
      "D loss : 11.33247184753418\n",
      "G loss : -35.90355682373047\n",
      "D loss : -9.58635139465332\n",
      "G loss : 105.86859893798828\n",
      "D loss : -13.458498001098633\n",
      "G loss : 80.12525177001953\n",
      "D loss : -25.281558990478516\n",
      "G loss : 117.1353759765625\n",
      "D loss : 0.332791805267334\n",
      "G loss : 32.69725036621094\n",
      "D loss : 15.400788307189941\n",
      "G loss : -19.416460037231445\n",
      "D loss : 4.825801849365234\n",
      "G loss : -145.0084228515625\n",
      "D loss : 3.208143711090088\n",
      "G loss : -197.24151611328125\n",
      "D loss : -3.9344024658203125\n",
      "G loss : -215.47518920898438\n",
      "D loss : 1.2553825378417969\n",
      "G loss : -252.4052734375\n",
      "D loss : 30.25442123413086\n",
      "G loss : -265.837646484375\n",
      "D loss : -8.74944019317627\n",
      "G loss : -251.15988159179688\n",
      "D loss : 100.65055084228516\n",
      "G loss : -78.21574401855469\n",
      "D loss : 16.576902389526367\n",
      "G loss : -47.072410583496094\n",
      "D loss : -0.25832653045654297\n",
      "G loss : -22.607059478759766\n",
      "D loss : 11.948545455932617\n",
      "G loss : 18.497190475463867\n",
      "D loss : -1.7965350151062012\n",
      "G loss : 63.930755615234375\n",
      "D loss : 5.870885848999023\n",
      "G loss : 107.9556884765625\n",
      "D loss : -3.3163599967956543\n",
      "G loss : 157.8512725830078\n",
      "D loss : -1.734375\n",
      "G loss : 161.99227905273438\n",
      "D loss : 17.80474853515625\n",
      "G loss : 190.5201416015625\n",
      "D loss : 0.7682113647460938\n",
      "G loss : 243.18560791015625\n",
      "D loss : -38.305137634277344\n",
      "G loss : 376.0010986328125\n",
      "D loss : 96.82666015625\n",
      "G loss : 141.09811401367188\n",
      "D loss : 30.91179847717285\n",
      "G loss : 68.04843139648438\n",
      "D loss : 21.904569625854492\n",
      "G loss : 47.6339225769043\n",
      "D loss : 7.707597255706787\n",
      "G loss : 12.46827507019043\n",
      "D loss : 2.7145252227783203\n",
      "G loss : 5.260821342468262\n",
      "D loss : 1.6262903213500977\n",
      "G loss : -11.347554206848145\n",
      "D loss : -4.629702568054199\n",
      "G loss : -31.188610076904297\n",
      "D loss : -9.8368501663208\n",
      "G loss : -79.67454528808594\n",
      "D loss : -8.092287063598633\n",
      "G loss : -120.94029998779297\n",
      "D loss : -13.930395126342773\n",
      "G loss : -140.98731994628906\n",
      "D loss : 28.77914810180664\n",
      "G loss : -125.36227416992188\n",
      "D loss : 8.950750350952148\n",
      "G loss : -128.95297241210938\n",
      "D loss : 26.1184139251709\n",
      "G loss : -131.71658325195312\n",
      "D loss : -1.921483039855957\n",
      "G loss : -142.4374237060547\n",
      "D loss : -3.2582244873046875\n",
      "G loss : -152.47537231445312\n",
      "D loss : -7.058480262756348\n",
      "G loss : -221.24700927734375\n",
      "D loss : -6.230374336242676\n",
      "G loss : -216.36520385742188\n",
      "D loss : 42.3754997253418\n",
      "G loss : -163.28277587890625\n",
      "D loss : 41.738563537597656\n",
      "G loss : -76.24385070800781\n",
      "D loss : 20.970876693725586\n",
      "G loss : -27.089521408081055\n",
      "D loss : 12.916631698608398\n",
      "G loss : -13.200141906738281\n",
      "D loss : 4.446950435638428\n",
      "G loss : -0.23615407943725586\n",
      "D loss : -0.019065380096435547\n",
      "G loss : 77.0687255859375\n",
      "D loss : 11.023773193359375\n",
      "G loss : 61.785560607910156\n",
      "D loss : 1.4408483505249023\n",
      "G loss : 131.53338623046875\n",
      "D loss : 6.356904983520508\n",
      "G loss : 130.93118286132812\n",
      "D loss : -29.081562042236328\n",
      "G loss : 198.00286865234375\n",
      "D loss : 68.58309936523438\n",
      "G loss : 24.45967674255371\n",
      "D loss : 4.317243576049805\n",
      "G loss : 100.46735382080078\n",
      "D loss : 70.29551696777344\n",
      "G loss : 51.06665802001953\n",
      "D loss : 12.121654510498047\n",
      "G loss : 32.410831451416016\n",
      "D loss : 18.83673095703125\n",
      "G loss : 30.37885284423828\n",
      "D loss : 10.422676086425781\n",
      "G loss : 33.22357177734375\n",
      "D loss : 13.144190788269043\n",
      "G loss : 37.470863342285156\n",
      "D loss : 2.3035078048706055\n",
      "G loss : 42.01430892944336\n",
      "D loss : 2.3931198120117188\n",
      "G loss : 41.807769775390625\n",
      "D loss : 4.112268447875977\n",
      "G loss : 39.63218688964844\n",
      "D loss : 6.682450294494629\n",
      "G loss : 21.842777252197266\n",
      "D loss : 4.2253618240356445\n",
      "G loss : 27.907276153564453\n",
      "D loss : 11.322699546813965\n",
      "G loss : 2.4366636276245117\n",
      "D loss : 9.465368270874023\n",
      "G loss : -5.952284812927246\n",
      "D loss : 4.52493953704834\n",
      "G loss : -35.565460205078125\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_5.ckpt\n",
      "D loss : 1.4381132125854492\n",
      "G loss : -46.82218933105469\n",
      "D loss : 6.511649131774902\n",
      "G loss : -52.979148864746094\n",
      "D loss : -1.8270998001098633\n",
      "G loss : -72.11512756347656\n",
      "D loss : 1.7563667297363281\n",
      "G loss : -82.28611755371094\n",
      "D loss : 3.1302194595336914\n",
      "G loss : -46.936317443847656\n",
      "D loss : -13.635486602783203\n",
      "G loss : -26.976585388183594\n",
      "D loss : -9.190386772155762\n",
      "G loss : -6.558391094207764\n",
      "D loss : 44.04163360595703\n",
      "G loss : -13.18519401550293\n",
      "D loss : 27.926326751708984\n",
      "G loss : 12.223130226135254\n",
      "D loss : 37.19060516357422\n",
      "G loss : 22.658382415771484\n",
      "D loss : 3.4396896362304688\n",
      "G loss : 34.9486198425293\n",
      "D loss : 1.334871768951416\n",
      "G loss : 61.22739791870117\n",
      "D loss : 8.123202323913574\n",
      "G loss : 58.54173278808594\n",
      "D loss : 2.6494288444519043\n",
      "G loss : 73.08201599121094\n",
      "D loss : 18.6957950592041\n",
      "G loss : 37.732112884521484\n",
      "D loss : 5.3744096755981445\n",
      "G loss : 26.452180862426758\n",
      "D loss : -4.432455062866211\n",
      "G loss : 27.957992553710938\n",
      "D loss : 12.027870178222656\n",
      "G loss : 39.98250961303711\n",
      "D loss : 15.310434341430664\n",
      "G loss : 23.130477905273438\n",
      "D loss : 10.922967910766602\n",
      "G loss : 10.854175567626953\n",
      "D loss : 6.717345237731934\n",
      "G loss : 5.522751808166504\n",
      "D loss : 0.36069583892822266\n",
      "G loss : -0.5893718004226685\n",
      "D loss : 3.143342971801758\n",
      "G loss : 11.249870300292969\n",
      "D loss : 13.315799713134766\n",
      "G loss : 32.297603607177734\n",
      "D loss : 14.681427955627441\n",
      "G loss : 9.337247848510742\n",
      "D loss : -7.753243446350098\n",
      "G loss : -28.40003776550293\n",
      "D loss : 49.90098190307617\n",
      "G loss : -27.67538833618164\n",
      "D loss : -1.23002290725708\n",
      "G loss : -37.92494201660156\n",
      "D loss : 9.677154541015625\n",
      "G loss : -55.995155334472656\n",
      "D loss : 23.963333129882812\n",
      "G loss : 2.727952003479004\n",
      "D loss : 11.406639099121094\n",
      "G loss : -1.187180519104004\n",
      "D loss : 20.95592498779297\n",
      "G loss : -55.95263671875\n",
      "D loss : 18.37419319152832\n",
      "G loss : -52.76646423339844\n",
      "D loss : 11.1671142578125\n",
      "G loss : -39.26784896850586\n",
      "D loss : 11.889077186584473\n",
      "G loss : -29.96599578857422\n",
      "D loss : 8.515458106994629\n",
      "G loss : -26.50181007385254\n",
      "D loss : 6.109491348266602\n",
      "G loss : -4.784152030944824\n",
      "D loss : 0.5236854553222656\n",
      "G loss : -5.810303688049316\n",
      "D loss : 14.879555702209473\n",
      "G loss : 7.976186275482178\n",
      "D loss : 12.354433059692383\n",
      "G loss : 7.757568359375\n",
      "D loss : 5.568556785583496\n",
      "G loss : 25.33742904663086\n",
      "D loss : 2.444319725036621\n",
      "G loss : 33.200103759765625\n",
      "D loss : 5.238109588623047\n",
      "G loss : 29.653928756713867\n",
      "D loss : 11.209710121154785\n",
      "G loss : 21.893917083740234\n",
      "D loss : 10.88640308380127\n",
      "G loss : 30.2551212310791\n",
      "D loss : 5.267991065979004\n",
      "G loss : 24.38483428955078\n",
      "D loss : 13.659134864807129\n",
      "G loss : -9.586625099182129\n",
      "D loss : 2.911243438720703\n",
      "G loss : -4.9687910079956055\n",
      "D loss : 7.691099643707275\n",
      "G loss : -9.844453811645508\n",
      "D loss : 10.608357429504395\n",
      "G loss : -35.86328887939453\n",
      "D loss : -6.166843414306641\n",
      "G loss : -49.80459213256836\n",
      "D loss : 0.7414455413818359\n",
      "G loss : -87.41971588134766\n",
      "D loss : 1.994297981262207\n",
      "G loss : -99.55535888671875\n",
      "D loss : 19.860254287719727\n",
      "G loss : -103.55793762207031\n",
      "D loss : 19.628520965576172\n",
      "G loss : -67.63699340820312\n",
      "D loss : 34.25328826904297\n",
      "G loss : -34.386817932128906\n",
      "D loss : 6.208249092102051\n",
      "G loss : -11.61471176147461\n",
      "D loss : 1.1583166122436523\n",
      "G loss : 15.003609657287598\n",
      "D loss : -0.20544910430908203\n",
      "G loss : 25.457839965820312\n",
      "D loss : -18.06192398071289\n",
      "G loss : 71.47388458251953\n",
      "D loss : -6.440531253814697\n",
      "G loss : 139.68032836914062\n",
      "D loss : 32.85115432739258\n",
      "G loss : 55.280662536621094\n",
      "D loss : 9.702688217163086\n",
      "G loss : 29.190509796142578\n",
      "D loss : 16.136180877685547\n",
      "G loss : 42.22607421875\n",
      "D loss : 25.532094955444336\n",
      "G loss : 38.72196960449219\n",
      "D loss : 13.622030258178711\n",
      "G loss : 44.89915466308594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 7.4321746826171875\n",
      "G loss : 46.76887512207031\n",
      "D loss : 9.027633666992188\n",
      "G loss : 53.59910202026367\n",
      "D loss : -3.3382811546325684\n",
      "G loss : 97.28939819335938\n",
      "D loss : 5.125491142272949\n",
      "G loss : 84.7588882446289\n",
      "D loss : 10.574432373046875\n",
      "G loss : 44.060340881347656\n",
      "D loss : 16.114337921142578\n",
      "G loss : 3.236093521118164\n",
      "D loss : 5.636503219604492\n",
      "G loss : -0.46849632263183594\n",
      "D loss : 10.206174850463867\n",
      "G loss : -17.55108070373535\n",
      "D loss : 3.4260826110839844\n",
      "G loss : -40.34953308105469\n",
      "D loss : 1.037984848022461\n",
      "G loss : -48.05788803100586\n",
      "D loss : 6.401554584503174\n",
      "G loss : -22.7457275390625\n",
      "D loss : 7.605895519256592\n",
      "G loss : -49.25349426269531\n",
      "D loss : 14.865606307983398\n",
      "G loss : -45.40744400024414\n",
      "D loss : 10.417308807373047\n",
      "G loss : -19.85968780517578\n",
      "D loss : 6.0405683517456055\n",
      "G loss : -71.37043762207031\n",
      "D loss : -10.757837295532227\n",
      "G loss : -168.82485961914062\n",
      "D loss : -4.816700458526611\n",
      "G loss : -55.47911071777344\n",
      "D loss : 74.21206665039062\n",
      "G loss : 100.17496490478516\n",
      "D loss : 7.203347206115723\n",
      "G loss : 299.5477294921875\n",
      "D loss : -10.609562873840332\n",
      "G loss : 276.713623046875\n",
      "D loss : 36.78672790527344\n",
      "G loss : 199.2088623046875\n",
      "D loss : 45.989662170410156\n",
      "G loss : 126.57421875\n",
      "D loss : 17.405405044555664\n",
      "G loss : 66.32234191894531\n",
      "D loss : 6.811824798583984\n",
      "G loss : 62.90530014038086\n",
      "D loss : 12.958091735839844\n",
      "G loss : 43.562835693359375\n",
      "D loss : 2.0697784423828125\n",
      "G loss : 43.097251892089844\n",
      "D loss : 4.1258134841918945\n",
      "G loss : 39.10426330566406\n",
      "D loss : 10.110725402832031\n",
      "G loss : 21.16302490234375\n",
      "D loss : -4.75671911239624\n",
      "G loss : 22.384660720825195\n",
      "D loss : 19.828571319580078\n",
      "G loss : 2.3311212062835693\n",
      "D loss : 5.361082077026367\n",
      "G loss : 6.224461555480957\n",
      "D loss : 3.225583553314209\n",
      "G loss : 13.464767456054688\n",
      "D loss : 2.7012314796447754\n",
      "G loss : 36.019859313964844\n",
      "D loss : 4.710826396942139\n",
      "G loss : 42.6638069152832\n",
      "D loss : 4.860403537750244\n",
      "G loss : 36.348209381103516\n",
      "D loss : 6.938070774078369\n",
      "G loss : 27.419967651367188\n",
      "D loss : 7.1882524490356445\n",
      "G loss : 34.05354309082031\n",
      "D loss : 9.030241012573242\n",
      "G loss : 33.75450897216797\n",
      "D loss : 2.7731237411499023\n",
      "G loss : 50.8121452331543\n",
      "D loss : 0.8188638687133789\n",
      "G loss : 22.936811447143555\n",
      "D loss : -12.542535781860352\n",
      "G loss : 51.20198059082031\n",
      "D loss : 13.503006935119629\n",
      "G loss : -36.89106750488281\n",
      "D loss : -8.727583885192871\n",
      "G loss : -72.85823059082031\n",
      "D loss : 7.955347061157227\n",
      "G loss : -49.39799880981445\n",
      "D loss : 19.85749053955078\n",
      "G loss : -39.581783294677734\n",
      "D loss : 7.019669532775879\n",
      "G loss : 33.3823356628418\n",
      "D loss : 5.7301177978515625\n",
      "G loss : -9.056330680847168\n",
      "D loss : -9.75100040435791\n",
      "G loss : -11.154638290405273\n",
      "D loss : 17.556468963623047\n",
      "G loss : -45.07483673095703\n",
      "D loss : 11.173347473144531\n",
      "G loss : -62.35878372192383\n",
      "D loss : 14.96194076538086\n",
      "G loss : 8.000946044921875\n",
      "D loss : 18.058212280273438\n",
      "G loss : -6.432074546813965\n",
      "D loss : 19.43447494506836\n",
      "G loss : 2.48073148727417\n",
      "D loss : 6.737995147705078\n",
      "G loss : 17.001155853271484\n",
      "D loss : 7.456350326538086\n",
      "G loss : 4.478361129760742\n",
      "D loss : 8.606755256652832\n",
      "G loss : 6.18941068649292\n",
      "D loss : -2.9216699600219727\n",
      "G loss : 6.250929355621338\n",
      "D loss : 23.899261474609375\n",
      "G loss : 27.428565979003906\n",
      "D loss : 24.725290298461914\n",
      "G loss : 25.07052230834961\n",
      "D loss : 5.531704425811768\n",
      "G loss : 43.22358322143555\n",
      "D loss : 10.600177764892578\n",
      "G loss : 43.43708801269531\n",
      "D loss : 10.41545581817627\n",
      "G loss : 54.79582214355469\n",
      "D loss : -2.9217729568481445\n",
      "G loss : 77.43133544921875\n",
      "D loss : 14.669767379760742\n",
      "G loss : 60.59867858886719\n",
      "D loss : 6.210599899291992\n",
      "G loss : 43.22999572753906\n",
      "D loss : -3.2079124450683594\n",
      "G loss : -0.5725150108337402\n",
      "D loss : 19.6982421875\n",
      "G loss : 25.29656982421875\n",
      "D loss : 6.247549057006836\n",
      "G loss : 34.50597381591797\n",
      "D loss : 5.344254970550537\n",
      "G loss : 25.86147689819336\n",
      "D loss : 5.887925148010254\n",
      "G loss : 23.618751525878906\n",
      "D loss : -2.2880873680114746\n",
      "G loss : 7.264571189880371\n",
      "D loss : 8.35239315032959\n",
      "G loss : -33.10595703125\n",
      "D loss : 18.85799789428711\n",
      "G loss : -43.615726470947266\n",
      "D loss : 1.1542158126831055\n",
      "G loss : -38.40796661376953\n",
      "D loss : 6.834379196166992\n",
      "G loss : -45.76930236816406\n",
      "D loss : 7.929378509521484\n",
      "G loss : -32.49972152709961\n",
      "D loss : 4.605903148651123\n",
      "G loss : -29.807598114013672\n",
      "D loss : 14.969982147216797\n",
      "G loss : -58.246910095214844\n",
      "D loss : 18.149551391601562\n",
      "G loss : -34.92644500732422\n",
      "D loss : 15.815818786621094\n",
      "G loss : -43.94956970214844\n",
      "D loss : 18.149316787719727\n",
      "G loss : -12.1434965133667\n",
      "D loss : 12.498381614685059\n",
      "G loss : -18.105188369750977\n",
      "D loss : 9.303756713867188\n",
      "G loss : -10.017762184143066\n",
      "D loss : 9.755301475524902\n",
      "G loss : 4.725497245788574\n",
      "D loss : 12.978116989135742\n",
      "G loss : 4.523911476135254\n",
      "D loss : 9.943446159362793\n",
      "G loss : 39.13275909423828\n",
      "D loss : 0.7235479354858398\n",
      "G loss : 22.11575698852539\n",
      "D loss : 10.917367935180664\n",
      "G loss : 4.9854278564453125\n",
      "D loss : 0.1385955810546875\n",
      "G loss : 43.8734016418457\n",
      "D loss : 4.021380424499512\n",
      "G loss : 30.74303436279297\n",
      "D loss : 9.657160758972168\n",
      "G loss : 4.112771034240723\n",
      "D loss : 13.33958625793457\n",
      "G loss : 20.889904022216797\n",
      "D loss : 22.00331687927246\n",
      "G loss : -17.916831970214844\n",
      "D loss : 7.723515510559082\n",
      "G loss : -16.47294807434082\n",
      "D loss : 12.003377914428711\n",
      "G loss : -26.325965881347656\n",
      "D loss : 6.830903053283691\n",
      "G loss : -34.88819885253906\n",
      "D loss : 11.932119369506836\n",
      "G loss : -26.391693115234375\n",
      "D loss : 5.9902448654174805\n",
      "G loss : -43.11981964111328\n",
      "D loss : 8.989102363586426\n",
      "G loss : -22.38964080810547\n",
      "D loss : 2.8496761322021484\n",
      "G loss : -37.32902526855469\n",
      "D loss : 9.805703163146973\n",
      "G loss : -23.211612701416016\n",
      "D loss : 9.358175277709961\n",
      "G loss : -19.342472076416016\n",
      "D loss : 4.995762825012207\n",
      "G loss : 13.611539840698242\n",
      "D loss : 1.0924787521362305\n",
      "G loss : 5.255454063415527\n",
      "D loss : -0.9916520118713379\n",
      "G loss : 30.499847412109375\n",
      "D loss : -12.169828414916992\n",
      "G loss : 41.76749801635742\n",
      "D loss : 47.822933197021484\n",
      "G loss : 23.753753662109375\n",
      "D loss : 15.218263626098633\n",
      "G loss : 13.308326721191406\n",
      "D loss : 16.71273422241211\n",
      "G loss : 34.82871627807617\n",
      "D loss : 9.731653213500977\n",
      "G loss : 34.0784912109375\n",
      "D loss : 7.106546401977539\n",
      "G loss : 41.34239196777344\n",
      "D loss : 4.508787631988525\n",
      "G loss : 55.314762115478516\n",
      "D loss : -1.1587677001953125\n",
      "G loss : 92.67294311523438\n",
      "D loss : -1.5552315711975098\n",
      "G loss : 95.73458862304688\n",
      "D loss : -5.861147880554199\n",
      "G loss : 123.9074478149414\n",
      "D loss : 11.362139701843262\n",
      "G loss : 57.40385055541992\n",
      "D loss : 40.909523010253906\n",
      "G loss : 13.436687469482422\n",
      "D loss : 10.597379684448242\n",
      "G loss : -3.899388551712036\n",
      "D loss : 11.12660026550293\n",
      "G loss : 13.221210479736328\n",
      "D loss : 6.832486152648926\n",
      "G loss : 3.445814371109009\n",
      "D loss : 9.110357284545898\n",
      "G loss : -6.183443069458008\n",
      "D loss : 6.624967575073242\n",
      "G loss : -5.396833419799805\n",
      "D loss : 7.84335994720459\n",
      "G loss : -4.050685405731201\n",
      "D loss : 6.420742034912109\n",
      "G loss : -12.553720474243164\n",
      "D loss : -1.4688119888305664\n",
      "G loss : -14.5399169921875\n",
      "D loss : 0.1947641372680664\n",
      "G loss : -13.146505355834961\n",
      "D loss : 4.536068439483643\n",
      "G loss : -26.11627197265625\n",
      "D loss : -2.2280120849609375\n",
      "G loss : -45.83647155761719\n",
      "D loss : 3.9557199478149414\n",
      "G loss : -63.122093200683594\n",
      "D loss : -3.731278419494629\n",
      "G loss : -75.30804443359375\n",
      "D loss : 2.0926828384399414\n",
      "G loss : -69.18306732177734\n",
      "D loss : -9.82680892944336\n",
      "G loss : -61.72674560546875\n",
      "D loss : 39.08018493652344\n",
      "G loss : -197.84375\n",
      "D loss : -4.641995906829834\n",
      "G loss : -187.5384521484375\n",
      "D loss : 23.763029098510742\n",
      "G loss : -112.5884780883789\n",
      "D loss : 34.94939041137695\n",
      "G loss : -62.36029815673828\n",
      "D loss : 22.179550170898438\n",
      "G loss : -4.795505523681641\n",
      "D loss : -10.047040939331055\n",
      "G loss : 52.122745513916016\n",
      "D loss : -41.66577911376953\n",
      "G loss : 138.704833984375\n",
      "D loss : -59.410640716552734\n",
      "G loss : 436.4058532714844\n",
      "D loss : -2.121829032897949\n",
      "G loss : 87.71989440917969\n",
      "D loss : 143.90939331054688\n",
      "G loss : 162.95339965820312\n",
      "D loss : -50.60540008544922\n",
      "G loss : 80.46061706542969\n",
      "D loss : 118.01005554199219\n",
      "G loss : 110.29928588867188\n",
      "D loss : 45.77853012084961\n",
      "G loss : 141.1693115234375\n",
      "D loss : 12.900249481201172\n",
      "G loss : 243.17138671875\n",
      "D loss : -12.582269668579102\n",
      "G loss : 291.60443115234375\n",
      "D loss : 28.06638526916504\n",
      "G loss : 381.28900146484375\n",
      "D loss : 22.118642807006836\n",
      "G loss : 401.37384033203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 44.77934265136719\n",
      "G loss : 228.8522186279297\n",
      "D loss : 52.433326721191406\n",
      "G loss : 103.97982025146484\n",
      "D loss : 51.72085952758789\n",
      "G loss : 55.824378967285156\n",
      "D loss : 14.921417236328125\n",
      "G loss : 44.4957389831543\n",
      "D loss : 16.11172866821289\n",
      "G loss : 18.052814483642578\n",
      "D loss : 24.199295043945312\n",
      "G loss : 1.6911649703979492\n",
      "D loss : 4.702795505523682\n",
      "G loss : -5.744287490844727\n",
      "D loss : 0.3070535659790039\n",
      "G loss : -11.518292427062988\n",
      "D loss : -2.9215803146362305\n",
      "G loss : -40.37751007080078\n",
      "D loss : -16.002700805664062\n",
      "G loss : -76.07278442382812\n",
      "D loss : -10.575616836547852\n",
      "G loss : -126.70039367675781\n",
      "D loss : -8.628028869628906\n",
      "G loss : -176.56788635253906\n",
      "D loss : -0.05229473114013672\n",
      "G loss : -196.470947265625\n",
      "D loss : 14.157661437988281\n",
      "G loss : -185.89993286132812\n",
      "D loss : 6.723265647888184\n",
      "G loss : -136.27310180664062\n",
      "D loss : 1.3926348686218262\n",
      "G loss : -119.70396423339844\n",
      "D loss : 15.518775939941406\n",
      "G loss : -88.16580963134766\n",
      "D loss : -15.242066383361816\n",
      "G loss : -98.62320709228516\n",
      "D loss : -11.621543884277344\n",
      "G loss : -109.08561706542969\n",
      "D loss : -50.01190185546875\n",
      "G loss : -91.88160705566406\n",
      "D loss : 20.549718856811523\n",
      "G loss : -95.98786926269531\n",
      "D loss : 70.66370391845703\n",
      "G loss : -46.049766540527344\n",
      "D loss : -23.356294631958008\n",
      "G loss : -111.69041442871094\n",
      "D loss : 106.79338073730469\n",
      "G loss : -21.311161041259766\n",
      "D loss : 6.725390434265137\n",
      "G loss : -14.110237121582031\n",
      "D loss : 20.00475311279297\n",
      "G loss : 32.686363220214844\n",
      "D loss : 6.125057220458984\n",
      "G loss : 15.294229507446289\n",
      "D loss : 5.289303779602051\n",
      "G loss : 142.8223876953125\n",
      "D loss : 1.132181167602539\n",
      "G loss : 154.930908203125\n",
      "D loss : -3.776247024536133\n",
      "G loss : 133.55299377441406\n",
      "D loss : -26.82766342163086\n",
      "G loss : 240.73406982421875\n",
      "D loss : -59.09615707397461\n",
      "G loss : 353.59130859375\n",
      "D loss : 18.306941986083984\n",
      "G loss : 144.0589141845703\n",
      "D loss : 51.692039489746094\n",
      "G loss : 122.52523040771484\n",
      "D loss : 108.5503158569336\n",
      "G loss : 67.59135437011719\n",
      "D loss : 26.054664611816406\n",
      "G loss : 75.56769561767578\n",
      "D loss : 5.269901752471924\n",
      "G loss : 45.02303695678711\n",
      "D loss : 34.28998565673828\n",
      "G loss : 50.4725227355957\n",
      "D loss : 10.631136894226074\n",
      "G loss : 44.174591064453125\n",
      "D loss : 9.785442352294922\n",
      "G loss : 18.388599395751953\n",
      "D loss : 2.509711742401123\n",
      "G loss : 1.0365337133407593\n",
      "D loss : -4.008391380310059\n",
      "G loss : -14.551301002502441\n",
      "D loss : -1.6552205085754395\n",
      "G loss : -13.753357887268066\n",
      "D loss : -23.16936492919922\n",
      "G loss : -7.8623948097229\n",
      "D loss : 9.299141883850098\n",
      "G loss : -77.19544219970703\n",
      "D loss : -13.435315132141113\n",
      "G loss : -129.55233764648438\n",
      "D loss : 5.133818626403809\n",
      "G loss : -173.18121337890625\n",
      "D loss : 55.885990142822266\n",
      "G loss : -181.71432495117188\n",
      "D loss : -0.6453914642333984\n",
      "G loss : -157.8409423828125\n",
      "D loss : 9.831500053405762\n",
      "G loss : -110.39608764648438\n",
      "D loss : 22.23434066772461\n",
      "G loss : -105.53793334960938\n",
      "D loss : 12.781808853149414\n",
      "G loss : -99.00511169433594\n",
      "D loss : 13.010733604431152\n",
      "G loss : -53.63751220703125\n",
      "D loss : 21.937480926513672\n",
      "G loss : -40.756126403808594\n",
      "D loss : -1.2267885208129883\n",
      "G loss : 19.04007911682129\n",
      "D loss : 8.380583763122559\n",
      "G loss : -32.262001037597656\n",
      "D loss : -9.437541961669922\n",
      "G loss : 23.315597534179688\n",
      "D loss : 24.28531265258789\n",
      "G loss : 14.238603591918945\n",
      "D loss : 14.742103576660156\n",
      "G loss : 15.702584266662598\n",
      "D loss : 15.442890167236328\n",
      "G loss : 25.01382064819336\n",
      "D loss : 11.331971168518066\n",
      "G loss : 53.74517822265625\n",
      "D loss : 5.1798553466796875\n",
      "G loss : 73.10655975341797\n",
      "D loss : 1.2525553703308105\n",
      "G loss : 74.7996826171875\n",
      "D loss : 0.48084449768066406\n",
      "G loss : 88.89592742919922\n",
      "D loss : 19.997825622558594\n",
      "G loss : 92.1192855834961\n",
      "D loss : -6.278161525726318\n",
      "G loss : 74.70164489746094\n",
      "D loss : 13.189738273620605\n",
      "G loss : 61.37737274169922\n",
      "D loss : 3.482743263244629\n",
      "G loss : 56.22712707519531\n",
      "D loss : 20.82296371459961\n",
      "G loss : 65.09761047363281\n",
      "D loss : 2.9436569213867188\n",
      "G loss : 59.10901641845703\n",
      "D loss : 6.0470075607299805\n",
      "G loss : 35.345149993896484\n",
      "D loss : 2.3686819076538086\n",
      "G loss : 25.829547882080078\n",
      "D loss : -0.3902912139892578\n",
      "G loss : 28.369218826293945\n",
      "D loss : 15.495843887329102\n",
      "G loss : 4.17156982421875\n",
      "D loss : 4.86373233795166\n",
      "G loss : -12.729951858520508\n",
      "D loss : 4.73100471496582\n",
      "G loss : 25.699739456176758\n",
      "D loss : 29.568675994873047\n",
      "G loss : 22.2503604888916\n",
      "D loss : 0.37134695053100586\n",
      "G loss : 9.230008125305176\n",
      "D loss : 4.703264236450195\n",
      "G loss : -15.4105224609375\n",
      "D loss : -2.32174015045166\n",
      "G loss : -16.637617111206055\n",
      "D loss : -9.63737678527832\n",
      "G loss : -12.994775772094727\n",
      "D loss : -7.362029075622559\n",
      "G loss : 56.44161605834961\n",
      "D loss : 20.443544387817383\n",
      "G loss : 22.47313690185547\n",
      "D loss : 3.3402299880981445\n",
      "G loss : -20.469276428222656\n",
      "D loss : 7.685734272003174\n",
      "G loss : 18.023563385009766\n",
      "D loss : 27.011428833007812\n",
      "G loss : 88.41996002197266\n",
      "D loss : 0.6436619758605957\n",
      "G loss : 81.45345306396484\n",
      "D loss : 1.0327529907226562\n",
      "G loss : 140.06967163085938\n",
      "D loss : 13.62728500366211\n",
      "G loss : 107.65314483642578\n",
      "D loss : 28.218219757080078\n",
      "G loss : 22.812973022460938\n",
      "D loss : 39.907527923583984\n",
      "G loss : 24.064556121826172\n",
      "D loss : 15.825651168823242\n",
      "G loss : 13.422996520996094\n",
      "D loss : 19.689754486083984\n",
      "G loss : -1.819502592086792\n",
      "D loss : 2.206320285797119\n",
      "G loss : -13.260400772094727\n",
      "D loss : 0.1497178077697754\n",
      "G loss : -25.68056869506836\n",
      "D loss : -1.9270143508911133\n",
      "G loss : -20.3732967376709\n",
      "D loss : -10.14157772064209\n",
      "G loss : -43.57014465332031\n",
      "D loss : -28.11957550048828\n",
      "G loss : -47.16339111328125\n",
      "D loss : -32.13371658325195\n",
      "G loss : -17.96190643310547\n",
      "D loss : -11.049647331237793\n",
      "G loss : -86.99589538574219\n",
      "D loss : 56.57023620605469\n",
      "G loss : -115.72955322265625\n",
      "D loss : 17.85341453552246\n",
      "G loss : -127.51974487304688\n",
      "D loss : 82.68344116210938\n",
      "G loss : -104.45930480957031\n",
      "D loss : 24.019023895263672\n",
      "G loss : -74.659912109375\n",
      "D loss : 10.248083114624023\n",
      "G loss : -41.565189361572266\n",
      "D loss : 13.107124328613281\n",
      "G loss : -42.04237365722656\n",
      "D loss : 1.7539544105529785\n",
      "G loss : -38.56952667236328\n",
      "2\n",
      "D loss : 19.734516143798828\n",
      "G loss : -13.73797607421875\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_6.ckpt\n",
      "D loss : 16.376405715942383\n",
      "G loss : 33.15662384033203\n",
      "D loss : 1.8172245025634766\n",
      "G loss : 62.89521408081055\n",
      "D loss : 2.2867326736450195\n",
      "G loss : 54.91835021972656\n",
      "D loss : 2.643630027770996\n",
      "G loss : 129.87615966796875\n",
      "D loss : 14.475015640258789\n",
      "G loss : 68.99488067626953\n",
      "D loss : -4.202757835388184\n",
      "G loss : 124.53317260742188\n",
      "D loss : -9.974265098571777\n",
      "G loss : 210.67605590820312\n",
      "D loss : -13.285575866699219\n",
      "G loss : 212.18618774414062\n",
      "D loss : 18.005924224853516\n",
      "G loss : 135.80160522460938\n",
      "D loss : 8.699758529663086\n",
      "G loss : 122.47389221191406\n",
      "D loss : 7.486337661743164\n",
      "G loss : 149.99813842773438\n",
      "D loss : 14.694609642028809\n",
      "G loss : 73.09115600585938\n",
      "D loss : 63.87089538574219\n",
      "G loss : 35.969635009765625\n",
      "D loss : 47.098655700683594\n",
      "G loss : 38.51914596557617\n",
      "D loss : 10.507336616516113\n",
      "G loss : 19.00775909423828\n",
      "D loss : 18.637598037719727\n",
      "G loss : 17.184782028198242\n",
      "D loss : 4.5975799560546875\n",
      "G loss : 8.643150329589844\n",
      "D loss : 6.030277252197266\n",
      "G loss : -16.484895706176758\n",
      "D loss : -14.470967292785645\n",
      "G loss : -54.75865936279297\n",
      "D loss : -25.63070297241211\n",
      "G loss : -93.99034881591797\n",
      "D loss : -15.294608116149902\n",
      "G loss : -145.0617218017578\n",
      "D loss : 36.8288688659668\n",
      "G loss : -250.28225708007812\n",
      "D loss : 13.347432136535645\n",
      "G loss : -263.990234375\n",
      "D loss : -8.18592643737793\n",
      "G loss : -312.4075927734375\n",
      "D loss : 17.255722045898438\n",
      "G loss : -290.501953125\n",
      "D loss : 26.762500762939453\n",
      "G loss : -262.33184814453125\n",
      "D loss : 31.72603988647461\n",
      "G loss : -209.69720458984375\n",
      "D loss : 13.258241653442383\n",
      "G loss : -151.48184204101562\n",
      "D loss : 19.5377254486084\n",
      "G loss : -102.54486846923828\n",
      "D loss : 11.7362060546875\n",
      "G loss : -21.201358795166016\n",
      "D loss : 11.995800018310547\n",
      "G loss : 24.121910095214844\n",
      "D loss : -1.1274518966674805\n",
      "G loss : 63.314208984375\n",
      "D loss : 8.017641067504883\n",
      "G loss : 104.68982696533203\n",
      "D loss : -20.663429260253906\n",
      "G loss : 188.13235473632812\n",
      "D loss : 1.6082897186279297\n",
      "G loss : 188.22940063476562\n",
      "D loss : -20.936691284179688\n",
      "G loss : 223.1585235595703\n",
      "D loss : -9.688953399658203\n",
      "G loss : 200.27169799804688\n",
      "D loss : -3.633840560913086\n",
      "G loss : 268.04547119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 1.8289265632629395\n",
      "G loss : 255.07522583007812\n",
      "D loss : 22.493810653686523\n",
      "G loss : 232.34542846679688\n",
      "D loss : 10.008563995361328\n",
      "G loss : 203.07205200195312\n",
      "D loss : 14.173441886901855\n",
      "G loss : 179.7022705078125\n",
      "D loss : 34.962528228759766\n",
      "G loss : 168.74114990234375\n",
      "D loss : 12.276239395141602\n",
      "G loss : 134.1978759765625\n",
      "D loss : 36.26955032348633\n",
      "G loss : 89.06531524658203\n",
      "D loss : 32.06653594970703\n",
      "G loss : 42.19571304321289\n",
      "D loss : 2.614856719970703\n",
      "G loss : 27.423137664794922\n",
      "D loss : 9.117029190063477\n",
      "G loss : 4.495884895324707\n",
      "D loss : 4.318558216094971\n",
      "G loss : -43.1093864440918\n",
      "D loss : 4.129228115081787\n",
      "G loss : -83.41870880126953\n",
      "D loss : 14.009275436401367\n",
      "G loss : -69.4360580444336\n",
      "D loss : -11.619821548461914\n",
      "G loss : -61.07079315185547\n",
      "D loss : -30.075490951538086\n",
      "G loss : -109.36024475097656\n",
      "D loss : -5.710550308227539\n",
      "G loss : -129.0953369140625\n",
      "D loss : 64.01263427734375\n",
      "G loss : -120.81831359863281\n",
      "D loss : 26.586517333984375\n",
      "G loss : -134.03451538085938\n",
      "D loss : 37.57962417602539\n",
      "G loss : -112.64476013183594\n",
      "D loss : 7.036140441894531\n",
      "G loss : -124.17049407958984\n",
      "D loss : 2.9835004806518555\n",
      "G loss : -104.93959045410156\n",
      "D loss : 27.550777435302734\n",
      "G loss : -39.433021545410156\n",
      "D loss : 13.139198303222656\n",
      "G loss : 19.991695404052734\n",
      "D loss : -6.35903787612915\n",
      "G loss : 7.724996566772461\n",
      "D loss : 10.761822700500488\n",
      "G loss : 2.911933660507202\n",
      "D loss : 6.976417064666748\n",
      "G loss : 29.007944107055664\n",
      "D loss : 3.767360210418701\n",
      "G loss : 15.60573673248291\n",
      "D loss : 14.808629989624023\n",
      "G loss : 63.683223724365234\n",
      "D loss : 2.100350856781006\n",
      "G loss : 46.2414665222168\n",
      "D loss : 6.692556381225586\n",
      "G loss : 55.097801208496094\n",
      "D loss : 6.556489944458008\n",
      "G loss : 50.920860290527344\n",
      "D loss : -3.516646385192871\n",
      "G loss : 71.96633911132812\n",
      "D loss : 0.4739365577697754\n",
      "G loss : 64.93951416015625\n",
      "D loss : 8.341001510620117\n",
      "G loss : 71.43737030029297\n",
      "D loss : 3.3891239166259766\n",
      "G loss : 36.91035461425781\n",
      "D loss : 15.789281845092773\n",
      "G loss : 49.78886795043945\n",
      "D loss : 15.520245552062988\n",
      "G loss : 52.63990020751953\n",
      "D loss : 5.617412567138672\n",
      "G loss : 38.50043487548828\n",
      "D loss : 6.600290298461914\n",
      "G loss : 8.225967407226562\n",
      "D loss : -6.267665386199951\n",
      "G loss : 14.129463195800781\n",
      "D loss : 21.883563995361328\n",
      "G loss : -3.3669753074645996\n",
      "D loss : 3.662604331970215\n",
      "G loss : -27.887149810791016\n",
      "D loss : 6.325551509857178\n",
      "G loss : -19.567218780517578\n",
      "D loss : 8.184431076049805\n",
      "G loss : -9.297074317932129\n",
      "D loss : -4.6600799560546875\n",
      "G loss : -2.0558042526245117\n",
      "D loss : -13.640697479248047\n",
      "G loss : -6.4376912117004395\n",
      "D loss : 10.674090385437012\n",
      "G loss : -36.094078063964844\n",
      "D loss : 16.56041717529297\n",
      "G loss : 12.716062545776367\n",
      "D loss : 5.778971195220947\n",
      "G loss : 20.138736724853516\n",
      "D loss : -10.934213638305664\n",
      "G loss : 35.78635787963867\n",
      "D loss : -2.5163936614990234\n",
      "G loss : 54.16265869140625\n",
      "D loss : -3.3121190071105957\n",
      "G loss : 11.492990493774414\n",
      "D loss : -83.04474639892578\n",
      "G loss : 5.25859260559082\n",
      "D loss : 57.423702239990234\n",
      "G loss : 53.598785400390625\n",
      "D loss : -38.319332122802734\n",
      "G loss : 25.342193603515625\n",
      "D loss : 39.481990814208984\n",
      "G loss : -37.338951110839844\n",
      "D loss : 64.8284683227539\n",
      "G loss : -96.8408203125\n",
      "D loss : 57.116981506347656\n",
      "G loss : 16.33437728881836\n",
      "D loss : 8.56126880645752\n",
      "G loss : 70.77436065673828\n",
      "D loss : -23.648712158203125\n",
      "G loss : 129.22998046875\n",
      "D loss : -44.29629135131836\n",
      "G loss : 238.23873901367188\n",
      "D loss : -73.43343353271484\n",
      "G loss : 407.3028869628906\n",
      "D loss : 25.343887329101562\n",
      "G loss : 243.33175659179688\n",
      "D loss : 71.40574645996094\n",
      "G loss : 51.1865234375\n",
      "D loss : 29.092060089111328\n",
      "G loss : 72.36564636230469\n",
      "D loss : 34.26100540161133\n",
      "G loss : 25.849775314331055\n",
      "D loss : 68.36445617675781\n",
      "G loss : 8.686118125915527\n",
      "D loss : 39.94636154174805\n",
      "G loss : 32.88956069946289\n",
      "D loss : 19.499345779418945\n",
      "G loss : 13.260649681091309\n",
      "D loss : 13.641400337219238\n",
      "G loss : 14.281877517700195\n",
      "D loss : 11.358368873596191\n",
      "G loss : 16.020666122436523\n",
      "D loss : 9.74024772644043\n",
      "G loss : 25.541736602783203\n",
      "D loss : 3.9634389877319336\n",
      "G loss : 49.73139953613281\n",
      "D loss : 4.076852321624756\n",
      "G loss : 40.281837463378906\n",
      "D loss : 10.355363845825195\n",
      "G loss : 39.555904388427734\n",
      "D loss : -2.7644147872924805\n",
      "G loss : 17.168155670166016\n",
      "D loss : -11.995439529418945\n",
      "G loss : 37.18152618408203\n",
      "D loss : -30.186716079711914\n",
      "G loss : 5.857411861419678\n",
      "D loss : -28.643680572509766\n",
      "G loss : -11.696922302246094\n",
      "D loss : 36.17765426635742\n",
      "G loss : -23.050172805786133\n",
      "D loss : -19.972789764404297\n",
      "G loss : -53.094810485839844\n",
      "D loss : -47.01902770996094\n",
      "G loss : -95.7363510131836\n",
      "D loss : -26.066532135009766\n",
      "G loss : -219.97959899902344\n",
      "D loss : -39.76688003540039\n",
      "G loss : -326.7518310546875\n",
      "D loss : 92.11198425292969\n",
      "G loss : -189.38882446289062\n",
      "D loss : 44.59288024902344\n",
      "G loss : -290.09033203125\n",
      "D loss : 52.75254440307617\n",
      "G loss : -107.15519714355469\n",
      "D loss : 17.56703758239746\n",
      "G loss : -63.50664520263672\n",
      "D loss : -9.739692687988281\n",
      "G loss : -15.386911392211914\n",
      "D loss : -30.068714141845703\n",
      "G loss : -23.689739227294922\n",
      "D loss : -5.852808475494385\n",
      "G loss : 66.88829040527344\n",
      "D loss : -6.185927867889404\n",
      "G loss : 17.43260955810547\n",
      "D loss : -63.01106262207031\n",
      "G loss : 115.37964630126953\n",
      "D loss : -9.334474563598633\n",
      "G loss : -209.81793212890625\n",
      "D loss : 176.7960968017578\n",
      "G loss : -8.58165168762207\n",
      "D loss : 20.33648681640625\n",
      "G loss : -4.39752197265625\n",
      "D loss : 46.074886322021484\n",
      "G loss : 23.252193450927734\n",
      "D loss : 40.671566009521484\n",
      "G loss : 102.6290283203125\n",
      "D loss : -6.907625198364258\n",
      "G loss : 116.17861938476562\n",
      "D loss : -4.417954444885254\n",
      "G loss : 138.29202270507812\n",
      "D loss : -11.441874504089355\n",
      "G loss : 209.14767456054688\n",
      "D loss : -16.5100040435791\n",
      "G loss : 219.95318603515625\n",
      "D loss : -9.715583801269531\n",
      "G loss : 183.57986450195312\n",
      "D loss : 12.418289184570312\n",
      "G loss : 146.7174072265625\n",
      "D loss : 17.826587677001953\n",
      "G loss : 147.39215087890625\n",
      "D loss : -2.390164375305176\n",
      "G loss : 165.46063232421875\n",
      "D loss : 39.790157318115234\n",
      "G loss : 115.79246520996094\n",
      "D loss : 24.841625213623047\n",
      "G loss : 89.19388580322266\n",
      "D loss : 14.751056671142578\n",
      "G loss : 19.945158004760742\n",
      "D loss : 23.37920570373535\n",
      "G loss : -19.868091583251953\n",
      "D loss : 41.84524917602539\n",
      "G loss : 3.6905503273010254\n",
      "D loss : 14.725703239440918\n",
      "G loss : -17.369657516479492\n",
      "D loss : 5.342476844787598\n",
      "G loss : -36.101234436035156\n",
      "D loss : 3.3318958282470703\n",
      "G loss : -69.9043960571289\n",
      "D loss : -9.052946090698242\n",
      "G loss : -84.00310516357422\n",
      "D loss : 1.4173860549926758\n",
      "G loss : -22.08753204345703\n",
      "D loss : 12.553617477416992\n",
      "G loss : -78.78335571289062\n",
      "D loss : 12.628131866455078\n",
      "G loss : -48.23246765136719\n",
      "D loss : 18.58127784729004\n",
      "G loss : -25.94385528564453\n",
      "D loss : 24.5167179107666\n",
      "G loss : 10.175905227661133\n",
      "D loss : 14.536431312561035\n",
      "G loss : -4.1151933670043945\n",
      "D loss : 14.103840827941895\n",
      "G loss : 12.327770233154297\n",
      "D loss : 10.665714263916016\n",
      "G loss : 21.877620697021484\n",
      "D loss : 16.478076934814453\n",
      "G loss : 45.62445068359375\n",
      "D loss : 16.330278396606445\n",
      "G loss : 41.349388122558594\n",
      "D loss : 8.255814552307129\n",
      "G loss : 43.944766998291016\n",
      "D loss : 14.168224334716797\n",
      "G loss : 26.100311279296875\n",
      "D loss : 3.3094496726989746\n",
      "G loss : 23.849746704101562\n",
      "D loss : 0.3602256774902344\n",
      "G loss : 16.914209365844727\n",
      "D loss : 9.23894214630127\n",
      "G loss : -1.1479251384735107\n",
      "D loss : 28.226581573486328\n",
      "G loss : 20.34977149963379\n",
      "D loss : 19.921382904052734\n",
      "G loss : 19.616504669189453\n",
      "D loss : 9.630400657653809\n",
      "G loss : 34.32032775878906\n",
      "D loss : 13.061270713806152\n",
      "G loss : 29.592090606689453\n",
      "D loss : 9.688911437988281\n",
      "G loss : 24.13945960998535\n",
      "D loss : 11.46826171875\n",
      "G loss : -4.666211128234863\n",
      "D loss : 7.392573356628418\n",
      "G loss : -7.275928497314453\n",
      "D loss : 10.51749324798584\n",
      "G loss : 8.876993179321289\n",
      "D loss : 11.68590259552002\n",
      "G loss : 7.055240154266357\n",
      "D loss : 8.872228622436523\n",
      "G loss : 14.650510787963867\n",
      "D loss : 7.169613361358643\n",
      "G loss : 5.464138507843018\n",
      "D loss : 9.148138999938965\n",
      "G loss : 2.418623208999634\n",
      "D loss : 9.250423431396484\n",
      "G loss : -8.890212059020996\n",
      "D loss : 6.37762451171875\n",
      "G loss : -22.970516204833984\n",
      "D loss : 5.8548173904418945\n",
      "G loss : -27.924962997436523\n",
      "D loss : 9.99386978149414\n",
      "G loss : -19.359434127807617\n",
      "D loss : 1.2965469360351562\n",
      "G loss : -38.88729476928711\n",
      "D loss : 15.93452262878418\n",
      "G loss : -20.56283187866211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 6.02273416519165\n",
      "G loss : -12.265735626220703\n",
      "D loss : 11.974509239196777\n",
      "G loss : 10.657556533813477\n",
      "D loss : 3.2025699615478516\n",
      "G loss : 52.115638732910156\n",
      "D loss : -9.866756439208984\n",
      "G loss : 86.72395324707031\n",
      "D loss : 41.32050704956055\n",
      "G loss : 77.44855499267578\n",
      "D loss : 4.426867485046387\n",
      "G loss : 75.3021240234375\n",
      "D loss : 5.669764995574951\n",
      "G loss : 90.4788818359375\n",
      "D loss : 5.226288318634033\n",
      "G loss : 93.79502868652344\n",
      "D loss : 15.026390075683594\n",
      "G loss : 63.159934997558594\n",
      "D loss : 20.57943344116211\n",
      "G loss : 48.60071563720703\n",
      "D loss : 28.690170288085938\n",
      "G loss : 11.874935150146484\n",
      "D loss : 10.628030776977539\n",
      "G loss : 0.09937000274658203\n",
      "D loss : 6.9261932373046875\n",
      "G loss : -11.437111854553223\n",
      "D loss : 5.061348915100098\n",
      "G loss : -44.70372009277344\n",
      "D loss : 0.05721473693847656\n",
      "G loss : -55.883460998535156\n",
      "D loss : -5.548493385314941\n",
      "G loss : -76.4020767211914\n",
      "D loss : 6.009846210479736\n",
      "G loss : -96.59040832519531\n",
      "D loss : -7.491787433624268\n",
      "G loss : -128.70883178710938\n",
      "D loss : -21.202133178710938\n",
      "G loss : -265.94036865234375\n",
      "D loss : 93.95427703857422\n",
      "G loss : -115.12581634521484\n",
      "D loss : 53.1096305847168\n",
      "G loss : -38.25202941894531\n",
      "D loss : 0.31277990341186523\n",
      "G loss : -52.55724334716797\n",
      "D loss : 3.12005615234375\n",
      "G loss : -54.702476501464844\n",
      "D loss : -2.0032973289489746\n",
      "G loss : -52.28715515136719\n",
      "D loss : -31.58633804321289\n",
      "G loss : -148.611083984375\n",
      "D loss : 13.796407699584961\n",
      "G loss : -52.34166717529297\n",
      "D loss : 26.842426300048828\n",
      "G loss : -0.1392979621887207\n",
      "D loss : -10.43919563293457\n",
      "G loss : 256.15081787109375\n",
      "D loss : 8.292020797729492\n",
      "G loss : 187.38442993164062\n",
      "D loss : -1.8974676132202148\n",
      "G loss : 134.99000549316406\n",
      "D loss : 95.42101287841797\n",
      "G loss : 129.0056610107422\n",
      "D loss : 15.957433700561523\n",
      "G loss : 153.9562530517578\n",
      "D loss : -1.5010557174682617\n",
      "G loss : 196.37185668945312\n",
      "D loss : -5.445201396942139\n",
      "G loss : 223.02969360351562\n",
      "D loss : -11.659637451171875\n",
      "G loss : 312.65478515625\n",
      "D loss : 18.576692581176758\n",
      "G loss : 219.43690490722656\n",
      "D loss : 18.4918212890625\n",
      "G loss : 160.2680206298828\n",
      "D loss : 25.755395889282227\n",
      "G loss : 132.79861450195312\n",
      "D loss : 24.463685989379883\n",
      "G loss : 74.02874755859375\n",
      "D loss : 25.85757827758789\n",
      "G loss : 38.98391342163086\n",
      "D loss : 18.144207000732422\n",
      "G loss : 7.7162628173828125\n",
      "D loss : 11.868070602416992\n",
      "G loss : -16.561180114746094\n",
      "D loss : 9.705926895141602\n",
      "G loss : -32.47428894042969\n",
      "D loss : -4.046304225921631\n",
      "G loss : -65.77214050292969\n",
      "D loss : -5.512950897216797\n",
      "G loss : -121.69070434570312\n",
      "D loss : 8.410478591918945\n",
      "G loss : -132.26510620117188\n",
      "D loss : -14.808618545532227\n",
      "G loss : -229.3900909423828\n",
      "D loss : 28.66351318359375\n",
      "G loss : -142.5791778564453\n",
      "D loss : -22.076168060302734\n",
      "G loss : -224.14161682128906\n",
      "D loss : -46.92753982543945\n",
      "G loss : -352.66949462890625\n",
      "D loss : 116.64822387695312\n",
      "G loss : -220.38571166992188\n",
      "D loss : 94.53495788574219\n",
      "G loss : -99.25515747070312\n",
      "D loss : 39.37220001220703\n",
      "G loss : -41.0650634765625\n",
      "D loss : 8.208600997924805\n",
      "G loss : 14.524123191833496\n",
      "D loss : 4.971276760101318\n",
      "G loss : 56.022483825683594\n",
      "D loss : -13.948089599609375\n",
      "G loss : 136.42495727539062\n",
      "D loss : -25.034881591796875\n",
      "G loss : 140.9474334716797\n",
      "D loss : -66.04633331298828\n",
      "G loss : 443.62188720703125\n",
      "D loss : -41.82636642456055\n",
      "G loss : 430.571044921875\n",
      "D loss : 4.748106479644775\n",
      "G loss : 202.91641235351562\n",
      "D loss : 1.4748530387878418\n",
      "G loss : 428.1052551269531\n",
      "D loss : -119.63043975830078\n",
      "G loss : 255.78726196289062\n",
      "D loss : 292.2676086425781\n",
      "G loss : 186.83419799804688\n",
      "D loss : 4.252142906188965\n",
      "G loss : 170.7606201171875\n",
      "D loss : 60.02467727661133\n",
      "G loss : 137.77352905273438\n",
      "D loss : -7.529088973999023\n",
      "G loss : 202.94271850585938\n",
      "D loss : 39.36723327636719\n",
      "G loss : 99.29243469238281\n",
      "D loss : 31.843448638916016\n",
      "G loss : 119.2904281616211\n",
      "D loss : 16.967409133911133\n",
      "G loss : 121.75285339355469\n",
      "D loss : 32.26953887939453\n",
      "G loss : 125.44160461425781\n",
      "D loss : 53.62574768066406\n",
      "G loss : 57.152748107910156\n",
      "D loss : 24.208404541015625\n",
      "G loss : 5.231019020080566\n",
      "D loss : 12.081270217895508\n",
      "G loss : -16.01007080078125\n",
      "D loss : 3.5004196166992188\n",
      "G loss : -58.231056213378906\n",
      "D loss : -3.286436080932617\n",
      "G loss : -77.26093292236328\n",
      "D loss : -5.291435718536377\n",
      "G loss : -121.57032012939453\n",
      "D loss : 18.944747924804688\n",
      "G loss : -121.66825866699219\n",
      "D loss : 4.493597030639648\n",
      "G loss : -144.18136596679688\n",
      "D loss : 10.271768569946289\n",
      "G loss : -135.63320922851562\n",
      "D loss : 2.442842483520508\n",
      "G loss : -93.5719223022461\n",
      "D loss : -25.39031410217285\n",
      "G loss : -90.47775268554688\n",
      "D loss : -3.414980888366699\n",
      "G loss : -95.6028823852539\n",
      "D loss : 10.909505844116211\n",
      "G loss : -137.82553100585938\n",
      "D loss : 24.637065887451172\n",
      "G loss : -142.61709594726562\n",
      "D loss : 58.249794006347656\n",
      "G loss : -80.63388061523438\n",
      "D loss : -3.1529951095581055\n",
      "G loss : -118.4267578125\n",
      "D loss : -3.9811148643493652\n",
      "G loss : -130.2262420654297\n",
      "D loss : 9.444616317749023\n",
      "G loss : -132.31350708007812\n",
      "D loss : 5.066238880157471\n",
      "G loss : -154.644775390625\n",
      "D loss : 13.830254554748535\n",
      "G loss : -85.88313293457031\n",
      "D loss : 20.97347640991211\n",
      "G loss : -61.15605545043945\n",
      "D loss : 0.9127922058105469\n",
      "G loss : -95.14722442626953\n",
      "D loss : -33.94423294067383\n",
      "G loss : 56.889305114746094\n",
      "D loss : -9.22946834564209\n",
      "G loss : 46.969913482666016\n",
      "D loss : 61.111534118652344\n",
      "G loss : 27.873859405517578\n",
      "D loss : 34.344425201416016\n",
      "G loss : 73.23143005371094\n",
      "D loss : 19.936582565307617\n",
      "G loss : 121.12417602539062\n",
      "D loss : -3.733722686767578\n",
      "G loss : 247.00782775878906\n",
      "D loss : -8.496712684631348\n",
      "G loss : 266.2924499511719\n",
      "D loss : 24.033466339111328\n",
      "G loss : 195.20303344726562\n",
      "D loss : 0.20266962051391602\n",
      "G loss : 148.25082397460938\n",
      "D loss : 61.33537673950195\n",
      "G loss : 68.01133728027344\n",
      "D loss : 21.539451599121094\n",
      "G loss : 28.67583465576172\n",
      "D loss : 8.109596252441406\n",
      "G loss : -3.1542112827301025\n",
      "D loss : 0.21808815002441406\n",
      "G loss : -49.07057189941406\n",
      "D loss : -23.109973907470703\n",
      "G loss : -107.03255462646484\n",
      "D loss : 0.45050668716430664\n",
      "G loss : -117.66403198242188\n",
      "D loss : -7.792996406555176\n",
      "G loss : -153.91868591308594\n",
      "D loss : -14.44874382019043\n",
      "G loss : -192.69525146484375\n",
      "D loss : 15.960418701171875\n",
      "G loss : -195.4322509765625\n",
      "D loss : 26.755435943603516\n",
      "G loss : -192.82431030273438\n",
      "D loss : 10.398027420043945\n",
      "G loss : -193.16275024414062\n",
      "D loss : 12.225817680358887\n",
      "G loss : -178.88442993164062\n",
      "D loss : 20.569229125976562\n",
      "G loss : -107.86431884765625\n",
      "D loss : 16.351625442504883\n",
      "G loss : -74.15707397460938\n",
      "D loss : -29.07988739013672\n",
      "G loss : -65.78229522705078\n",
      "D loss : -5.709968090057373\n",
      "G loss : -56.08416748046875\n",
      "D loss : -24.876480102539062\n",
      "G loss : -283.3289794921875\n",
      "D loss : 91.31261444091797\n",
      "G loss : -35.00929260253906\n",
      "D loss : 105.81829833984375\n",
      "G loss : -47.025142669677734\n",
      "D loss : -26.7974796295166\n",
      "G loss : -87.00222778320312\n",
      "D loss : 6.930563926696777\n",
      "G loss : -89.25335693359375\n",
      "D loss : 92.36518859863281\n",
      "G loss : 36.35289001464844\n",
      "D loss : 23.29343605041504\n",
      "G loss : 65.56575012207031\n",
      "D loss : 9.741876602172852\n",
      "G loss : 60.33808135986328\n",
      "D loss : -2.1041126251220703\n",
      "G loss : 100.52310180664062\n",
      "D loss : -32.06296157836914\n",
      "G loss : 158.77777099609375\n",
      "D loss : -26.462919235229492\n",
      "G loss : 200.457275390625\n",
      "D loss : -61.00440216064453\n",
      "G loss : 312.430908203125\n",
      "D loss : -19.097734451293945\n",
      "G loss : 330.5818786621094\n",
      "D loss : -45.85010528564453\n",
      "G loss : 525.7484130859375\n",
      "D loss : -15.711853981018066\n",
      "G loss : 268.71893310546875\n",
      "D loss : -68.56275939941406\n",
      "G loss : 626.8207397460938\n",
      "D loss : 187.060546875\n",
      "G loss : 378.52667236328125\n",
      "D loss : 119.04598236083984\n",
      "G loss : 190.84329223632812\n",
      "D loss : 31.95415687561035\n",
      "G loss : 147.4137725830078\n",
      "D loss : 24.13640785217285\n",
      "G loss : 120.50688171386719\n",
      "D loss : 26.063716888427734\n",
      "G loss : 70.91383361816406\n",
      "D loss : 7.4660258293151855\n",
      "G loss : 13.148394584655762\n",
      "D loss : 7.679871559143066\n",
      "G loss : -7.516925811767578\n",
      "D loss : 6.610291481018066\n",
      "G loss : -75.16804504394531\n",
      "D loss : 23.94220733642578\n",
      "G loss : -65.12976837158203\n",
      "D loss : 66.89749145507812\n",
      "G loss : -38.255123138427734\n",
      "D loss : 7.505828857421875\n",
      "G loss : -47.143310546875\n",
      "D loss : 18.13095474243164\n",
      "G loss : -54.034515380859375\n",
      "D loss : -5.493463516235352\n",
      "G loss : -87.1937484741211\n",
      "D loss : 22.175182342529297\n",
      "G loss : -84.18283081054688\n",
      "D loss : -2.6819753646850586\n",
      "G loss : -88.58455657958984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 16.773181915283203\n",
      "G loss : -82.11711120605469\n",
      "D loss : 1.449751377105713\n",
      "G loss : -81.85797119140625\n",
      "D loss : 10.215734481811523\n",
      "G loss : -81.57048034667969\n",
      "D loss : -27.662534713745117\n",
      "G loss : -106.79660034179688\n",
      "D loss : -4.941025257110596\n",
      "G loss : -79.21981811523438\n",
      "D loss : 35.82865905761719\n",
      "G loss : -99.09117126464844\n",
      "D loss : 30.133541107177734\n",
      "G loss : -69.73604583740234\n",
      "D loss : -11.434052467346191\n",
      "G loss : -96.68730926513672\n",
      "D loss : 3.912731170654297\n",
      "G loss : -28.078956604003906\n",
      "D loss : -26.445619583129883\n",
      "G loss : -233.9851837158203\n",
      "D loss : 124.75148010253906\n",
      "G loss : -7.222568035125732\n",
      "D loss : 47.19866180419922\n",
      "G loss : -28.7764835357666\n",
      "D loss : 19.425411224365234\n",
      "G loss : -14.920653343200684\n",
      "D loss : 7.0808210372924805\n",
      "G loss : 12.921485900878906\n",
      "D loss : -3.6530838012695312\n",
      "G loss : 27.869388580322266\n",
      "D loss : -1.3204851150512695\n",
      "G loss : -0.38385438919067383\n",
      "D loss : -16.972999572753906\n",
      "G loss : 0.9836692810058594\n",
      "D loss : -24.88717269897461\n",
      "G loss : 67.18756103515625\n",
      "D loss : -22.830081939697266\n",
      "G loss : 96.81678009033203\n",
      "D loss : -4.812709808349609\n",
      "G loss : 93.5701904296875\n",
      "D loss : -44.18399429321289\n",
      "G loss : 187.554443359375\n",
      "D loss : -17.570524215698242\n",
      "G loss : 184.68679809570312\n",
      "D loss : 271.4140319824219\n",
      "G loss : 119.97151947021484\n",
      "D loss : 46.48062515258789\n",
      "G loss : 105.20389556884766\n",
      "D loss : 52.18018341064453\n",
      "G loss : 195.23681640625\n",
      "D loss : 6.977308750152588\n",
      "G loss : 264.24029541015625\n",
      "D loss : -0.743964672088623\n",
      "G loss : 280.5308837890625\n",
      "D loss : 4.367000579833984\n",
      "G loss : 258.968017578125\n",
      "D loss : 63.50692367553711\n",
      "G loss : 142.32540893554688\n",
      "D loss : 6.0395121574401855\n",
      "G loss : 84.08210754394531\n",
      "D loss : 52.49504089355469\n",
      "G loss : 16.795440673828125\n",
      "D loss : 28.786251068115234\n",
      "G loss : 3.1423325538635254\n",
      "D loss : -3.937314033508301\n",
      "G loss : -67.9542236328125\n",
      "D loss : -16.885562896728516\n",
      "G loss : -108.13215637207031\n",
      "D loss : -31.56279754638672\n",
      "G loss : -176.37814331054688\n",
      "D loss : -3.862957000732422\n",
      "G loss : -238.11111450195312\n",
      "D loss : 12.706995964050293\n",
      "G loss : -247.89633178710938\n",
      "D loss : 18.64510154724121\n",
      "G loss : -238.84671020507812\n",
      "D loss : -0.13216590881347656\n",
      "G loss : -249.46929931640625\n",
      "D loss : 48.262664794921875\n",
      "G loss : -180.71673583984375\n",
      "D loss : 14.05868148803711\n",
      "G loss : -126.04521179199219\n",
      "D loss : 15.251760482788086\n",
      "G loss : -175.52584838867188\n",
      "D loss : 46.63020324707031\n",
      "G loss : -99.62528991699219\n",
      "D loss : 30.45205307006836\n",
      "G loss : -90.04310607910156\n",
      "D loss : 15.30577564239502\n",
      "G loss : -58.18199920654297\n",
      "D loss : 10.039231300354004\n",
      "G loss : -3.8175408840179443\n",
      "D loss : -10.606961250305176\n",
      "G loss : 25.357376098632812\n",
      "D loss : -31.44528579711914\n",
      "G loss : 11.196258544921875\n",
      "D loss : 36.83248519897461\n",
      "G loss : 13.16840934753418\n",
      "D loss : 21.646759033203125\n",
      "G loss : -43.45477294921875\n",
      "D loss : 60.14214324951172\n",
      "G loss : 7.5660810470581055\n",
      "D loss : 29.064212799072266\n",
      "G loss : 26.697105407714844\n",
      "D loss : 10.460917472839355\n",
      "G loss : 19.582481384277344\n",
      "D loss : 1.9806509017944336\n",
      "G loss : 53.935791015625\n",
      "D loss : 16.881879806518555\n",
      "G loss : 47.107276916503906\n",
      "D loss : 4.854355812072754\n",
      "G loss : 39.796470642089844\n",
      "D loss : 1.2625031471252441\n",
      "G loss : 73.43821716308594\n",
      "D loss : 1.854794979095459\n",
      "G loss : 69.54094696044922\n",
      "D loss : 18.828975677490234\n",
      "G loss : 62.211727142333984\n",
      "D loss : -1.2527461051940918\n",
      "G loss : 64.19491577148438\n",
      "D loss : 2.2656807899475098\n",
      "G loss : 38.84123229980469\n",
      "D loss : 12.583076477050781\n",
      "G loss : 46.09436798095703\n",
      "D loss : -4.127691268920898\n",
      "G loss : 40.34827423095703\n",
      "D loss : 20.930479049682617\n",
      "G loss : 37.95058059692383\n",
      "D loss : 4.235238075256348\n",
      "G loss : 22.208232879638672\n",
      "D loss : 1.3162970542907715\n",
      "G loss : 68.58081817626953\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_7.ckpt\n",
      "D loss : 8.084059715270996\n",
      "G loss : 64.10507202148438\n",
      "D loss : 10.466519355773926\n",
      "G loss : 73.96182250976562\n",
      "D loss : 1.6018791198730469\n",
      "G loss : 57.368499755859375\n",
      "D loss : 10.642953872680664\n",
      "G loss : 24.993192672729492\n",
      "D loss : -17.001998901367188\n",
      "G loss : 20.23805046081543\n",
      "D loss : -9.386848449707031\n",
      "G loss : -13.291158676147461\n",
      "D loss : 16.11515998840332\n",
      "G loss : -26.61251449584961\n",
      "D loss : -3.3385682106018066\n",
      "G loss : -96.1181640625\n",
      "D loss : -4.81446647644043\n",
      "G loss : -124.08815002441406\n",
      "D loss : 11.68415355682373\n",
      "G loss : -116.47666931152344\n",
      "D loss : 1.280665397644043\n",
      "G loss : -104.45713806152344\n",
      "D loss : 6.56030797958374\n",
      "G loss : -63.74353790283203\n",
      "D loss : 22.370616912841797\n",
      "G loss : -20.78785514831543\n",
      "D loss : -51.4060173034668\n",
      "G loss : 45.60478210449219\n",
      "D loss : -48.98685836791992\n",
      "G loss : 9.693766593933105\n",
      "D loss : -46.21105194091797\n",
      "G loss : 329.0015869140625\n",
      "D loss : -55.14814376831055\n",
      "G loss : 496.46124267578125\n",
      "D loss : 165.27565002441406\n",
      "G loss : 150.36355590820312\n",
      "D loss : 12.23548698425293\n",
      "G loss : 190.44259643554688\n",
      "D loss : 88.59648895263672\n",
      "G loss : 262.97900390625\n",
      "D loss : -27.586639404296875\n",
      "G loss : 345.19482421875\n",
      "D loss : 26.89948844909668\n",
      "G loss : 421.93048095703125\n",
      "D loss : 22.809722900390625\n",
      "G loss : 398.6213073730469\n",
      "D loss : 32.09023666381836\n",
      "G loss : 359.70965576171875\n",
      "D loss : 27.968372344970703\n",
      "G loss : 265.35028076171875\n",
      "D loss : 4.0866851806640625\n",
      "G loss : 211.08511352539062\n",
      "D loss : 21.31934356689453\n",
      "G loss : 162.50643920898438\n",
      "D loss : 34.53318405151367\n",
      "G loss : 80.0716323852539\n",
      "D loss : 14.358665466308594\n",
      "G loss : 15.992301940917969\n",
      "D loss : 9.180337905883789\n",
      "G loss : -29.235416412353516\n",
      "D loss : -5.648625373840332\n",
      "G loss : -120.37467956542969\n",
      "D loss : 0.1075429916381836\n",
      "G loss : -144.95034790039062\n",
      "D loss : -6.627270221710205\n",
      "G loss : -248.1273651123047\n",
      "D loss : 18.68648338317871\n",
      "G loss : -200.1962890625\n",
      "D loss : 2.168130874633789\n",
      "G loss : -161.79315185546875\n",
      "D loss : 66.37394714355469\n",
      "G loss : -151.3173828125\n",
      "D loss : -13.56512451171875\n",
      "G loss : -194.95578002929688\n",
      "D loss : 14.79659652709961\n",
      "G loss : -169.9295196533203\n",
      "D loss : 11.425803184509277\n",
      "G loss : -172.05752563476562\n",
      "D loss : -28.722003936767578\n",
      "G loss : -169.1307373046875\n",
      "D loss : 129.380859375\n",
      "G loss : -76.73249816894531\n",
      "D loss : 38.02671813964844\n",
      "G loss : -90.85751342773438\n",
      "D loss : 6.72191858291626\n",
      "G loss : -32.88739776611328\n",
      "D loss : 6.161256790161133\n",
      "G loss : -68.22550964355469\n",
      "D loss : 22.956987380981445\n",
      "G loss : -31.370363235473633\n",
      "D loss : -6.792834281921387\n",
      "G loss : -39.44826889038086\n",
      "D loss : 9.527532577514648\n",
      "G loss : -33.23875045776367\n",
      "D loss : 9.642824172973633\n",
      "G loss : -9.044407844543457\n",
      "D loss : 7.330672740936279\n",
      "G loss : -0.35161542892456055\n",
      "D loss : -6.289917469024658\n",
      "G loss : 24.549713134765625\n",
      "D loss : 0.34908533096313477\n",
      "G loss : 24.48271369934082\n",
      "D loss : -17.330114364624023\n",
      "G loss : 168.04666137695312\n",
      "D loss : -38.816001892089844\n",
      "G loss : 174.4620361328125\n",
      "D loss : 43.19366455078125\n",
      "G loss : 161.3264617919922\n",
      "D loss : 29.295120239257812\n",
      "G loss : 104.07246398925781\n",
      "D loss : 5.05335807800293\n",
      "G loss : 97.75562286376953\n",
      "D loss : 35.913352966308594\n",
      "G loss : 146.66192626953125\n",
      "D loss : 3.3417491912841797\n",
      "G loss : 123.45870971679688\n",
      "D loss : 8.519540786743164\n",
      "G loss : 117.04545593261719\n",
      "D loss : 24.941513061523438\n",
      "G loss : 86.19801330566406\n",
      "D loss : 33.51565933227539\n",
      "G loss : 54.122005462646484\n",
      "D loss : 11.32443618774414\n",
      "G loss : 26.58422088623047\n",
      "D loss : 9.777911186218262\n",
      "G loss : 31.948637008666992\n",
      "D loss : -7.0560479164123535\n",
      "G loss : -7.00358772277832\n",
      "D loss : -17.84326171875\n",
      "G loss : -21.861074447631836\n",
      "D loss : -35.83448028564453\n",
      "G loss : -116.05056762695312\n",
      "D loss : 98.98666381835938\n",
      "G loss : -118.36547088623047\n",
      "D loss : 87.497314453125\n",
      "G loss : -77.18500518798828\n",
      "D loss : 7.724244594573975\n",
      "G loss : -89.8840560913086\n",
      "D loss : 0.3118562698364258\n",
      "G loss : -130.909423828125\n",
      "D loss : 29.519229888916016\n",
      "G loss : -111.27421569824219\n",
      "D loss : -9.855012893676758\n",
      "G loss : -120.10363006591797\n",
      "D loss : 10.051012992858887\n",
      "G loss : -110.6492919921875\n",
      "D loss : 10.044037818908691\n",
      "G loss : -77.5118408203125\n",
      "D loss : 3.3982677459716797\n",
      "G loss : -116.09430694580078\n",
      "D loss : 14.62353801727295\n",
      "G loss : -89.82200622558594\n",
      "D loss : -1.0873603820800781\n",
      "G loss : -52.482215881347656\n",
      "D loss : 35.11946105957031\n",
      "G loss : 2.8931102752685547\n",
      "D loss : -11.742018699645996\n",
      "G loss : 12.574251174926758\n",
      "D loss : 13.253142356872559\n",
      "G loss : 81.67578887939453\n",
      "D loss : -9.809736251831055\n",
      "G loss : 128.302978515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 6.323864936828613\n",
      "G loss : 177.3626708984375\n",
      "D loss : -9.690296173095703\n",
      "G loss : 176.53086853027344\n",
      "D loss : 12.618064880371094\n",
      "G loss : 172.63949584960938\n",
      "D loss : 51.96989822387695\n",
      "G loss : 166.48605346679688\n",
      "D loss : 21.527833938598633\n",
      "G loss : 138.47988891601562\n",
      "D loss : 46.47404098510742\n",
      "G loss : 76.87788391113281\n",
      "D loss : 16.835277557373047\n",
      "G loss : 30.376697540283203\n",
      "D loss : 6.112325668334961\n",
      "G loss : 4.657933235168457\n",
      "D loss : 2.5910167694091797\n",
      "G loss : -43.11122512817383\n",
      "D loss : 8.829219818115234\n",
      "G loss : -27.45292091369629\n",
      "D loss : -3.105236053466797\n",
      "G loss : -28.259126663208008\n",
      "D loss : 8.757357597351074\n",
      "G loss : -52.310699462890625\n",
      "D loss : 7.76998233795166\n",
      "G loss : -77.34780883789062\n",
      "D loss : 3.5323171615600586\n",
      "G loss : -39.99781036376953\n",
      "D loss : 0.32436513900756836\n",
      "G loss : -65.20287322998047\n",
      "D loss : 30.598058700561523\n",
      "G loss : -93.03602600097656\n",
      "D loss : -9.48661994934082\n",
      "G loss : -44.01782989501953\n",
      "D loss : 24.761642456054688\n",
      "G loss : -72.76566314697266\n",
      "D loss : 30.15326690673828\n",
      "G loss : -71.96121215820312\n",
      "D loss : 3.0290093421936035\n",
      "G loss : -87.83943939208984\n",
      "D loss : 17.81952667236328\n",
      "G loss : -96.38084411621094\n",
      "D loss : 22.183979034423828\n",
      "G loss : -59.866554260253906\n",
      "D loss : 16.832443237304688\n",
      "G loss : -35.50640869140625\n",
      "D loss : 1.09627103805542\n",
      "G loss : 13.242574691772461\n",
      "D loss : -1.8745408058166504\n",
      "G loss : 23.606346130371094\n",
      "D loss : 27.18937110900879\n",
      "G loss : 94.45863342285156\n",
      "D loss : -5.631867408752441\n",
      "G loss : 90.2828598022461\n",
      "D loss : -0.11028051376342773\n",
      "G loss : 126.11750793457031\n",
      "D loss : 4.143223762512207\n",
      "G loss : 174.23800659179688\n",
      "D loss : 10.58462905883789\n",
      "G loss : 182.01893615722656\n",
      "D loss : 22.350753784179688\n",
      "G loss : 110.72001647949219\n",
      "D loss : 16.96117401123047\n",
      "G loss : 60.97946548461914\n",
      "D loss : 24.414623260498047\n",
      "G loss : 5.992300033569336\n",
      "D loss : 3.569593906402588\n",
      "G loss : -46.28911590576172\n",
      "D loss : -3.1407008171081543\n",
      "G loss : -89.47152709960938\n",
      "D loss : 26.386844635009766\n",
      "G loss : -93.60877990722656\n",
      "D loss : 11.381587982177734\n",
      "G loss : -103.23831939697266\n",
      "D loss : 11.149596214294434\n",
      "G loss : -95.6516342163086\n",
      "D loss : 18.8743839263916\n",
      "G loss : -64.41482543945312\n",
      "D loss : 13.812751770019531\n",
      "G loss : -5.34630012512207\n",
      "D loss : -1.014233112335205\n",
      "G loss : 33.80625915527344\n",
      "D loss : -16.001903533935547\n",
      "G loss : 114.12437438964844\n",
      "D loss : 19.81415557861328\n",
      "G loss : 113.19644927978516\n",
      "D loss : 7.524219512939453\n",
      "G loss : 75.8011703491211\n",
      "D loss : -12.771313667297363\n",
      "G loss : 119.984619140625\n",
      "D loss : 18.5761775970459\n",
      "G loss : 32.27155303955078\n",
      "D loss : -3.685570240020752\n",
      "G loss : 28.668882369995117\n",
      "D loss : 7.344965934753418\n",
      "G loss : -25.317975997924805\n",
      "D loss : 28.245601654052734\n",
      "G loss : -67.05743408203125\n",
      "D loss : 11.97854995727539\n",
      "G loss : -92.97061157226562\n",
      "D loss : 8.694318771362305\n",
      "G loss : -144.34368896484375\n",
      "D loss : 2.372732162475586\n",
      "G loss : -160.6959228515625\n",
      "D loss : 25.33889389038086\n",
      "G loss : -147.97219848632812\n",
      "D loss : 6.892644882202148\n",
      "G loss : -57.80022048950195\n",
      "D loss : 48.5166015625\n",
      "G loss : -60.1153564453125\n",
      "D loss : 13.739351272583008\n",
      "G loss : -22.058414459228516\n",
      "D loss : 15.799495697021484\n",
      "G loss : 35.17198944091797\n",
      "D loss : 5.551867485046387\n",
      "G loss : 76.29987335205078\n",
      "D loss : 3.624274730682373\n",
      "G loss : 89.08598327636719\n",
      "D loss : -1.390625\n",
      "G loss : 117.91213989257812\n",
      "D loss : 0.42029762268066406\n",
      "G loss : 105.43572998046875\n",
      "D loss : 8.618171691894531\n",
      "G loss : 70.75843811035156\n",
      "D loss : 13.787973403930664\n",
      "G loss : 55.81675720214844\n",
      "D loss : 11.739213943481445\n",
      "G loss : 84.03253936767578\n",
      "D loss : 7.182852745056152\n",
      "G loss : 84.21149444580078\n",
      "D loss : 31.72871971130371\n",
      "G loss : 31.71788787841797\n",
      "D loss : 15.035636901855469\n",
      "G loss : 21.049930572509766\n",
      "D loss : 8.856437683105469\n",
      "G loss : -12.272283554077148\n",
      "D loss : 6.527371406555176\n",
      "G loss : -36.62063980102539\n",
      "D loss : -0.6738314628601074\n",
      "G loss : -66.92761993408203\n",
      "D loss : 7.656808853149414\n",
      "G loss : -67.83882141113281\n",
      "D loss : 8.929428100585938\n",
      "G loss : -45.412635803222656\n",
      "D loss : 6.217883110046387\n",
      "G loss : -42.43533706665039\n",
      "D loss : 4.261618137359619\n",
      "G loss : -20.7559814453125\n",
      "D loss : 3.265036106109619\n",
      "G loss : -15.348420143127441\n",
      "D loss : -0.8552331924438477\n",
      "G loss : -12.274621963500977\n",
      "D loss : 9.171262741088867\n",
      "G loss : 18.54768180847168\n",
      "D loss : 2.2064599990844727\n",
      "G loss : 14.694664001464844\n",
      "D loss : 20.331987380981445\n",
      "G loss : 3.5103774070739746\n",
      "D loss : 8.522453308105469\n",
      "G loss : 60.978843688964844\n",
      "D loss : 19.638416290283203\n",
      "G loss : 72.06849670410156\n",
      "D loss : 6.783250331878662\n",
      "G loss : 41.62434768676758\n",
      "D loss : 18.43948745727539\n",
      "G loss : 64.70341491699219\n",
      "D loss : 0.07689905166625977\n",
      "G loss : 102.14527893066406\n",
      "D loss : -14.084795951843262\n",
      "G loss : 72.28886413574219\n",
      "D loss : -23.571311950683594\n",
      "G loss : 114.02985382080078\n",
      "D loss : 22.857595443725586\n",
      "G loss : -1.4602751731872559\n",
      "D loss : 1.638953685760498\n",
      "G loss : 50.07231140136719\n",
      "D loss : 88.62889099121094\n",
      "G loss : 17.04705810546875\n",
      "D loss : -1.439401626586914\n",
      "G loss : -19.2340087890625\n",
      "D loss : 11.335567474365234\n",
      "G loss : -38.11033630371094\n",
      "D loss : 9.559381484985352\n",
      "G loss : -35.04517364501953\n",
      "D loss : -2.157170295715332\n",
      "G loss : -17.968055725097656\n",
      "D loss : 4.840872764587402\n",
      "G loss : 7.551852226257324\n",
      "D loss : 6.212821006774902\n",
      "G loss : 25.59389877319336\n",
      "D loss : 16.305593490600586\n",
      "G loss : 33.20552062988281\n",
      "D loss : 3.4651665687561035\n",
      "G loss : 23.736515045166016\n",
      "D loss : 9.036309242248535\n",
      "G loss : 27.842548370361328\n",
      "D loss : 11.980630874633789\n",
      "G loss : 11.022920608520508\n",
      "D loss : 14.46906852722168\n",
      "G loss : 4.037327766418457\n",
      "D loss : 15.67279052734375\n",
      "G loss : -0.6757566928863525\n",
      "D loss : 17.83024024963379\n",
      "G loss : -3.218172550201416\n",
      "D loss : 16.968299865722656\n",
      "G loss : -14.230952262878418\n",
      "D loss : 12.375370979309082\n",
      "G loss : -10.070930480957031\n",
      "D loss : -1.247300624847412\n",
      "G loss : -16.03249740600586\n",
      "D loss : 12.783702850341797\n",
      "G loss : -39.42118835449219\n",
      "D loss : 11.800411224365234\n",
      "G loss : -33.09185028076172\n",
      "D loss : 0.6408929824829102\n",
      "G loss : -14.695609092712402\n",
      "D loss : 11.97984504699707\n",
      "G loss : -33.40836715698242\n",
      "D loss : 30.841819763183594\n",
      "G loss : -41.70635223388672\n",
      "D loss : 14.656206130981445\n",
      "G loss : -15.766201972961426\n",
      "D loss : 9.808893203735352\n",
      "G loss : -20.04315757751465\n",
      "D loss : 14.582000732421875\n",
      "G loss : -33.24577331542969\n",
      "D loss : 9.818609237670898\n",
      "G loss : -19.595191955566406\n",
      "D loss : 5.464754581451416\n",
      "G loss : -25.123565673828125\n",
      "D loss : 3.3346805572509766\n",
      "G loss : -7.091071128845215\n",
      "D loss : 9.922765731811523\n",
      "G loss : -3.5193305015563965\n",
      "D loss : 5.187869071960449\n",
      "G loss : -8.005876541137695\n",
      "D loss : 11.047248840332031\n",
      "G loss : 26.160655975341797\n",
      "D loss : 9.163957595825195\n",
      "G loss : 44.168190002441406\n",
      "D loss : 4.447135925292969\n",
      "G loss : 82.26103210449219\n",
      "D loss : 8.873430252075195\n",
      "G loss : 75.5522232055664\n",
      "D loss : -0.06246614456176758\n",
      "G loss : 84.11335754394531\n",
      "D loss : 16.303028106689453\n",
      "G loss : 71.28335571289062\n",
      "D loss : 13.053518295288086\n",
      "G loss : 42.942081451416016\n",
      "D loss : 12.450559616088867\n",
      "G loss : 33.76963806152344\n",
      "D loss : 10.270872116088867\n",
      "G loss : 38.708831787109375\n",
      "D loss : 9.766985893249512\n",
      "G loss : 19.130491256713867\n",
      "D loss : 6.49275016784668\n",
      "G loss : 12.175373077392578\n",
      "D loss : 4.1554856300354\n",
      "G loss : 26.06181526184082\n",
      "D loss : 12.38221263885498\n",
      "G loss : 0.4331420660018921\n",
      "D loss : 9.888908386230469\n",
      "G loss : -44.139896392822266\n",
      "D loss : 16.199472427368164\n",
      "G loss : -7.777545928955078\n",
      "D loss : 9.710648536682129\n",
      "G loss : -24.706863403320312\n",
      "D loss : 6.434479236602783\n",
      "G loss : -52.60100173950195\n",
      "D loss : 4.433104038238525\n",
      "G loss : -50.632774353027344\n",
      "D loss : 24.70525360107422\n",
      "G loss : -14.986642837524414\n",
      "D loss : 9.498863220214844\n",
      "G loss : 9.33975601196289\n",
      "D loss : 3.168494701385498\n",
      "G loss : 38.18608093261719\n",
      "D loss : 1.414670467376709\n",
      "G loss : 56.15589141845703\n",
      "D loss : 14.935615539550781\n",
      "G loss : 20.228151321411133\n",
      "D loss : 21.0521240234375\n",
      "G loss : -13.70984172821045\n",
      "D loss : 9.774946212768555\n",
      "G loss : -6.047477722167969\n",
      "D loss : 7.343818187713623\n",
      "G loss : -18.42347526550293\n",
      "D loss : 7.20325231552124\n",
      "G loss : -17.857921600341797\n",
      "D loss : 10.739891052246094\n",
      "G loss : -15.791940689086914\n",
      "D loss : 7.492873191833496\n",
      "G loss : -34.45704650878906\n",
      "D loss : 9.606232643127441\n",
      "G loss : -25.034391403198242\n",
      "D loss : 7.952116012573242\n",
      "G loss : -7.65757942199707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 8.53062629699707\n",
      "G loss : 41.76101303100586\n",
      "D loss : 1.6978259086608887\n",
      "G loss : 68.93792724609375\n",
      "D loss : 3.8699021339416504\n",
      "G loss : 56.77068328857422\n",
      "D loss : 18.699893951416016\n",
      "G loss : 20.91458511352539\n",
      "D loss : 4.445939540863037\n",
      "G loss : 7.4977498054504395\n",
      "D loss : 16.26644515991211\n",
      "G loss : -2.957671642303467\n",
      "D loss : -1.0625314712524414\n",
      "G loss : -16.050647735595703\n",
      "D loss : 9.403352737426758\n",
      "G loss : -19.27450942993164\n",
      "D loss : -3.2078351974487305\n",
      "G loss : -61.741966247558594\n",
      "D loss : 7.350916385650635\n",
      "G loss : -47.91022491455078\n",
      "D loss : 5.380186557769775\n",
      "G loss : 18.638900756835938\n",
      "D loss : 5.141081809997559\n",
      "G loss : 47.114681243896484\n",
      "D loss : 11.63149642944336\n",
      "G loss : 25.955108642578125\n",
      "D loss : 77.89784240722656\n",
      "G loss : 18.62982940673828\n",
      "D loss : 18.790746688842773\n",
      "G loss : 37.66870880126953\n",
      "D loss : 6.702317714691162\n",
      "G loss : 16.771329879760742\n",
      "D loss : 4.489656925201416\n",
      "G loss : 3.830984592437744\n",
      "D loss : 11.849239349365234\n",
      "G loss : 1.5652852058410645\n",
      "D loss : 10.14186954498291\n",
      "G loss : -5.930445671081543\n",
      "D loss : 11.63638687133789\n",
      "G loss : -21.724180221557617\n",
      "D loss : 20.015153884887695\n",
      "G loss : -35.887516021728516\n",
      "D loss : 14.391042709350586\n",
      "G loss : -41.26667785644531\n",
      "D loss : 9.324975967407227\n",
      "G loss : -57.189231872558594\n",
      "D loss : 0.7605504989624023\n",
      "G loss : -50.66775894165039\n",
      "D loss : 8.053129196166992\n",
      "G loss : -52.30493927001953\n",
      "D loss : 13.916948318481445\n",
      "G loss : -24.808120727539062\n",
      "D loss : 3.9233431816101074\n",
      "G loss : -35.57451629638672\n",
      "D loss : -8.034124374389648\n",
      "G loss : 103.88641357421875\n",
      "D loss : -0.7642631530761719\n",
      "G loss : 82.9686508178711\n",
      "D loss : -14.747552871704102\n",
      "G loss : 193.9039764404297\n",
      "D loss : 51.46014404296875\n",
      "G loss : 65.72412872314453\n",
      "D loss : 31.725223541259766\n",
      "G loss : 50.0711555480957\n",
      "D loss : 4.5298380851745605\n",
      "G loss : 91.55931091308594\n",
      "D loss : 32.670196533203125\n",
      "G loss : 100.38304138183594\n",
      "D loss : 9.923145294189453\n",
      "G loss : 110.99468231201172\n",
      "D loss : 10.686361312866211\n",
      "G loss : 89.93833923339844\n",
      "D loss : 6.86100435256958\n",
      "G loss : 88.7186279296875\n",
      "D loss : 22.23728370666504\n",
      "G loss : 27.750690460205078\n",
      "D loss : 27.91994857788086\n",
      "G loss : 0.38368892669677734\n",
      "D loss : 7.131077766418457\n",
      "G loss : -15.263898849487305\n",
      "D loss : 7.252389907836914\n",
      "G loss : -45.82478713989258\n",
      "D loss : 1.8887462615966797\n",
      "G loss : -56.227455139160156\n",
      "D loss : 11.867912292480469\n",
      "G loss : -64.14309692382812\n",
      "D loss : 11.92384147644043\n",
      "G loss : -81.00273895263672\n",
      "D loss : 2.1688356399536133\n",
      "G loss : -87.44329071044922\n",
      "D loss : 5.729730606079102\n",
      "G loss : -85.58931732177734\n",
      "D loss : 12.924832344055176\n",
      "G loss : -67.9205322265625\n",
      "D loss : 8.002945899963379\n",
      "G loss : -63.58699035644531\n",
      "D loss : 18.10553741455078\n",
      "G loss : -28.518539428710938\n",
      "D loss : 5.424028396606445\n",
      "G loss : 0.5487159490585327\n",
      "D loss : 7.641607284545898\n",
      "G loss : 18.48174285888672\n",
      "D loss : 10.782224655151367\n",
      "G loss : 35.108306884765625\n",
      "D loss : 2.161703109741211\n",
      "G loss : 35.38715362548828\n",
      "D loss : 15.580018997192383\n",
      "G loss : 27.847896575927734\n",
      "D loss : 8.033259391784668\n",
      "G loss : 20.352567672729492\n",
      "D loss : 16.339033126831055\n",
      "G loss : 2.6654257774353027\n",
      "D loss : 15.940786361694336\n",
      "G loss : 7.788991928100586\n",
      "D loss : 4.887910842895508\n",
      "G loss : 29.631309509277344\n",
      "D loss : 3.6826372146606445\n",
      "G loss : 35.938514709472656\n",
      "D loss : 8.968847274780273\n",
      "G loss : 9.671512603759766\n",
      "D loss : 22.197490692138672\n",
      "G loss : 18.58212661743164\n",
      "D loss : 1.1436986923217773\n",
      "G loss : 17.133625030517578\n",
      "D loss : 14.801206588745117\n",
      "G loss : 19.193279266357422\n",
      "D loss : 11.076333045959473\n",
      "G loss : -6.967766761779785\n",
      "D loss : 7.777853965759277\n",
      "G loss : -18.546985626220703\n",
      "D loss : 12.870165824890137\n",
      "G loss : 0.41289782524108887\n",
      "D loss : 5.375617504119873\n",
      "G loss : -6.096864700317383\n",
      "D loss : 12.67707347869873\n",
      "G loss : 32.83251190185547\n",
      "D loss : 8.105123519897461\n",
      "G loss : 39.882652282714844\n",
      "D loss : 8.104074478149414\n",
      "G loss : 31.67912483215332\n",
      "D loss : 11.824100494384766\n",
      "G loss : 41.61104965209961\n",
      "D loss : 26.19331169128418\n",
      "G loss : 10.079216957092285\n",
      "D loss : 10.869789123535156\n",
      "G loss : 17.85400390625\n",
      "D loss : 9.13012981414795\n",
      "G loss : 3.0067224502563477\n",
      "D loss : 7.204185485839844\n",
      "G loss : 10.121341705322266\n",
      "D loss : 9.12324333190918\n",
      "G loss : -3.8453822135925293\n",
      "D loss : 7.814579963684082\n",
      "G loss : -15.0263671875\n",
      "D loss : 6.49578332901001\n",
      "G loss : -10.251317024230957\n",
      "D loss : 10.798824310302734\n",
      "G loss : -10.260992050170898\n",
      "D loss : 12.322898864746094\n",
      "G loss : 12.509125709533691\n",
      "D loss : 7.244911193847656\n",
      "G loss : 18.291034698486328\n",
      "D loss : 4.953181266784668\n",
      "G loss : 21.319087982177734\n",
      "D loss : 8.28769302368164\n",
      "G loss : -8.018179893493652\n",
      "D loss : 19.599000930786133\n",
      "G loss : -11.070556640625\n",
      "D loss : 8.381038665771484\n",
      "G loss : -25.289770126342773\n",
      "D loss : 7.29654598236084\n",
      "G loss : -40.42918395996094\n",
      "D loss : 10.036191940307617\n",
      "G loss : -8.855303764343262\n",
      "D loss : 7.23553466796875\n",
      "G loss : -30.038806915283203\n",
      "D loss : 17.62731170654297\n",
      "G loss : -5.194001197814941\n",
      "D loss : 9.028038024902344\n",
      "G loss : -9.953601837158203\n",
      "D loss : 13.0982666015625\n",
      "G loss : -17.07268714904785\n",
      "D loss : 18.962696075439453\n",
      "G loss : 3.9791419506073\n",
      "3\n",
      "D loss : 7.833844184875488\n",
      "G loss : 33.33945846557617\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_2.ckpt\n",
      "D loss : 6.075796127319336\n",
      "G loss : 66.9732894897461\n",
      "D loss : 15.442193031311035\n",
      "G loss : 23.702335357666016\n",
      "D loss : 13.68494987487793\n",
      "G loss : 18.35474967956543\n",
      "D loss : 9.624695777893066\n",
      "G loss : -3.593456506729126\n",
      "D loss : 8.11003589630127\n",
      "G loss : -13.788763046264648\n",
      "D loss : 5.669153213500977\n",
      "G loss : -8.580821990966797\n",
      "D loss : 7.940121650695801\n",
      "G loss : -13.922420501708984\n",
      "D loss : -1.8161048889160156\n",
      "G loss : -29.60476303100586\n",
      "D loss : -0.8282012939453125\n",
      "G loss : -32.271728515625\n",
      "D loss : 24.44281005859375\n",
      "G loss : -26.35077667236328\n",
      "D loss : 27.46007537841797\n",
      "G loss : 2.659806251525879\n",
      "D loss : 13.460633277893066\n",
      "G loss : 24.331501007080078\n",
      "D loss : 9.242069244384766\n",
      "G loss : 51.33642578125\n",
      "D loss : 11.543588638305664\n",
      "G loss : 39.92399597167969\n",
      "D loss : 1.216628074645996\n",
      "G loss : 67.066162109375\n",
      "D loss : 7.875802993774414\n",
      "G loss : 42.26322555541992\n",
      "D loss : 10.485384941101074\n",
      "G loss : 44.05381774902344\n",
      "D loss : 9.79055404663086\n",
      "G loss : -2.0761828422546387\n",
      "D loss : 13.599191665649414\n",
      "G loss : -1.5811302661895752\n",
      "D loss : 5.509027481079102\n",
      "G loss : -18.135828018188477\n",
      "D loss : 15.068243980407715\n",
      "G loss : -24.37786865234375\n",
      "D loss : 8.720070838928223\n",
      "G loss : -34.64264678955078\n",
      "D loss : 5.804441452026367\n",
      "G loss : -57.338111877441406\n",
      "D loss : 18.17734718322754\n",
      "G loss : -41.908042907714844\n",
      "D loss : 8.796506881713867\n",
      "G loss : -38.23738098144531\n",
      "D loss : 5.236327171325684\n",
      "G loss : -19.710933685302734\n",
      "D loss : 5.092543601989746\n",
      "G loss : -41.762001037597656\n",
      "D loss : 7.19277811050415\n",
      "G loss : -47.475215911865234\n",
      "D loss : 4.208629608154297\n",
      "G loss : -32.08940887451172\n",
      "D loss : 4.0674519538879395\n",
      "G loss : -72.31768798828125\n",
      "D loss : 4.895639896392822\n",
      "G loss : -90.13211059570312\n",
      "D loss : 19.486236572265625\n",
      "G loss : -67.32718658447266\n",
      "D loss : 20.635181427001953\n",
      "G loss : -34.78260040283203\n",
      "D loss : 14.018667221069336\n",
      "G loss : 7.601785182952881\n",
      "D loss : 4.260213851928711\n",
      "G loss : 37.74761962890625\n",
      "D loss : 5.115536689758301\n",
      "G loss : 50.75013732910156\n",
      "D loss : 11.356630325317383\n",
      "G loss : 44.786865234375\n",
      "D loss : 7.189008712768555\n",
      "G loss : 53.8442497253418\n",
      "D loss : 1.4838085174560547\n",
      "G loss : 85.48090362548828\n",
      "D loss : 23.014997482299805\n",
      "G loss : 41.455387115478516\n",
      "D loss : 6.717591285705566\n",
      "G loss : 41.401039123535156\n",
      "D loss : 20.70629119873047\n",
      "G loss : 10.298847198486328\n",
      "D loss : 7.877077102661133\n",
      "G loss : 0.0018983185291290283\n",
      "D loss : 8.224177360534668\n",
      "G loss : -3.4374895095825195\n",
      "D loss : 12.428121566772461\n",
      "G loss : -20.557039260864258\n",
      "D loss : 7.655256271362305\n",
      "G loss : -24.38779067993164\n",
      "D loss : -3.868246078491211\n",
      "G loss : -34.0368537902832\n",
      "D loss : -6.033486366271973\n",
      "G loss : -69.49606323242188\n",
      "D loss : 16.408935546875\n",
      "G loss : -81.55205535888672\n",
      "D loss : 25.569656372070312\n",
      "G loss : -89.06642150878906\n",
      "D loss : 5.7542595863342285\n",
      "G loss : -93.08660888671875\n",
      "D loss : 19.038761138916016\n",
      "G loss : -87.88923645019531\n",
      "D loss : 12.561302185058594\n",
      "G loss : -51.06241989135742\n",
      "D loss : 2.011866569519043\n",
      "G loss : -46.933326721191406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 7.136645793914795\n",
      "G loss : -9.828475952148438\n",
      "D loss : 0.1368083953857422\n",
      "G loss : 38.18459701538086\n",
      "D loss : -8.416563034057617\n",
      "G loss : 64.740478515625\n",
      "D loss : -27.79629135131836\n",
      "G loss : 116.13336944580078\n",
      "D loss : 39.2337646484375\n",
      "G loss : 49.433013916015625\n",
      "D loss : 3.4043869972229004\n",
      "G loss : 82.68031311035156\n",
      "D loss : 17.971424102783203\n",
      "G loss : 74.29108428955078\n",
      "D loss : 23.68213653564453\n",
      "G loss : 74.99967193603516\n",
      "D loss : 10.733003616333008\n",
      "G loss : 78.77252197265625\n",
      "D loss : 9.867670059204102\n",
      "G loss : 89.94854736328125\n",
      "D loss : 7.364006042480469\n",
      "G loss : 89.69054412841797\n",
      "D loss : 7.641124725341797\n",
      "G loss : 74.65992736816406\n",
      "D loss : 7.784689903259277\n",
      "G loss : 50.235294342041016\n",
      "D loss : 5.558449745178223\n",
      "G loss : 31.581972122192383\n",
      "D loss : 17.26218032836914\n",
      "G loss : 12.518119812011719\n",
      "D loss : -1.9081611633300781\n",
      "G loss : -1.1540513038635254\n",
      "D loss : -5.031618118286133\n",
      "G loss : -25.181468963623047\n",
      "D loss : 20.066570281982422\n",
      "G loss : -29.11765480041504\n",
      "D loss : 2.749697208404541\n",
      "G loss : -29.138469696044922\n",
      "D loss : 6.265707015991211\n",
      "G loss : -30.391321182250977\n",
      "D loss : 8.667996406555176\n",
      "G loss : -36.07136154174805\n",
      "D loss : 14.278443336486816\n",
      "G loss : -31.26643943786621\n",
      "D loss : 25.09085464477539\n",
      "G loss : -6.0907673835754395\n",
      "D loss : 12.668031692504883\n",
      "G loss : 11.557409286499023\n",
      "D loss : 11.93362808227539\n",
      "G loss : -0.3163168430328369\n",
      "D loss : 6.667652130126953\n",
      "G loss : -3.2794594764709473\n",
      "D loss : 15.324092864990234\n",
      "G loss : -13.567959785461426\n",
      "D loss : 12.75912094116211\n",
      "G loss : -15.927099227905273\n",
      "D loss : 10.711698532104492\n",
      "G loss : -10.405858039855957\n",
      "D loss : 12.383098602294922\n",
      "G loss : -15.684622764587402\n",
      "D loss : 13.210326194763184\n",
      "G loss : -14.913320541381836\n",
      "D loss : 9.17848014831543\n",
      "G loss : -14.320873260498047\n",
      "D loss : 9.618341445922852\n",
      "G loss : 4.905831813812256\n",
      "D loss : 8.03822135925293\n",
      "G loss : 10.252470970153809\n",
      "D loss : 14.175729751586914\n",
      "G loss : -3.8114938735961914\n",
      "D loss : 6.492072582244873\n",
      "G loss : -16.919761657714844\n",
      "D loss : 8.896522521972656\n",
      "G loss : 10.80722713470459\n",
      "D loss : 8.059408187866211\n",
      "G loss : 7.08054256439209\n",
      "D loss : 2.85013484954834\n",
      "G loss : 4.083288669586182\n",
      "D loss : 8.792863845825195\n",
      "G loss : -2.02410888671875\n",
      "D loss : 6.660040378570557\n",
      "G loss : 15.48371410369873\n",
      "D loss : 8.921698570251465\n",
      "G loss : 27.63971519470215\n",
      "D loss : 8.826414108276367\n",
      "G loss : 49.19336700439453\n",
      "D loss : 6.045138835906982\n",
      "G loss : 39.85320281982422\n",
      "D loss : 15.34134578704834\n",
      "G loss : 42.3521728515625\n",
      "D loss : 3.23077392578125\n",
      "G loss : 47.38124084472656\n",
      "D loss : 8.663965225219727\n",
      "G loss : 43.5617561340332\n",
      "D loss : 15.746929168701172\n",
      "G loss : 19.0017147064209\n",
      "D loss : 13.114278793334961\n",
      "G loss : 14.74070930480957\n",
      "D loss : 9.471019744873047\n",
      "G loss : 18.787269592285156\n",
      "D loss : 12.639619827270508\n",
      "G loss : 12.22036361694336\n",
      "D loss : 16.105934143066406\n",
      "G loss : 0.8378808498382568\n",
      "D loss : 12.653693199157715\n",
      "G loss : -6.398964881896973\n",
      "D loss : 7.176198959350586\n",
      "G loss : -28.955310821533203\n",
      "D loss : 9.606400489807129\n",
      "G loss : -46.827781677246094\n",
      "D loss : 6.568752288818359\n",
      "G loss : -65.83977508544922\n",
      "D loss : 0.5509433746337891\n",
      "G loss : -66.00040435791016\n",
      "D loss : 7.791395664215088\n",
      "G loss : -46.54459762573242\n",
      "D loss : 12.109567642211914\n",
      "G loss : -47.92699432373047\n",
      "D loss : 2.4210457801818848\n",
      "G loss : -38.472625732421875\n",
      "D loss : 11.75123405456543\n",
      "G loss : -61.4467658996582\n",
      "D loss : 26.434593200683594\n",
      "G loss : -1.0001373291015625\n",
      "D loss : 11.907831192016602\n",
      "G loss : -14.932442665100098\n",
      "D loss : 6.479802131652832\n",
      "G loss : 5.703510284423828\n",
      "D loss : 6.504488945007324\n",
      "G loss : 54.116539001464844\n",
      "D loss : 1.344775676727295\n",
      "G loss : 84.38313293457031\n",
      "D loss : -2.846402645111084\n",
      "G loss : 76.07918548583984\n",
      "D loss : -7.478055000305176\n",
      "G loss : 102.51800537109375\n",
      "D loss : -29.08077621459961\n",
      "G loss : 114.91558837890625\n",
      "D loss : 33.87778854370117\n",
      "G loss : 145.63111877441406\n",
      "D loss : 31.405874252319336\n",
      "G loss : 40.634742736816406\n",
      "D loss : 41.16755676269531\n",
      "G loss : 45.12178039550781\n",
      "D loss : 23.30931854248047\n",
      "G loss : 37.386627197265625\n",
      "D loss : 13.395112991333008\n",
      "G loss : 14.40134334564209\n",
      "D loss : 21.554702758789062\n",
      "G loss : 4.537308216094971\n",
      "D loss : 15.943341255187988\n",
      "G loss : -10.751861572265625\n",
      "D loss : 8.363162994384766\n",
      "G loss : -34.1173095703125\n",
      "D loss : 8.626846313476562\n",
      "G loss : -38.98865509033203\n",
      "D loss : -5.079154968261719\n",
      "G loss : -60.85423278808594\n",
      "D loss : -15.741666793823242\n",
      "G loss : -85.10385131835938\n",
      "D loss : 7.083000183105469\n",
      "G loss : -90.9473648071289\n",
      "D loss : 13.850918769836426\n",
      "G loss : -97.86293029785156\n",
      "D loss : 11.50391960144043\n",
      "G loss : -85.73258209228516\n",
      "D loss : 2.532166004180908\n",
      "G loss : -74.62223815917969\n",
      "D loss : 2.153263568878174\n",
      "G loss : -74.7225570678711\n",
      "D loss : 24.367389678955078\n",
      "G loss : -49.00715637207031\n",
      "D loss : 13.235420227050781\n",
      "G loss : -47.11005783081055\n",
      "D loss : 30.04348373413086\n",
      "G loss : -19.30643081665039\n",
      "D loss : 14.76086139678955\n",
      "G loss : 7.813868522644043\n",
      "D loss : 6.093960762023926\n",
      "G loss : 20.625049591064453\n",
      "D loss : 1.6666059494018555\n",
      "G loss : 32.38707733154297\n",
      "D loss : -1.7019696235656738\n",
      "G loss : 41.60533142089844\n",
      "D loss : -2.4059414863586426\n",
      "G loss : 60.66138458251953\n",
      "D loss : 9.900298118591309\n",
      "G loss : 25.0754451751709\n",
      "D loss : 11.33063793182373\n",
      "G loss : 58.06220626831055\n",
      "D loss : 11.64462947845459\n",
      "G loss : 34.412879943847656\n",
      "D loss : -9.457891464233398\n",
      "G loss : -32.074100494384766\n",
      "D loss : 85.72061157226562\n",
      "G loss : 12.547749519348145\n",
      "D loss : 19.871788024902344\n",
      "G loss : 14.288447380065918\n",
      "D loss : 22.315879821777344\n",
      "G loss : 39.1697998046875\n",
      "D loss : 9.454608917236328\n",
      "G loss : 60.151065826416016\n",
      "D loss : 7.893200874328613\n",
      "G loss : 49.82568359375\n",
      "D loss : 12.51700496673584\n",
      "G loss : 38.61896514892578\n",
      "D loss : 6.506104469299316\n",
      "G loss : 34.02873229980469\n",
      "D loss : 7.512964248657227\n",
      "G loss : 31.6351318359375\n",
      "D loss : 4.74058723449707\n",
      "G loss : 24.179805755615234\n",
      "D loss : 2.6106157302856445\n",
      "G loss : 12.452019691467285\n",
      "D loss : 0.021946430206298828\n",
      "G loss : -0.8223062753677368\n",
      "D loss : -3.995424747467041\n",
      "G loss : 23.747642517089844\n",
      "D loss : 2.550510883331299\n",
      "G loss : -0.09268808364868164\n",
      "D loss : -0.019103527069091797\n",
      "G loss : -14.289051055908203\n",
      "D loss : 14.112287521362305\n",
      "G loss : -24.366708755493164\n",
      "D loss : 5.487270832061768\n",
      "G loss : -26.20672035217285\n",
      "D loss : 4.388365268707275\n",
      "G loss : -8.376343727111816\n",
      "D loss : 12.200801849365234\n",
      "G loss : -19.66089630126953\n",
      "D loss : 23.64045524597168\n",
      "G loss : -67.63682556152344\n",
      "D loss : 13.707391738891602\n",
      "G loss : -71.36170959472656\n",
      "D loss : 12.721359252929688\n",
      "G loss : -65.5163345336914\n",
      "D loss : 10.926548957824707\n",
      "G loss : -96.80059814453125\n",
      "D loss : 12.169344902038574\n",
      "G loss : -79.57820892333984\n",
      "D loss : 22.240324020385742\n",
      "G loss : -71.08817291259766\n",
      "D loss : 15.693949699401855\n",
      "G loss : -37.06987762451172\n",
      "D loss : 19.076248168945312\n",
      "G loss : -21.865795135498047\n",
      "D loss : 9.031713485717773\n",
      "G loss : -8.131180763244629\n",
      "D loss : 9.991948127746582\n",
      "G loss : -10.130306243896484\n",
      "D loss : 6.35555362701416\n",
      "G loss : 2.0255119800567627\n",
      "D loss : -0.0027475357055664062\n",
      "G loss : 4.713693618774414\n",
      "D loss : 15.349340438842773\n",
      "G loss : 33.02513122558594\n",
      "D loss : -0.6868758201599121\n",
      "G loss : 58.324546813964844\n",
      "D loss : -3.8355517387390137\n",
      "G loss : 91.83682250976562\n",
      "D loss : 12.079818725585938\n",
      "G loss : 62.98783493041992\n",
      "D loss : 11.993072509765625\n",
      "G loss : 61.02241516113281\n",
      "D loss : 5.402740478515625\n",
      "G loss : 38.09764862060547\n",
      "D loss : 14.955107688903809\n",
      "G loss : 14.868602752685547\n",
      "D loss : 5.019989967346191\n",
      "G loss : 5.282763957977295\n",
      "D loss : 7.704488754272461\n",
      "G loss : 5.1148576736450195\n",
      "D loss : -1.588538646697998\n",
      "G loss : -4.764493465423584\n",
      "D loss : 4.779507637023926\n",
      "G loss : -4.4370951652526855\n",
      "D loss : 7.833295822143555\n",
      "G loss : -17.614343643188477\n",
      "D loss : -4.920247554779053\n",
      "G loss : -8.28024673461914\n",
      "D loss : 9.7439603805542\n",
      "G loss : -24.657180786132812\n",
      "D loss : 25.832820892333984\n",
      "G loss : -24.054533004760742\n",
      "D loss : 22.9193172454834\n",
      "G loss : -16.54119110107422\n",
      "D loss : 12.735652923583984\n",
      "G loss : 21.573272705078125\n",
      "D loss : 2.1116890907287598\n",
      "G loss : 24.00877571105957\n",
      "D loss : 6.926712989807129\n",
      "G loss : 47.66185760498047\n",
      "D loss : 11.828288078308105\n",
      "G loss : 48.5321044921875\n",
      "D loss : 4.200830936431885\n",
      "G loss : 70.41163635253906\n",
      "D loss : 11.68165397644043\n",
      "G loss : 52.54869842529297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 12.80723762512207\n",
      "G loss : 32.88531494140625\n",
      "D loss : 12.425631523132324\n",
      "G loss : 32.261383056640625\n",
      "D loss : 7.934406280517578\n",
      "G loss : 9.540931701660156\n",
      "D loss : 2.21272611618042\n",
      "G loss : 25.186813354492188\n",
      "D loss : 7.875054836273193\n",
      "G loss : 58.6923828125\n",
      "D loss : 11.571898460388184\n",
      "G loss : 46.779624938964844\n",
      "D loss : 2.056399345397949\n",
      "G loss : 35.420047760009766\n",
      "D loss : 14.549077033996582\n",
      "G loss : 29.138826370239258\n",
      "D loss : 8.558443069458008\n",
      "G loss : 13.087163925170898\n",
      "D loss : 18.84269142150879\n",
      "G loss : -3.858619213104248\n",
      "D loss : 10.052099227905273\n",
      "G loss : -18.27951431274414\n",
      "D loss : 12.211575508117676\n",
      "G loss : -10.43481159210205\n",
      "D loss : 12.724689483642578\n",
      "G loss : -30.759815216064453\n",
      "D loss : 6.607393264770508\n",
      "G loss : -32.92141342163086\n",
      "D loss : 7.209780693054199\n",
      "G loss : -47.84872817993164\n",
      "D loss : 14.214683532714844\n",
      "G loss : -36.50575256347656\n",
      "D loss : 13.03731632232666\n",
      "G loss : -7.632259845733643\n",
      "D loss : 13.263614654541016\n",
      "G loss : -3.0644607543945312\n",
      "D loss : 12.02065658569336\n",
      "G loss : -23.060314178466797\n",
      "D loss : 14.333312034606934\n",
      "G loss : -19.295886993408203\n",
      "D loss : 6.400899887084961\n",
      "G loss : -28.338333129882812\n",
      "D loss : 14.12391471862793\n",
      "G loss : -21.30194091796875\n",
      "D loss : 11.032676696777344\n",
      "G loss : -7.056846618652344\n",
      "D loss : 5.135786056518555\n",
      "G loss : -8.961191177368164\n",
      "D loss : 9.277066230773926\n",
      "G loss : 4.519575119018555\n",
      "D loss : 5.210663318634033\n",
      "G loss : 1.9574880599975586\n",
      "D loss : 2.6436166763305664\n",
      "G loss : 9.487184524536133\n",
      "D loss : 1.2628498077392578\n",
      "G loss : 31.027036666870117\n",
      "D loss : 32.096920013427734\n",
      "G loss : 36.415340423583984\n",
      "D loss : 7.537392616271973\n",
      "G loss : 47.174232482910156\n",
      "D loss : 0.9161272048950195\n",
      "G loss : 64.07327270507812\n",
      "D loss : 10.951682090759277\n",
      "G loss : 73.75503540039062\n",
      "D loss : 8.90602970123291\n",
      "G loss : 53.872947692871094\n",
      "D loss : 10.919883728027344\n",
      "G loss : 23.88934326171875\n",
      "D loss : 5.319681167602539\n",
      "G loss : 2.254366159439087\n",
      "D loss : 5.009438514709473\n",
      "G loss : -1.6652181148529053\n",
      "D loss : 0.6278209686279297\n",
      "G loss : -24.413467407226562\n",
      "D loss : 4.683041572570801\n",
      "G loss : -31.868078231811523\n",
      "D loss : 10.815216064453125\n",
      "G loss : -27.65818214416504\n",
      "D loss : 3.638913154602051\n",
      "G loss : -25.17644691467285\n",
      "D loss : 5.681149959564209\n",
      "G loss : -65.64151763916016\n",
      "D loss : 5.188573360443115\n",
      "G loss : -18.459325790405273\n",
      "D loss : 23.39376449584961\n",
      "G loss : 25.582502365112305\n",
      "D loss : 2.121553897857666\n",
      "G loss : -39.78440856933594\n",
      "D loss : 20.746427536010742\n",
      "G loss : 49.098289489746094\n",
      "D loss : 9.529350280761719\n",
      "G loss : 10.616849899291992\n",
      "D loss : 41.096229553222656\n",
      "G loss : 46.0948486328125\n",
      "D loss : 10.904977798461914\n",
      "G loss : 51.15327835083008\n",
      "D loss : 8.177559852600098\n",
      "G loss : 48.93433380126953\n",
      "D loss : -0.06493377685546875\n",
      "G loss : 94.58169555664062\n",
      "D loss : -8.39731502532959\n",
      "G loss : 56.92161560058594\n",
      "D loss : 36.51797103881836\n",
      "G loss : 44.9710693359375\n",
      "D loss : 2.986268997192383\n",
      "G loss : 11.81727409362793\n",
      "D loss : -23.55628776550293\n",
      "G loss : 18.5322265625\n",
      "D loss : 2.567227363586426\n",
      "G loss : 14.40097427368164\n",
      "D loss : 54.86124801635742\n",
      "G loss : -31.528156280517578\n",
      "D loss : 17.583688735961914\n",
      "G loss : -2.978917121887207\n",
      "D loss : 4.766694068908691\n",
      "G loss : -21.568645477294922\n",
      "D loss : 18.104719161987305\n",
      "G loss : -13.761215209960938\n",
      "D loss : 19.81294059753418\n",
      "G loss : -26.637432098388672\n",
      "D loss : 6.806117057800293\n",
      "G loss : -35.39933776855469\n",
      "D loss : 8.509952545166016\n",
      "G loss : -35.427940368652344\n",
      "D loss : 3.721414566040039\n",
      "G loss : -44.242408752441406\n",
      "D loss : 5.584567070007324\n",
      "G loss : -63.791648864746094\n",
      "D loss : 6.255711555480957\n",
      "G loss : -57.58356475830078\n",
      "D loss : 9.267906188964844\n",
      "G loss : -54.26341247558594\n",
      "D loss : -0.8980083465576172\n",
      "G loss : -58.79476547241211\n",
      "D loss : 5.270781993865967\n",
      "G loss : -55.34278106689453\n",
      "D loss : 11.097076416015625\n",
      "G loss : -78.79499816894531\n",
      "D loss : 13.122889518737793\n",
      "G loss : -66.96915435791016\n",
      "D loss : 8.902813911437988\n",
      "G loss : -46.86824035644531\n",
      "D loss : 7.200862884521484\n",
      "G loss : -36.292110443115234\n",
      "D loss : 9.653584480285645\n",
      "G loss : -24.61670684814453\n",
      "D loss : 1.4535341262817383\n",
      "G loss : -18.13682746887207\n",
      "D loss : 16.607088088989258\n",
      "G loss : 5.430920600891113\n",
      "D loss : 13.558419227600098\n",
      "G loss : 45.404212951660156\n",
      "D loss : -0.1546611785888672\n",
      "G loss : 56.259552001953125\n",
      "D loss : 1.9636211395263672\n",
      "G loss : 73.02268981933594\n",
      "D loss : 3.318638801574707\n",
      "G loss : 57.48638153076172\n",
      "D loss : 1.8955020904541016\n",
      "G loss : 55.64545822143555\n",
      "D loss : 14.961563110351562\n",
      "G loss : 65.82321166992188\n",
      "D loss : 11.106664657592773\n",
      "G loss : 46.30596923828125\n",
      "D loss : 8.956340789794922\n",
      "G loss : 26.198020935058594\n",
      "D loss : 3.8932876586914062\n",
      "G loss : 19.43242645263672\n",
      "D loss : 6.23740816116333\n",
      "G loss : 17.20759391784668\n",
      "D loss : 9.208751678466797\n",
      "G loss : -5.3581013679504395\n",
      "D loss : -0.9928975105285645\n",
      "G loss : -38.103485107421875\n",
      "D loss : 19.861709594726562\n",
      "G loss : -10.963062286376953\n",
      "D loss : 11.886568069458008\n",
      "G loss : -20.14944076538086\n",
      "D loss : 16.97373390197754\n",
      "G loss : -14.62784194946289\n",
      "D loss : 9.627402305603027\n",
      "G loss : 24.728849411010742\n",
      "D loss : 6.176875114440918\n",
      "G loss : 39.594459533691406\n",
      "D loss : 4.039313316345215\n",
      "G loss : 67.97914123535156\n",
      "D loss : 9.443683624267578\n",
      "G loss : 59.277305603027344\n",
      "D loss : 2.6387834548950195\n",
      "G loss : 63.30495071411133\n",
      "D loss : 2.8590760231018066\n",
      "G loss : 55.08858871459961\n",
      "D loss : -4.821755409240723\n",
      "G loss : 33.267799377441406\n",
      "D loss : 5.180770397186279\n",
      "G loss : -18.384733200073242\n",
      "D loss : 15.165634155273438\n",
      "G loss : -69.29296875\n",
      "D loss : 9.156076431274414\n",
      "G loss : -99.16973876953125\n",
      "D loss : 13.692525863647461\n",
      "G loss : -96.3521957397461\n",
      "D loss : 6.216510772705078\n",
      "G loss : -109.86289978027344\n",
      "D loss : -0.16347932815551758\n",
      "G loss : -59.28187561035156\n",
      "D loss : -21.111263275146484\n",
      "G loss : -101.90377807617188\n",
      "D loss : 22.029342651367188\n",
      "G loss : -60.71137619018555\n",
      "D loss : 16.920360565185547\n",
      "G loss : -40.27619171142578\n",
      "D loss : 16.532930374145508\n",
      "G loss : -48.73127746582031\n",
      "D loss : 14.491943359375\n",
      "G loss : -30.743722915649414\n",
      "D loss : 12.461908340454102\n",
      "G loss : 28.96221160888672\n",
      "D loss : 6.571173667907715\n",
      "G loss : 77.11134338378906\n",
      "D loss : -8.678178787231445\n",
      "G loss : 117.6302490234375\n",
      "D loss : 10.049224853515625\n",
      "G loss : 122.88475799560547\n",
      "D loss : 7.432355880737305\n",
      "G loss : 120.78335571289062\n",
      "D loss : 15.049503326416016\n",
      "G loss : 118.27752685546875\n",
      "D loss : 26.785486221313477\n",
      "G loss : 60.13368225097656\n",
      "D loss : 10.935110092163086\n",
      "G loss : 46.595787048339844\n",
      "D loss : 17.976491928100586\n",
      "G loss : 47.350852966308594\n",
      "D loss : 17.166133880615234\n",
      "G loss : 20.241912841796875\n",
      "D loss : 15.863037109375\n",
      "G loss : -10.555252075195312\n",
      "D loss : 10.870205879211426\n",
      "G loss : -21.292343139648438\n",
      "D loss : 9.008878707885742\n",
      "G loss : -25.049659729003906\n",
      "D loss : 4.579634666442871\n",
      "G loss : -32.53057098388672\n",
      "D loss : 4.607858180999756\n",
      "G loss : -46.84742736816406\n",
      "D loss : 6.163633346557617\n",
      "G loss : -67.0541000366211\n",
      "D loss : 16.33643341064453\n",
      "G loss : -49.88610076904297\n",
      "D loss : 8.846304893493652\n",
      "G loss : -46.40475845336914\n",
      "D loss : 12.65772819519043\n",
      "G loss : -20.798709869384766\n",
      "D loss : 8.596503257751465\n",
      "G loss : 1.3019946813583374\n",
      "D loss : 5.444032669067383\n",
      "G loss : 28.052881240844727\n",
      "D loss : 5.07312536239624\n",
      "G loss : 45.780120849609375\n",
      "D loss : 8.238694190979004\n",
      "G loss : 52.01238250732422\n",
      "D loss : 3.8716373443603516\n",
      "G loss : 85.664794921875\n",
      "D loss : 1.8052263259887695\n",
      "G loss : 104.9789047241211\n",
      "D loss : 27.317996978759766\n",
      "G loss : 56.424251556396484\n",
      "D loss : 11.770706176757812\n",
      "G loss : 31.242725372314453\n",
      "D loss : 17.215885162353516\n",
      "G loss : 4.541254997253418\n",
      "D loss : 11.413487434387207\n",
      "G loss : 6.852444171905518\n",
      "D loss : 11.205436706542969\n",
      "G loss : -16.513031005859375\n",
      "D loss : 3.964630126953125\n",
      "G loss : -40.234432220458984\n",
      "D loss : 5.8534255027771\n",
      "G loss : -57.37930679321289\n",
      "D loss : 16.42464828491211\n",
      "G loss : -47.96446228027344\n",
      "D loss : 0.9495234489440918\n",
      "G loss : -98.7578353881836\n",
      "D loss : 12.853012084960938\n",
      "G loss : -93.6124267578125\n",
      "D loss : 21.226993560791016\n",
      "G loss : -74.10688018798828\n",
      "D loss : 8.033676147460938\n",
      "G loss : -60.461814880371094\n",
      "D loss : 10.361741065979004\n",
      "G loss : -45.02895736694336\n",
      "D loss : 9.837230682373047\n",
      "G loss : -36.3725700378418\n",
      "D loss : 16.89986801147461\n",
      "G loss : -17.02737808227539\n",
      "D loss : 4.685683250427246\n",
      "G loss : 0.3300292491912842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 8.299609184265137\n",
      "G loss : 29.33709716796875\n",
      "D loss : 22.242490768432617\n",
      "G loss : 43.36383056640625\n",
      "D loss : 1.1847209930419922\n",
      "G loss : 50.43235778808594\n",
      "D loss : 5.99504280090332\n",
      "G loss : 65.78820037841797\n",
      "D loss : 7.9616007804870605\n",
      "G loss : 77.56398010253906\n",
      "D loss : 6.9806437492370605\n",
      "G loss : 102.28033447265625\n",
      "D loss : 10.756916046142578\n",
      "G loss : 70.41078186035156\n",
      "D loss : 12.34740161895752\n",
      "G loss : 59.84373474121094\n",
      "D loss : 11.866439819335938\n",
      "G loss : 47.19313049316406\n",
      "D loss : 11.157526969909668\n",
      "G loss : 11.486440658569336\n",
      "D loss : 3.6955394744873047\n",
      "G loss : -8.750762939453125\n",
      "D loss : 6.802883148193359\n",
      "G loss : -15.366872787475586\n",
      "D loss : 9.66313648223877\n",
      "G loss : -46.67436218261719\n",
      "D loss : 4.53683614730835\n",
      "G loss : -37.50836181640625\n",
      "D loss : 21.807947158813477\n",
      "G loss : -40.983821868896484\n",
      "D loss : 9.831147193908691\n",
      "G loss : -39.108421325683594\n",
      "D loss : 6.798544883728027\n",
      "G loss : -39.285587310791016\n",
      "D loss : 11.773355484008789\n",
      "G loss : -24.609619140625\n",
      "D loss : -1.9784207344055176\n",
      "G loss : -10.27353286743164\n",
      "D loss : 2.5983686447143555\n",
      "G loss : 10.536017417907715\n",
      "D loss : 9.009672164916992\n",
      "G loss : -3.7208919525146484\n",
      "D loss : 32.26830291748047\n",
      "G loss : -0.09250915050506592\n",
      "D loss : 5.679909706115723\n",
      "G loss : 39.93647003173828\n",
      "D loss : 24.756067276000977\n",
      "G loss : 23.283061981201172\n",
      "D loss : 6.789436340332031\n",
      "G loss : 35.357666015625\n",
      "D loss : 7.013411521911621\n",
      "G loss : 56.08177185058594\n",
      "D loss : 3.7551498413085938\n",
      "G loss : 73.75498962402344\n",
      "D loss : 8.029430389404297\n",
      "G loss : 76.75564575195312\n",
      "D loss : -2.472806930541992\n",
      "G loss : 111.82749938964844\n",
      "D loss : 24.004669189453125\n",
      "G loss : 48.93877410888672\n",
      "D loss : 13.804040908813477\n",
      "G loss : 38.158416748046875\n",
      "D loss : 11.118664741516113\n",
      "G loss : 20.603864669799805\n",
      "D loss : 7.6506242752075195\n",
      "G loss : 3.1052191257476807\n",
      "D loss : 8.576355934143066\n",
      "G loss : -5.11508846282959\n",
      "D loss : 6.174344062805176\n",
      "G loss : -18.957304000854492\n",
      "D loss : 7.8010969161987305\n",
      "G loss : -31.482803344726562\n",
      "D loss : 4.1015095710754395\n",
      "G loss : -46.982139587402344\n",
      "D loss : 5.089449405670166\n",
      "G loss : -62.21378707885742\n",
      "D loss : 22.355304718017578\n",
      "G loss : -75.19640350341797\n",
      "D loss : 9.716978073120117\n",
      "G loss : -64.29218292236328\n",
      "D loss : 15.355878829956055\n",
      "G loss : -57.61289596557617\n",
      "D loss : 16.24408531188965\n",
      "G loss : -43.18776321411133\n",
      "D loss : 7.812812805175781\n",
      "G loss : -13.41187572479248\n",
      "D loss : 5.378202438354492\n",
      "G loss : -4.570286750793457\n",
      "D loss : 13.619612693786621\n",
      "G loss : 15.802742004394531\n",
      "D loss : 16.788803100585938\n",
      "G loss : 22.742006301879883\n",
      "D loss : 10.205337524414062\n",
      "G loss : 53.63922119140625\n",
      "D loss : 9.240630149841309\n",
      "G loss : 53.96885681152344\n",
      "saving model...\n",
      "Model saved in file: ./model_tf/model_gan9_bs16_HEclass_original_3.ckpt\n",
      "D loss : 7.826889991760254\n",
      "G loss : 70.72256469726562\n",
      "D loss : 6.925772666931152\n",
      "G loss : 69.14540100097656\n",
      "D loss : 8.882317543029785\n",
      "G loss : 67.26101684570312\n",
      "D loss : 17.120304107666016\n",
      "G loss : 28.002416610717773\n",
      "D loss : 9.64307689666748\n",
      "G loss : 4.391880512237549\n",
      "D loss : 8.194650650024414\n",
      "G loss : -12.668730735778809\n",
      "D loss : 12.620768547058105\n",
      "G loss : -6.1117353439331055\n",
      "D loss : 2.5352354049682617\n",
      "G loss : -12.38920783996582\n",
      "D loss : 11.696264266967773\n",
      "G loss : -34.911643981933594\n",
      "D loss : 10.439814567565918\n",
      "G loss : -21.443117141723633\n",
      "D loss : 3.29238224029541\n",
      "G loss : -27.884113311767578\n",
      "D loss : 5.976987838745117\n",
      "G loss : -15.861153602600098\n",
      "D loss : 6.704187393188477\n",
      "G loss : -19.236515045166016\n",
      "D loss : 10.682395935058594\n",
      "G loss : 4.2849578857421875\n",
      "D loss : 11.547001838684082\n",
      "G loss : -7.249114513397217\n",
      "D loss : 15.360522270202637\n",
      "G loss : -11.221162796020508\n",
      "D loss : 11.444123268127441\n",
      "G loss : -9.481128692626953\n",
      "D loss : 7.87200927734375\n",
      "G loss : 16.751617431640625\n",
      "D loss : 2.568406105041504\n",
      "G loss : 33.71424102783203\n",
      "D loss : -0.964015007019043\n",
      "G loss : 59.76006317138672\n",
      "D loss : 9.370855331420898\n",
      "G loss : 22.026676177978516\n",
      "D loss : 15.511358261108398\n",
      "G loss : 18.75783348083496\n",
      "D loss : 9.874496459960938\n",
      "G loss : 5.851100444793701\n",
      "D loss : 14.735445976257324\n",
      "G loss : 30.28469467163086\n",
      "D loss : 15.962675094604492\n",
      "G loss : 60.074378967285156\n",
      "D loss : 12.645800590515137\n",
      "G loss : 31.744422912597656\n",
      "D loss : 11.567108154296875\n",
      "G loss : 5.561698913574219\n",
      "D loss : 9.015456199645996\n",
      "G loss : -5.883092403411865\n",
      "D loss : 7.811328887939453\n",
      "G loss : 20.476070404052734\n",
      "D loss : 14.318552017211914\n",
      "G loss : 0.990462064743042\n",
      "D loss : 15.274253845214844\n",
      "G loss : -24.002822875976562\n",
      "D loss : 6.919611930847168\n",
      "G loss : -24.68920135498047\n",
      "D loss : 3.458982467651367\n",
      "G loss : -27.63711166381836\n",
      "D loss : 14.671649932861328\n",
      "G loss : -25.55060577392578\n",
      "D loss : 9.332151412963867\n",
      "G loss : -15.531862258911133\n",
      "D loss : 9.27599811553955\n",
      "G loss : 1.1730059385299683\n",
      "D loss : 10.4954833984375\n",
      "G loss : 6.595698833465576\n",
      "D loss : 14.36761474609375\n",
      "G loss : 1.93708074092865\n",
      "D loss : 8.566679954528809\n",
      "G loss : 17.12078285217285\n",
      "D loss : 9.19140625\n",
      "G loss : 34.23500061035156\n",
      "D loss : 11.23354721069336\n",
      "G loss : 15.97262954711914\n",
      "D loss : 9.306535720825195\n",
      "G loss : -4.639383792877197\n",
      "D loss : 7.515003681182861\n",
      "G loss : -5.586381435394287\n",
      "D loss : 6.205541610717773\n",
      "G loss : -7.474414348602295\n",
      "D loss : 8.141292572021484\n",
      "G loss : -21.284191131591797\n",
      "D loss : 6.899605751037598\n",
      "G loss : -23.633569717407227\n",
      "D loss : 8.301194190979004\n",
      "G loss : -23.14270782470703\n",
      "D loss : 15.870024681091309\n",
      "G loss : -21.526134490966797\n",
      "D loss : 11.851598739624023\n",
      "G loss : -2.1623117923736572\n",
      "D loss : 8.498065948486328\n",
      "G loss : 29.02634048461914\n",
      "D loss : 3.4780988693237305\n",
      "G loss : 58.389556884765625\n",
      "D loss : 25.562599182128906\n",
      "G loss : 13.66986083984375\n",
      "D loss : 8.844378471374512\n",
      "G loss : 17.618106842041016\n",
      "D loss : 9.440649032592773\n",
      "G loss : 26.319866180419922\n",
      "D loss : 10.428144454956055\n",
      "G loss : 34.308815002441406\n",
      "D loss : 11.131217956542969\n",
      "G loss : 0.7924847602844238\n",
      "D loss : 9.466968536376953\n",
      "G loss : -2.2271809577941895\n",
      "D loss : 4.495166778564453\n",
      "G loss : -14.259834289550781\n",
      "D loss : 5.59765625\n",
      "G loss : -29.641265869140625\n",
      "D loss : 6.557222366333008\n",
      "G loss : -29.910348892211914\n",
      "D loss : 11.332077980041504\n",
      "G loss : -25.242145538330078\n",
      "D loss : 6.241452217102051\n",
      "G loss : -40.55320358276367\n",
      "D loss : 4.002735137939453\n",
      "G loss : -54.05812072753906\n",
      "D loss : 11.147565841674805\n",
      "G loss : -49.3704833984375\n",
      "D loss : 18.468172073364258\n",
      "G loss : -50.740684509277344\n",
      "D loss : 7.725276947021484\n",
      "G loss : -50.341148376464844\n",
      "D loss : 16.28371810913086\n",
      "G loss : -29.671218872070312\n",
      "D loss : 12.628393173217773\n",
      "G loss : 8.02514934539795\n",
      "D loss : 5.433067798614502\n",
      "G loss : -2.395812511444092\n",
      "D loss : 4.600332736968994\n",
      "G loss : 6.065549850463867\n",
      "D loss : 7.352422714233398\n",
      "G loss : 44.693111419677734\n",
      "D loss : 0.43618202209472656\n",
      "G loss : 64.73694610595703\n",
      "D loss : 12.375900268554688\n",
      "G loss : 85.65607452392578\n",
      "D loss : -0.03672599792480469\n",
      "G loss : 75.58076477050781\n",
      "D loss : 11.203554153442383\n",
      "G loss : 104.97543334960938\n",
      "D loss : 7.085862159729004\n",
      "G loss : 74.23561096191406\n",
      "D loss : 16.79637908935547\n",
      "G loss : 68.78250122070312\n",
      "D loss : 23.18038558959961\n",
      "G loss : 32.70941925048828\n",
      "D loss : 17.88204002380371\n",
      "G loss : 6.861542701721191\n",
      "D loss : 13.05689525604248\n",
      "G loss : -4.027419090270996\n",
      "D loss : 6.398194789886475\n",
      "G loss : -34.764503479003906\n",
      "D loss : 10.936753273010254\n",
      "G loss : -41.076637268066406\n",
      "D loss : 5.669240951538086\n",
      "G loss : -48.0927619934082\n",
      "D loss : 10.086453437805176\n",
      "G loss : -45.04297637939453\n",
      "D loss : 7.707195281982422\n",
      "G loss : -43.85527801513672\n",
      "D loss : 12.912798881530762\n",
      "G loss : -17.677715301513672\n",
      "D loss : 7.147479057312012\n",
      "G loss : -15.123382568359375\n",
      "D loss : 6.465456962585449\n",
      "G loss : -1.1061081886291504\n",
      "D loss : 1.5274486541748047\n",
      "G loss : 13.907873153686523\n",
      "D loss : -6.035383224487305\n",
      "G loss : 40.13867950439453\n",
      "D loss : 6.277378082275391\n",
      "G loss : 61.98853302001953\n",
      "D loss : 2.43794584274292\n",
      "G loss : 55.19449234008789\n",
      "D loss : 1.801347255706787\n",
      "G loss : 46.05841827392578\n",
      "D loss : 15.359375\n",
      "G loss : 40.385704040527344\n",
      "D loss : 4.158143997192383\n",
      "G loss : 22.020414352416992\n",
      "D loss : 6.717165470123291\n",
      "G loss : -7.23169469833374\n",
      "D loss : 32.35284423828125\n",
      "G loss : 16.870594024658203\n",
      "D loss : 13.797994613647461\n",
      "G loss : 44.582489013671875\n",
      "D loss : 7.933189392089844\n",
      "G loss : 25.07435417175293\n",
      "D loss : 16.926448822021484\n",
      "G loss : 20.809425354003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss : 7.822888374328613\n",
      "G loss : 28.51529312133789\n",
      "D loss : 7.467689514160156\n",
      "G loss : 21.348854064941406\n",
      "D loss : -5.572029113769531\n",
      "G loss : 5.781357288360596\n",
      "D loss : 11.614070892333984\n",
      "G loss : 18.075923919677734\n",
      "D loss : 12.191112518310547\n",
      "G loss : -31.026039123535156\n",
      "D loss : 8.160492897033691\n",
      "G loss : -39.71106719970703\n",
      "D loss : 5.855118751525879\n",
      "G loss : -39.4921989440918\n",
      "D loss : 4.80778694152832\n",
      "G loss : -37.97461700439453\n",
      "D loss : 15.061138153076172\n",
      "G loss : -46.03437042236328\n",
      "D loss : 10.6708984375\n",
      "G loss : -26.970115661621094\n",
      "D loss : 8.167801856994629\n",
      "G loss : -29.55426788330078\n",
      "D loss : 5.9436540603637695\n",
      "G loss : -25.987403869628906\n",
      "D loss : 8.811284065246582\n",
      "G loss : -29.717679977416992\n",
      "D loss : 6.819640159606934\n",
      "G loss : -5.977262496948242\n"
     ]
    }
   ],
   "source": [
    "def training() :\n",
    "    tf.reset_default_graph()\n",
    "    ary_tag_hair, ary_tag_eyes, ary_img = preprocess(save=False,load=load_data)\n",
    "    if condition :\n",
    "        gan = GAN()\n",
    "        gan.build_net()\n",
    "        if load_model :\n",
    "            pass\n",
    "        pretrain_hair = True\n",
    "        if pretrain_hair :\n",
    "            for i in range(10) :\n",
    "                print (i)\n",
    "                ary_tag_hair_sh, ary_tag_eyes_sh, ary_img_sh = shuffle(ary_tag_hair[:-1000], ary_tag_eyes[:-1000], ary_img[:-1000], random_state=i)\n",
    "                ary_img_sh = ary_img_sh*2 -1\n",
    "                b_i = 0\n",
    "                while b_i+gan.bs_pre < len_img_all-1000 :\n",
    "                    sys.stdout.write(\"\\r{}\\t\".format(b_i))\n",
    "                    sys.stdout.flush()\n",
    "                    b_tag_hair = ary_tag_hair_sh[b_i:b_i+gan.bs_pre]\n",
    "                    b_img = ary_img_sh[b_i:b_i+gan.bs_pre]\n",
    "                    \n",
    "                    _, loss = gan.sess.run([gan.hair_train,gan.hair_loss], feed_dict={gan.hair_in_hair:b_tag_hair,\n",
    "                                                            gan.hair_in_img:b_img})\n",
    "#                     print (loss)\n",
    "                    b_i += gan.bs_pre\n",
    "                ### validation    \n",
    "                y_pred = np.argmax(gan.sess.run(gan.hair, feed_dict={gan.hair_in_img:ary_img[-500:]}), axis=1)\n",
    "                y_true = ary_tag_hair[-500:]\n",
    "#                 print ('\\n')\n",
    "#                 print (y_pred)\n",
    "#                 print (y_true)\n",
    "                print ('acc : {}'.format(accuracy_score(y_true,y_pred)))\n",
    "\n",
    "        pretrain_eyes = True\n",
    "        if pretrain_eyes :\n",
    "            for i in range(10) :\n",
    "                print (i)\n",
    "                ary_tag_eyes_sh, ary_tag_eyes_sh, ary_img_sh = shuffle(ary_tag_eyes[:-1000], ary_tag_eyes[:-1000], ary_img[:-1000], random_state=i)\n",
    "                ary_img_sh = ary_img_sh*2 -1\n",
    "                b_i = 0\n",
    "                while b_i+gan.bs_pre < len_img_all-1000 :\n",
    "                    sys.stdout.write(\"\\r{}\\t\".format(b_i))\n",
    "                    sys.stdout.flush()\n",
    "                    b_tag_eyes = ary_tag_eyes_sh[b_i:b_i+gan.bs_pre]\n",
    "                    b_img = ary_img_sh[b_i:b_i+gan.bs_pre]\n",
    "                    \n",
    "                    _, loss = gan.sess.run([gan.eyes_train,gan.eyes_loss], feed_dict={gan.eyes_in_eyes:b_tag_eyes,\n",
    "                                                            gan.eyes_in_img:b_img})\n",
    "#                     print (loss)\n",
    "                    b_i += gan.bs_pre\n",
    "                ### validation    \n",
    "                y_pred = np.argmax(gan.sess.run(gan.eyes, feed_dict={gan.eyes_in_img:ary_img[-500:]}), axis=1)\n",
    "                y_true = ary_tag_eyes[-500:]\n",
    "#                 print ('\\n')\n",
    "#                 print (y_pred)\n",
    "#                 print (y_true)\n",
    "                print ('acc : {}'.format(accuracy_score(y_true,y_pred)))\n",
    "    else :\n",
    "        gan = GAN_no_condition()\n",
    "        gan.build_net()\n",
    "    \n",
    "    lst_loss_his_d = []\n",
    "    lst_loss_his_g = []\n",
    "    for i in range(iteration) :\n",
    "        print(i)\n",
    "        ary_tag_hair_sh, ary_tag_eyes_sh, ary_img_sh = shuffle(ary_tag_hair, ary_tag_eyes, ary_img, random_state=i)\n",
    "        gen_tag_hair = np.random.randint(13, size=int(len_img_all/2+1))\n",
    "        gen_tag_eyes = np.random.randint(12, size=int(len_img_all/2+1))\n",
    "        ary_img_sh = ary_img_sh*2 -1\n",
    "        \n",
    "        b_i = 0\n",
    "        while b_i+gan.bs <= len_img_all :\n",
    "            b_tag_hair_right = ary_tag_hair_sh[b_i:b_i+gan.bs]\n",
    "            b_tag_eyes_right = ary_tag_eyes_sh[b_i:b_i+gan.bs]\n",
    "            b_img_right = ary_img_sh[b_i:b_i+gan.bs]\n",
    "            \n",
    "            # fake1 (right img wrong text)\n",
    "            b_tag_hair_fake1 = np.random.randint(1,13, size=int(gan.bs/4))\n",
    "            b_tag_eyes_fake1 = np.random.randint(1,12, size=int(gan.bs/4))\n",
    "            b_img_fake1 = np.copy(b_img_right[:int(gan.bs/4)])\n",
    "            for ii in range(int(gan.bs/4)) :\n",
    "                while b_tag_hair_fake1[ii] == b_tag_hair_right[ii] :\n",
    "                    b_tag_hair_fake1[ii] = random.randint(0,13)\n",
    "                while b_tag_eyes_fake1[ii] == b_tag_eyes_right[ii] :\n",
    "                    b_tag_eyes_fake1[ii] = random.randint(0,12)\n",
    "                    \n",
    "            # fake2 (wrong img right text)\n",
    "            b_tag_hair_fake2 = np.copy(b_tag_hair_right[:int(gan.bs/4)])\n",
    "            b_tag_eyes_fake2 = np.copy(b_tag_eyes_right[:int(gan.bs/4)])\n",
    "            lst_random_num = random.sample(range(len_img_all),k=int(gan.bs/4))\n",
    "            b_img_fake2 = np.copy(ary_img_sh[lst_random_num])\n",
    "            \n",
    "            # fake3 (generate img right text)\n",
    "            b_tag_hair_fake3 = gen_tag_hair[int(b_i/2):int(b_i/2+gan.bs/2)]\n",
    "            b_tag_eyes_fake3 = gen_tag_eyes[int(b_i/2):int(b_i/2+gan.bs/2)]\n",
    "            ary_temp = np.random.normal(0,1,[b_tag_eyes_fake3.shape[0],100])\n",
    "\n",
    "            b_img_fake3 = gan.sess.run(gan.g, feed_dict={gan.G_in_hair:b_tag_hair_fake3, \n",
    "                                                         gan.G_in_eyes:b_tag_eyes_fake3, \n",
    "                                                         gan.G_in_noise:ary_temp})\n",
    "            \n",
    "            \n",
    "            # update D\n",
    "            b_tag_hair = np.concatenate((b_tag_hair_right,b_tag_hair_fake1,b_tag_hair_fake2,b_tag_hair_fake3), axis=0)\n",
    "            b_tag_eyes = np.concatenate((b_tag_eyes_right,b_tag_eyes_fake1,b_tag_eyes_fake2,b_tag_eyes_fake3), axis=0)\n",
    "            b_img = np.concatenate((b_img_right,b_img_fake1,b_img_fake2,b_img_fake3), axis=0)\n",
    "            b_epsilon = np.random.rand(1,)\n",
    "            for i2 in range(D_ITER) :\n",
    "                _, loss_D = gan.sess.run([gan.d_train,gan.d_loss], feed_dict={gan.D_in_hair:b_tag_hair, \n",
    "                                                          gan.D_in_eyes:b_tag_eyes, \n",
    "                                                          gan.D_in_img:b_img,\n",
    "                                                          gan.epsilon:b_epsilon})\n",
    "            \n",
    "                print ('D loss : {}'.format(loss_D))\n",
    "            \n",
    "            # update G\n",
    "            b_tag_hair_g = gen_tag_hair[int(b_i/2):int(b_i/2+gan.bs/2)]\n",
    "            b_tag_eyes_g = gen_tag_eyes[int(b_i/2):int(b_i/2+gan.bs/2)]\n",
    "            ary_temp_g = np.random.normal(0,1,[b_tag_hair_g.shape[0],100])\n",
    "            for i3 in range(G_ITER) :\n",
    "                _, loss_G = gan.sess.run([gan.gd_train,gan.gd_loss], feed_dict={gan.G_in_hair:b_tag_hair_g, \n",
    "                                                         gan.G_in_eyes:b_tag_eyes_g, \n",
    "                                                         gan.G_in_noise:ary_temp_g})\n",
    "    \n",
    "                print ('G loss : {}'.format(loss_G))\n",
    "            \n",
    "            \n",
    "            if b_i % 6400 == 0 :\n",
    "                lst_loss_his_d += [loss_D]\n",
    "                lst_loss_his_g += [loss_G]\n",
    "                print ('saving model...')\n",
    "                if not os.path.isdir('./model_tf') :\n",
    "                    os.mkdir('./model_tf')\n",
    "                if not os.path.isdir('./record') :\n",
    "                    os.mkdir('./record')\n",
    "                if not os.path.isdir('./img') :\n",
    "                    os.mkdir('./img')\n",
    "                k = 0\n",
    "                while 1 :\n",
    "                    if os.path.isfile('./model_tf/model_{}_{}.ckpt.meta'.format(output_str, k)) :\n",
    "                        k += 1\n",
    "                    else :\n",
    "                        break\n",
    "                save_path = gan.saver.save(gan.sess, './model_tf/model_{}_{}.ckpt'.format(output_str, k))\n",
    "                with open('./record/loss_g_{}_{}.pkl'.format(output_str, k), 'wb') as f:\n",
    "                    pickle.dump(lst_loss_his_g, f)\n",
    "                with open('./record/loss_d_{}_{}.pkl'.format(output_str, k), 'wb') as f:\n",
    "                    pickle.dump(lst_loss_his_d, f)\n",
    "                img_sample = gan.sess.run(gan.g, feed_dict={gan.G_in_hair:b_tag_hair_fake3, \n",
    "                                                         gan.G_in_eyes:b_tag_eyes_fake3, \n",
    "                                                         gan.G_in_noise:ary_temp})\n",
    "                scipy.misc.imsave('img/img_sample_{}_{}.jpg'.format(output_str,k),img_sample[0]) \n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "            b_i += gan.bs\n",
    "        \n",
    "training()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,6\n",
    "    # 2,4,12\n",
    "    # 3,5,9\n",
    "    # 7,10\n",
    "#     lst_hair = ['null', 1'orange hair', 2'white hair', 3'aqua hair', 4'gray hair',\n",
    "#                 5'green hair', 6'red hair', 7'purple hair', 8'pink hair',\n",
    "#                 9'blue hair', 10'black hair', 11'brown hair', 12'blonde hair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_show() :\n",
    "    k = 0\n",
    "    img_temp = skimage.io.imread('img_sample_{}_{}.jpg'.format(output_str,k))\n",
    "    imshow(img_temp)\n",
    "test_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pre(text) :\n",
    "    text = text.replace(',',' ')\n",
    "    lst_text = text.split(' ')\n",
    "    hair_i = 0\n",
    "    eyes_i = 0\n",
    "    for i,s in enumerate(lst_text) :\n",
    "        if s == 'hair' :\n",
    "            hair_i = i\n",
    "        elif s == 'eyes' :\n",
    "            eyes_i = i\n",
    "    if hair_i :\n",
    "        hair_style = lst_text[hair_i-1] + ' ' + lst_text[hair_i]\n",
    "    else :\n",
    "        hair_style = 'null'\n",
    "    if eyes_i :\n",
    "        eyes_style = lst_text[eyes_i-1] + ' ' + lst_text[eyes_i]\n",
    "    else :\n",
    "        eyes_style = 'null'\n",
    "    \n",
    "    return hair_style, eyes_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## special task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img() :\n",
    "    for i in range(5) :\n",
    "        ary_img = np.random.randint(255,size=(64,64,3))\n",
    "        scipy.misc.imsave('sample_1_{}.jpg'.format(i+1),ary_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'red hair, green eyes'\n",
    "# text = 'red eyes'\n",
    "hair_style, eyes_style = text_pre(text)\n",
    "print (hair_style)\n",
    "print (eyes_style)\n",
    "\n",
    "generate_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "args = get_args()\n",
    "model_type = 'CNN'\n",
    "path_model = get_path_new_model(model_type)\n",
    "#path_model = './model/CNN_1.h5'\n",
    "\n",
    "\n",
    "print ('all process cost {} seconds'.format(time.time() - start_t))\n",
    "print ('all done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15).reshape((3,5))\n",
    "print (a[[0,2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'value' is a tensor with shape [5, 30]\n",
    "# Split 'value' into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
    "v = tf.constant(1, shape=[5,30])\n",
    "v2 = tf.constant(2, shape=[5,30])\n",
    "vv = tf.add(v,v2)\n",
    "sess = tf.Session(config=config)\n",
    "vv = sess.run(vv, feed_dict={})\n",
    "print(vv)\n",
    "\n",
    "print (v)\n",
    "s0, s1, s2 = tf.split(v, [1, 1, 3], 0)\n",
    "print (s0)\n",
    "print (s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15).reshape((3,5))\n",
    "b = np.ones((3,5))\n",
    "\n",
    "print ((a+b)/2)\n",
    "\n",
    "c = tf.placeholder(tf.float32, shape=(None,3,5))\n",
    "c = tf.constant(1.0, shape=[3,5])\n",
    "cc = c[:2] + 1\n",
    "print (cc)\n",
    "x = tf.range(0,15,1,dtype=tf.float32)\n",
    "xx = tf.reshape(x,shape=[3,5])\n",
    "\n",
    "\n",
    "d = tf.norm(c, ord=2)\n",
    "print (d)\n",
    "sess = tf.Session(config=config)\n",
    "vv = sess.run(xx+c, feed_dict={})\n",
    "print (vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0,1,[3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
